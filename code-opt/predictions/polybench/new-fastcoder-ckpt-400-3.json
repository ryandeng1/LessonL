{
  "gemm": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_gemm(int ni, int nj, int nk,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B,\n                 std::vector<std::vector<double>>& C)\n{\n    /* Convert the std::vector<std::vector<double>> to 1\u2011dimensional\n       contiguous arrays for better cache behaviour.\n       The input matrices are unchanged, only auxiliary pointers\n       are created for the inner loops.                                       */\n    const size_t A_off = 0, B_off = 0, C_off = 0;          // not used, kept for clarity\n    auto A_ptr = reinterpret_cast<const double*>(A.data()->data());\n    auto B_ptr = reinterpret_cast<const double*>(B.data()->data());\n    auto C_ptr = reinterpret_cast<double*>(C.data()->data());\n\n    /* OpenMP parallelisation of the outer loop.                         */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i)\n    {\n        /* Multiply the i\u2011th row of C by beta only once.                 */\n        double* c_row = C_ptr + i * nj;\n        for (int j = 0; j < nj; ++j)\n            c_row[j] *= beta;\n\n        /* Compute the dot products for this row.                       */\n        const double* a_row = A_ptr + i * nk;\n        for (int k = 0; k < nk; ++k)\n        {\n            double aik = alpha * a_row[k];\n            const double* b_row = B_ptr + k * nj;\n            for (int j = 0; j < nj; ++j)\n                c_row[j] += aik * b_row[j];\n        }\n    }\n}\n```",
  "covariance": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_covariance(int m, int n,\n                       std::vector<std::vector<double>>& data,\n                       std::vector<std::vector<double>>& cov,\n                       std::vector<double>& mean)\n{\n    // --------------------------------------------------------------------\n    // Step 1: compute column means\n    // --------------------------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double s = 0.0;\n        for (int i = 0; i < n; ++i) {\n            s += data[i][j];\n        }\n        mean[j] = s / n;\n    }\n\n    // --------------------------------------------------------------------\n    // Step 2: center data by subtracting the mean\n    // --------------------------------------------------------------------\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < m; ++j) {\n            data[i][j] -= mean[j];\n        }\n    }\n\n    // --------------------------------------------------------------------\n    // Step 3: compute covariance matrix (upper triangle + mirroring)\n    // --------------------------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        for (int j = i; j < m; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < n; ++k) {\n                sum += data[k][i] * data[k][j];\n            }\n            cov[i][j] = sum / (n - 1.0);\n            if (j != i) {\n                cov[j][i] = cov[i][j];\n            }\n        }\n    }\n}\n```",
  "syr2k": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syr2k(int n, int m,\n                  double alpha,\n                  double beta,\n                  std::vector<std::vector<double>>& C,\n                  std::vector<std::vector<double>>& A,\n                  std::vector<std::vector<double>>& B) {\n    // Parallelise over the outermost loop (rows of C).\n    #pragma omp parallel for schedule(static) collapse(1)\n    for (int i = 0; i < n; ++i) {\n        const double* Ai = A[i].data();        // row i of A\n        const double* Bi = B[i].data();        // row i of B\n        double* Ci = C[i].data();              // row i of C\n\n        // Scale the lower triangular part of the current row.\n        for (int j = 0; j <= i; ++j) {\n            Ci[j] *= beta;\n        }\n\n        // Accumulate the rank\u20112 update.\n        for (int k = 0; k < m; ++k) {\n            const double aik = Ai[k];\n            const double bik = Bi[k];\n            for (int j = 0; j <= i; ++j) {\n                Ci[j] += alpha * (A[j][k]*bik + B[j][k]*aik);\n            }\n        }\n    }\n}\n```\n",
  "atax": "```cpp\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_atax(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& x,\n                 std::vector<double>& y,\n                 std::vector<double>& tmp) {\n    // Initialise y to zero (parallelizable)\n    std::fill(y.begin(), y.end(), 0.0);\n\n    /* Compute tmp[i] = A[i] \u00b7 x          (row\u2011wise dot product)\n       Parallelise over the outer loop (rows).            */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        const double* Ai = A[i].data();   // pointer to the ith row\n        double sum = 0.0;\n        for (int j = 0; j < n; ++j) {\n            sum += Ai[j] * x[j];\n        }\n        tmp[i] = sum;\n    }\n\n    /* Compute y[j] = \u03a3_i A[i][j] * tmp[i]   (col\u2011wise weighted sum)\n       Parallelise over the outer loop (columns).                  */\n#pragma omp parallel for schedule(static)\n    for (int j = 0; j < n; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < m; ++i) {\n            sum += A[i][j] * tmp[i];\n        }\n        y[j] = sum;\n    }\n}\n```",
  "doitgen": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_doitgen(int nr, int nq, int np,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<double>>& C4,\n                    std::vector<double>& sum) {\n\n    // Temporary storage for a row of A - reused across all (r,q)\n    std::vector<double> temp(np);\n\n    // Parallelise outer two loops (r,q) on a single thread pool\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int r = 0; r < nr; ++r) {\n        for (int q = 0; q < nq; ++q) {\n            double* Arow = A[r][q].data();          // pointer to A[r][q][0]\n            const double* C4col;                    // pointer to a column of C4\n\n            // Compute A[r][q][p] = sum over s A[r][q][s] * C4[s][p]\n            for (int p = 0; p < np; ++p) {\n                double acc = 0.0;\n                for (int s = 0; s < np; ++s) {\n                    acc += A[row][s] * C4[s][p];\n                }\n                temp[p] = acc;\n            }\n\n            // Copy result back into A\n            for (int p = 0; p < np; ++p) {\n                Arow[p] = temp[p];\n            }\n        }\n    }\n}\n```\n",
  "nussinov": "```cpp\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\n/* Optimised Nussinov kernel\n *\n * \u2022 Parallelised over all (i,j) pairs using OpenMP\n * \u2022 Local variables reduce memory traffic\n * \u2022 Branches eliminated where possible\n * \u2022 Uses a raw 1\u2011D flat array for the DP table for better cache behaviour\n */\n\nstatic inline int score(int b1, int b2) { return (b1 + b2 == 3) ? 1 : 0; }\n\n/* Helper to compute 1\u2011D index from 2\u2011D coordinates */\nstatic inline size_t idx(size_t i, size_t j, size_t n) { return i * n + j; }\n\n/* Main kernel */\nvoid kernel_nussinov(int n,\n                     const std::vector<int> &seq,\n                     std::vector<std::vector<int>> &table)\n{\n    /* Flatten the 2\u2011D table to a 1\u2011D vector to improve cache locality */\n    std::vector<int> flat(n * n, 0);\n    int *flatP = flat.data();           // raw pointer for speed\n    const int *seqP = seq.data();       // raw pointer for speed\n\n    /* Parallel over all i<j pairs.  The triangular order is optional\n     * because all accesses are read\u2011once from previously computed\n     * positions.  The OpenMP schedule guarantees that a cell is updated\n     * only after the needed predecessors are finished. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            int best = flatP[idx(i, j - 1, n)];       // table[i][j-1]\n            int b = flatP[idx(i + 1, j, n)];          // table[i+1][j]\n            if (b > best) best = b;\n\n            /* Handle the i+1,j-1 case */\n            int b1 = flatP[idx(i + 1, j - 1, n)];\n            if (i < j - 1) {\n                int m = b1 + score(seqP[i], seqP[j]); // match\n                if (m > best) best = m;\n            } else {\n                if (b1 > best) best = b1;\n            }\n\n            /* Split case */\n            for (int k = i + 1; k < j; ++k) {\n                int tmp = flatP[idx(i, k, n)] + flatP[idx(k + 1, j, n)];\n                if (tmp > best) best = tmp;\n            }\n\n            flatP[idx(i, j, n)] = best;\n        }\n    }\n\n    /* Copy the results back to the 2\u2011D table structure */\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            table[i][j] = flatP[idx(i, j, n)];\n}\n```",
  "gesummv": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_gesummv(int n,\n                    double alpha,\n                    double beta,\n                    std::vector<std::vector<double>>& A,\n                    std::vector<std::vector<double>>& B,\n                    std::vector<double>& tmp,\n                    std::vector<double>& x,\n                    std::vector<double>& y) {\n\n    /* Parallelize the outer loop.  The inner loop is a pure dot product\n       that scales well with a few registers.  We keep the data layout\n       unchanged but use raw pointers to eliminate bounds checks. */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double tmp_i = 0.0;\n        double y_i   = 0.0;\n\n        /* Pointers to the i\u2011th row in A and B eliminate vector indexing\n           overhead; x remains a simple vector because it is accessed\n           sequentially. */\n        double *restrict Ai = A.at(i).data();\n        double *restrict Bi = B.at(i).data();\n\n        for (int j = 0; j < n; ++j) {\n            const double xj = x[j];\n            tmp_i += Ai[j] * xj;\n            y_i   += Bi[j] * xj;\n        }\n\n        tmp[i] = tmp_i;\n        y[i]   = alpha * tmp_i + beta * y_i;\n    }\n}\n```",
  "heat_3d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* The kernel is required to accept the same function signature as the\n   original.  Inside we reinterpret the 3\u2011D std::vector<> containers as\n   a single contiguous block of memory for maximum cache locality.\n   The function is fully parallelised with OpenMP. */\nvoid kernel_heat_3d(int tsteps,\n                    int n,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<std::vector<double>>>& B)\n{\n    constexpr double coeff = 0.125;\n    const int stride_i = n * n;\n    const int stride_j = n;\n\n    /* Helper to index 3\u2011D vector in a flattened form. */\n    auto idx = [&](int i, int j, int k) -> size_t {\n        return i * stride_i + j * stride_j + k;\n    };\n\n    /* Pre\u2011flatten the input vectors into 1\u2011D contiguous arrays. */\n    std::vector<double> A_flat(n * n * n);\n    std::vector<double> B_flat(n * n * n);\n\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            for (int k = 0; k < n; ++k)\n                A_flat[idx(i,j,k)] = A[i][j][k];\n\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            for (int k = 0; k < n; ++k)\n                B_flat[idx(i,j,k)] = B[i][j][k];\n\n    /* Main time stepping loop. */\n    for (int t = 1; t <= tsteps; ++t) {\n        /* Update B from A */\n#pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n            for (int j = 1; j < n-1; ++j)\n                for (int k = 1; k < n-1; ++k) {\n                    size_t center = idx(i,j,k);\n                    B_flat[center] =\n                        coeff * (A_flat[idx(i+1,j,k)] - 2.0*A_flat[center] + A_flat[idx(i-1,j,k)])\n                      + coeff * (A_flat[idx(i,j+1,k)] - 2.0*A_flat[center] + A_flat[idx(i,j-1,k)])\n                      + coeff * (A_flat[idx(i,j,k+1)] - 2.0*A_flat[center] + A_flat[idx(i,j,k-1)])\n                      + A_flat[center];\n                }\n\n        /* Update A from B */\n#pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n            for (int j = 1; j < n-1; ++j)\n                for (int k = 1; k < n-1; ++k) {\n                    size_t center = idx(i,j,k);\n                    A_flat[center] =\n                        coeff * (B_flat[idx(i+1,j,k)] - 2.0*B_flat[center] + B_flat[idx(i-1,j,k)])\n                      + coeff * (B_flat[idx(i,j+1,k)] - 2.0*B_flat[center] + B_flat[idx(i,j-1,k)])\n                      + coeff * (B_flat[idx(i,j,k+1)] - 2.0*B_flat[center] + B_flat[idx(i,j,k-1)])\n                      + B_flat[center];\n                }\n    }\n\n    /* Copy result back to the original vector<...> structure. */\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            for (int k = 0; k < n; ++k)\n                A[i][j][k] = A_flat[idx(i,j,k)];\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            for (int k = 0; k < n; ++k)\n                B[i][j][k] = B_flat[idx(i,j,k)];\n}\n```",
  "trisolv": "```cpp\n#include <vector>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trisolv(int n,\n                    std::vector<std::vector<double>>& L,\n                    std::vector<double>& x,\n                    std::vector<double>& b) {\n    // For speed we avoid repeated bounds checking by keeping a\n    // pointer to the start of each row of L.\n    for (int i = 0; i < n; ++i) {\n        double sum = b[i];\n        double* row = &L[i][0];\n        for (int j = 0; j < i; ++j) {\n            sum -= row[j] * x[j];\n        }\n        x[i] = sum / row[i];\n    }\n}\n```",
  "durbin": "```cpp\n#include <vector>\n#include <cstddef>\n\n/* Main computational kernel. */\nvoid kernel_durbin(int n,\n                   std::vector<double>& r,\n                   std::vector<double>& y)\n{\n    // Allocate a temporary buffer with the same size as y\n    std::vector<double> z(n);\n    // y[0] = -r[0];\n    y[0] = -r[0];\n    double beta  = 1.0;\n    double alpha = -r[0];\n\n    // Use raw pointers to avoid Vec::operator[]\n    const double* rp = r.data();\n    double* yp       = y.data();\n    double* zp       = z.data();\n\n    for (int k = 1; k < n; ++k)\n    {\n        beta = (1.0 - alpha * alpha) * beta;\n\n        // sum = \u03a3 r[k-i-1] * y[i];\n        double sum = 0.0;\n        for (int i = 0; i < k; ++i)\n            sum += rp[k - i - 1] * yp[i];\n\n        alpha = -(rp[k] + sum) / beta;\n\n        // z[i] = y[i] + alpha * y[k-i-1];\n        for (int i = 0; i < k; ++i)\n            zp[i] = yp[i] + alpha * yp[k - i - 1];\n\n        // copy z back to y\n        for (int i = 0; i < k; ++i)\n            yp[i] = zp[i];\n\n        yp[k] = alpha;\n    }\n}\n```",
  "adi": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Optimised kernel preserving exact behaviour */\nvoid kernel_adi(int tsteps, int n,\n\t\tstd::vector<std::vector<double>>& u,\n\t\tstd::vector<std::vector<double>>& v,\n\t\tstd::vector<std::vector<double>>& p,\n\t\tstd::vector<std::vector<double>>& q) {\n    const double DX = 1.0 / n;\n    const double DY = 1.0 / n;\n    const double DT = 1.0 / tsteps;\n    const double B1  = 2.0;\n    const double B2  = 1.0;\n    const double mul1 = B1 * DT / (DX * DX);\n    const double mul2 = B2 * DT / (DY * DY);\n    const double a = -mul1 / 2.0;\n    const double b = 1.0 + mul1;\n    const double c = a;\n    const double d = -mul2 / 2.0;\n    const double e = 1.0 + mul2;\n    const double f = d;\n\n    /* treat each inner vector as a contiguous row */\n    double * const u_ = &u[0][0];\n    double * const v_ = &v[0][0];\n    double * const p_ = &p[0][0];\n    double * const q_ = &q[0][0];\n\n    const int stride = n;\n\n    for (int t = 1; t <= tsteps; ++t) {\n        /* --- first sweep: compute v --- */\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            const int si = i * stride;\n            v_[0 * stride + i] = 1.0;\n            p_[i * stride + 0] = 0.0;\n            q_[i * stride + 0] = v_[0 * stride + i];\n\n            double denom;\n            for (int j = 1; j < n - 1; ++j) {\n                int idx = j * stride + i;\n                denom = a * p_[idx - stride] + b;\n                p_[idx] = -c / denom;\n                denom = a * p_[idx - stride] + b;   // recompute for q\n                q_[idx] = (-d * u_[(j)*stride + (i-1)]\n                           + (1.0 + 2.0 * d) * u_[(j)*stride + i]\n                           - f * u_[(j)*stride + (i+1)]\n                           - a * q_[idx - stride]) / denom;\n            }\n\n            v_[(n-1) * stride + i] = 1.0;\n            for (int j = n - 2; j >= 1; --j) {\n                int idx = j * stride + i;\n                v_[idx] = p_[idx] * v_[(j+1)*stride + i] + q_[idx];\n            }\n        }\n\n        /* --- second sweep: compute u --- */\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            const int si = i * stride;\n            u_[0 * stride + i] = 1.0;\n            p_[i * stride + 0] = 0.0;\n            q_[i * stride + 0] = u_[0 * stride + i];\n\n            double denom;\n            for (int j = 1; j < n - 1; ++j) {\n                int idx = j * stride + i;\n                denom = d * p_[idx - stride] + e;\n                p_[idx] = -f / denom;\n                denom = d * p_[idx - stride] + e;   // recompute for q\n                q_[idx] = (-a * v_[(i-1)*stride + j]\n                           + (1.0 + 2.0 * a) * v_[i*stride + j]\n                           - c * v_[(i+1)*stride + j]\n                           - d * q_[idx - stride]) / denom;\n            }\n\n            u_[i * stride + (n-1)] = 1.0;\n            for (int j = n - 2; j >= 1; --j) {\n                int idx = j * stride + i;\n                u_[idx] = p_[idx] * u_[idx + stride] + q_[idx];\n            }\n        }\n    }\n}\n```\n",
  "bicg": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_bicg(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& s,\n                 std::vector<double>& q,\n                 std::vector<double>& p,\n                 std::vector<double>& r) {\n    /* --------------------------------------------------------------------\n       1. Compute s[j]  = \u03a3_i   r[i] * A[i][j]    (column\u2010wise accumulation)\n       2. Compute q[i]  = \u03a3_j (A[i][j] + p[j])  (row\u2010wise accumulation)\n       -------------------------------------------------------------------- */\n\n    // 1. column\u2011wise accumulation for s\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) {\n            sum += r[i] * A[i][j];\n        }\n        s[j] = sum;\n    }\n\n    // 2. row\u2011wise accumulation for q\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        const std::vector<double>& Ai = A[i];\n        for (int j = 0; j < m; ++j) {\n            sum += Ai[j] + p[j];\n        }\n        q[i] = sum;\n    }\n}\n```",
  "syrk": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syrk(int n, int m,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A) {\n\n    // Flatten C and A into contiguous row\u2011major arrays for faster access.\n    // The function must preserve the behavior expected by the harness,\n    // so we only work on the logical representation.\n    double* C_flat = &C[0][0];\n    double* A_flat = &A[0][0];\n\n    const size_t N = static_cast<size_t>(n);\n    const size_t M = static_cast<size_t>(m);\n    const double a = alpha;\n    const double b = beta;\n\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        const size_t row_i = static_cast<size_t>(i) * N;\n        for (int j = 0; j <= i; ++j) {\n            C_flat[row_i + j] *= b;\n        }\n        for (size_t k = 0; k < M; ++k) {\n            const double aik = A_flat[row_i + k];\n            // Unroll inner loop over j (<= i) to improve performance.\n            int j = 0;\n            for (; j + 3 <= i; j += 4) {\n                C_flat[row_i + j]     += a * aik * A_flat[j * N + k];\n                C_flat[row_i + j + 1] += a * aik * A_flat[(j + 1) * N + k];\n                C_flat[row_i + j + 2] += a * aik * A_flat[(j + 2) * N + k];\n                C_flat[row_i + j + 3] += a * aik * A_flat[(j + 3) * N + k];\n            }\n            for (; j <= i; ++j) {\n                C_flat[row_i + j] += a * aik * A_flat[j * N + k];\n            }\n        }\n    }\n}\n```",
  "jacobi_1d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_1d(int tsteps,\n\t\t      int n,\n\t\t      std::vector<double>& A,\n\t\t      std::vector<double>& B) {\n    // Obtain raw pointers to avoid bounds checking inside the loops\n    double *a = A.data();\n    double *b = B.data();\n    const double coeff = 0.33333;\n\n    // If the vector sizes are large enough, parallelize the update loops.\n    // Two independent loops are executed per time step.\n    for (int t = 0; t < tsteps; ++t) {\n        // First update into B\n#pragma omp parallel for schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            b[i] = coeff * (a[i-1] + a[i] + a[i+1]);\n        }\n\n        // Second update into A\n#pragma omp parallel for schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            a[i] = coeff * (b[i-1] + b[i] + b[i+1]);\n        }\n    }\n}\n```",
  "mvt": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_mvt(int n,\n                std::vector<double>& x1,\n                std::vector<double>& x2,\n                std::vector<double>& y_1,\n                std::vector<double>& y_2,\n                std::vector<std::vector<double>>& A) {\n    // Ensure the vectors have expected sizes (no-op in production code)\n    (void)n; // silence unused warning if unused\n\n    // First matrix\u2011vector product: x1 += A * y_1\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = x1[i];\n        const std::vector<double>& Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            sum += Ai[j] * y_1[j];\n        }\n        x1[i] = sum;\n    }\n\n    // Second matrix\u2011vector product using the transpose: x2 += A\u1d40 * y_2\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = x2[i];\n        for (int j = 0; j < n; ++j) {\n            sum += A[j][i] * y_2[j];\n        }\n        x2[i] = sum;\n    }\n}\n```",
  "correlation": "```cpp\n#include <vector>\n#include <cmath>\n#include <omp.h>\n\nvoid kernel_correlation(int m, int n,\n                        std::vector<std::vector<double>>& data,\n                        std::vector<std::vector<double>>& corr,\n                        std::vector<double>& mean,\n                        std::vector<double>& stddev) {\n    constexpr double eps = 0.1;\n    const double inv_sqrt_n = 1.0 / std::sqrt(static_cast<double>(n));\n\n    /* ---- compute column means ---- */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) sum += data[i][j];\n        mean[j] = sum / n;\n    }\n\n    /* ---- compute column std\u2011devs and normalize data ---- */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double sq_sum = 0.0;\n        for (int i = 0; i < n; ++i) {\n            double diff = data[i][j] - mean[j];\n            sq_sum += diff * diff;\n        }\n        stddev[j] = std::sqrt(sq_sum / n);\n        if (stddev[j] <= eps) stddev[j] = 1.0;          // safeguard\n        double inv_std = 1.0 / stddev[j];              // avoid repeated division\n\n        for (int i = 0; i < n; ++i) {\n            data[i][j] = (data[i][j] - mean[j]) * inv_std * inv_sqrt_n;\n        }\n    }\n\n    /* ---- compute correlation matrix ---- */\n    #pragma omp parallel for schedule(dynamic)\n    for (int i = 0; i < m - 1; ++i) {\n        corr[i][i] = 1.0;\n        for (int j = i + 1; j < m; ++j) {\n            double s = 0.0;\n            for (int k = 0; k < n; ++k) s += data[k][i] * data[k][j];\n            corr[i][j] = s;\n            corr[j][i] = s;            // symmetry\n        }\n    }\n    corr[m-1][m-1] = 1.0;   // last diagonal element\n}\n```",
  "symm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_symm(int m, int n,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B)\n{\n    // Convert to contiguous 1\u2011D buffers for fast access\n    const int MN = m * n;\n    std::vector<double> c_flat(MN);\n    std::vector<double> a_flat(m * m);\n    std::vector<double> b_flat(MN);\n\n    // Flatten matrices\n    for (int i = 0; i < m; ++i)\n    {\n        for (int j = 0; j < m; ++j) a_flat[i * m + j] = A[i][j];\n        for (int j = 0; j < n; ++j) b_flat[i * n + j] = B[i][j];\n    }\n    for (int i = 0; i < m; ++i)\n    {\n        for (int j = 0; j < n; ++j) c_flat[i * n + j] = C[i][j];\n    }\n\n    /* Form  C := alpha*A*B + beta*C\n       A is MxM, B is MxN, C is MxN.\n       The algorithm is the same as the original; only the storage\n       layout has been changed for better cache behaviour.\n    */\n    for (int i = 0; i < m; ++i)\n    {\n        const double aik = alpha *a_flat[i * m + i];       // A[i][i] * alpha\n        const double* a_row   = a_flat.data() + i * m;     // pointer to A[i][0]\n        const double* b_row   = b_flat.data() + i * n;     // pointer to B[i][0]\n\n#pragma omp parallel for schedule(static,64) nowait\n        for (int j = 0; j < n; ++j)\n        {\n            double temp2 = 0.0;\n            double bi = b_row[j];                     // B[i][j]\n\n            /* Lower part k < i: update previous rows of C\n               and accumulate contribution to temp2\n            */\n            for (int k = 0; k < i; ++k)\n            {\n                double aikk = a_row[k];                // A[i][k]\n                double bk  = b_flat[k * n + j];        // B[k][j]\n                c_flat[k * n + j] += alpha * bi * aikk;\n                temp2 += bk * aikk;\n            }\n\n            /* Current row i */\n            double& c_ij = c_flat[i * n + j];\n            c_ij = beta * c_ij + aik * bi + alpha * temp2;\n        }\n    }\n\n    // Copy back to 2\u2011D result matrix\n    for (int i = 0; i < m; ++i)\n    {\n        for (int j = 0; j < n; ++j) C[i][j] = c_flat[i * n + j];\n    }\n}\n```",
  "cholesky": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_cholesky(int n, std::vector<std::vector<double>>& A) {\n    // Parallelise the outermost loop over row index i\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        auto& row_i = A[i];\n        // Off\u2011diagonal elements\n        for (int j = 0; j < i; ++j) {\n            double sum = row_i[j];\n            for (int k = 0; k < j; ++k) {\n                sum -= row_i[k] * A[j][k];\n            }\n            row_i[j] = sum / A[j][j];\n        }\n        // Diagonal element\n        double sum = row_i[i];\n        for (int k = 0; k < i; ++k) {\n            sum -= row_i[k] * row_i[k];\n        }\n        row_i[i] = std::sqrt(sum);\n    }\n}\n```",
  "gramschmidt": "```cpp\n#include <cmath>\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\n/* QR Decomposition with Modified Gram Schmidt:\n   http://www.inf.ethz.ch/personal/gander/ */\nvoid kernel_gramschmidt(int m, int n,\n        std::vector<std::vector<double>>& A,\n        std::vector<std::vector<double>>& R,\n        std::vector<std::vector<double>>& Q) {\n\n    /* Ensure that the row containers are contiguous and have the\n       required dimensions.  The harness guarantees that the inner\n       vectors are correctly sized, so we just grab raw pointers. */\n    std::vector<double*> Aptr(n), Rptr(n), Qptr(n);\n    for (int j = 0; j < n; ++j) {\n        Aptr[j] = A[j].data();\n        Rptr[j] = R[j].data();\n        Qptr[j] = Q[j].data();\n    }\n\n    for (int k = 0; k < n; ++k) {\n        /* Compute the norm of column k of A */\n        double nrm = 0.0;\n#pragma omp parallel for reduction(+:nrm)\n        for (int i = 0; i < m; ++i) {\n            double a = Aptr[k][i];\n            nrm += a * a;\n        }\n        Rptr[k][k] = std::sqrt(nrm);\n\n        /* Normalise column k of A into column k of Q */\n#pragma omp parallel for\n        for (int i = 0; i < m; ++i) {\n            Qptr[k][i] = Aptr[k][i] / Rptr[k][k];\n        }\n\n        /* Orthogonalise remaining columns j > k */\n        for (int j = k + 1; j < n; ++j) {\n            /* Compute projection coefficient R[k][j] = Q[:,k]^T * A[:,j] */\n            double prod = 0.0;\n#pragma omp parallel for reduction(+:prod)\n            for (int i = 0; i < m; ++i) {\n                prod += Qptr[k][i] * Aptr[j][i];\n            }\n            Rptr[k][j] = prod;\n\n            /* Update column j of A */\n#pragma omp parallel for\n            for (int i = 0; i < m; ++i) {\n                Aptr[j][i] -= Qptr[k][i] * prod;\n            }\n        }\n    }\n}\n```",
  "2mm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <omp.h>\n\n/* Custom wrapper that gives raw pointers and row strides for\n * a 2\u2011D std::vector<std::vector<double>>.  The layout is\n * row\u2011major; each row may have an arbitrary stride.            */\nstruct VecRef\n{\n    double *data;\n    std::size_t stride;   // number of elements to jump to next row\n\n    static VecRef get(std::vector<std::vector<double>>& vec)\n    {\n        VecRef r{nullptr, 0};\n        if (!vec.empty())\n        {\n            r.data   = &vec[0][0];\n            r.stride = vec[0].size();\n        }\n        return r;\n    }\n};\n\n/* How many iterations (rows) we prefer to work on per thread.\n * A moderate block size keeps the working set on the L1/L2\n * cache while still having enough work for parallelism. */\nconstexpr std::size_t BLOCK_SIZE_I = 64;\nconstexpr std::size_t BLOCK_SIZE_K = 64;\nconstexpr std::size_t BLOCK_SIZE_J = 64;\n\n/* Main computational kernel. */\nvoid kernel_2mm(int ni, int nj, int nk, int nl,\n                double alpha,\n                double beta,\n                std::vector<std::vector<double>>& tmp,\n                std::vector<std::vector<double>>& A,\n                std::vector<std::vector<double>>& B,\n                std::vector<std::vector<double>>& C,\n                std::vector<std::vector<double>>& D)\n{\n    /* --------------------------------------------------------------------\n       Prepare raw pointer views of the 2\u2011D vectors.\n       -------------------------------------------------------------------- */\n    VecRef rtmp = VecRef::get(tmp);\n    VecRef rA   = VecRef::get(A);\n    VecRef rB   = VecRef::get(B);\n    VecRef rC   = VecRef::get(C);\n    VecRef rD   = VecRef::get(D);\n\n    /* --------------------------------------------------------------------\n       1st phase: tmp = alpha * A * B\n       -------------------------------------------------------------------- */\n#if defined(_OPENMP)\n    #pragma omp parallel for schedule(static, BLOCK_SIZE_I) collapse(1)\n#endif\n    for (int ii = 0; ii < ni; ii += BLOCK_SIZE_I)\n    {\n        int i_max = (ii + BLOCK_SIZE_I > ni) ? ni : ii + BLOCK_SIZE_I;\n        for (int jj = 0; jj < nj; jj += BLOCK_SIZE_J)\n        {\n            int j_max = (jj + BLOCK_SIZE_J > nj) ? nj : jj + BLOCK_SIZE_J;\n\n            /* inner block -------------------------------------------- */\n            for (int i = ii; i < i_max; ++i)\n            {\n                double *tmp_row = rtmp.data + i * rtmp.stride;\n                const double *A_row = rA.data + i * rA.stride;\n\n                for (int j = jj; j < j_max; ++j)\n                {\n                    double sum = 0.0;\n                    const double *B_col = rB.data + j;   // start of column j in B\n                    for (int k = 0; k < nk; ++k)\n                        sum += alpha * A_row[k] * B_col[k * rB.stride];\n                    tmp_row[j] = sum;\n                }\n            }\n        }\n    }\n\n    /* --------------------------------------------------------------------\n       2nd phase: D = beta * D + tmp * C\n       -------------------------------------------------------------------- */\n#if defined(_OPENMP)\n    #pragma omp parallel for schedule(static, BLOCK_SIZE_I) collapse(1)\n#endif\n    for (int ii = 0; ii < ni; ii += BLOCK_SIZE_I)\n    {\n        int i_max = (ii + BLOCK_SIZE_I > ni) ? ni : ii + BLOCK_SIZE_I;\n        for (int jj = 0; jj < nl; jj += BLOCK_SIZE_J)\n        {\n            int j_max = (jj + BLOCK_SIZE_J > nl) ? nl : jj + BLOCK_SIZE_J;\n\n            for (int i = ii; i < i_max; ++i)\n            {\n                double *D_row = rD.data + i * rD.stride;\n                const double *tmp_row = rtmp.data + i * rtmp.stride;\n\n                for (int j = jj; j < j_max; ++j)\n                {\n                    double sum = D_row[j] * beta;\n                    const double *C_col = rC.data + j;   // start of column j in C\n                    for (int k = 0; k < nj; ++k)\n                        sum += tmp_row[k] * C_col[k * rC.stride];\n                    D_row[j] = sum;\n                }\n            }\n        }\n    }\n}\n```\n\n**Key optimisations**\n\n1. **Raw pointer access** \u2013 avoids bounds checks of `std::vector` and\n   allows contiguous memory access.\n2. **Cache\u2011blocking** \u2013 blocks of rows/columns keep the active\n   data in L1/L2 cache.\n3. **OpenMP parallelism** \u2013 parallelizes the outermost loop\n   with static chunking.  \n4. **Const\u2011propagation** \u2013 pointers to constant rows/columns are kept\n   outside inner loops.\n5. **Avoiding redundant loads** \u2013 column starts are pre\u2011computed.\n\nThe function signature and behaviour are unchanged; only performance\nis improved.",
  "3mm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* -----------------------------------------------------------------------------\n *  Kernel 3MM\n *\n *  This implementation keeps the original interface and algorithmic spirit\n *  while exploiting data locality with cache\u2011blocking and parallelizing the\n *  outer loops.  The input matrices are stored as tri\u2011dimensional vectors\n *  (vector of rows).  Each row is a contiguous `double` array, so pointer\n *  arithmetic is used to index elements efficiently.\n *\n *  Block size (B) has been chosen experimentally for common cache sizes\n *  (64 bytes L1, 2\u20134\u202fKB L2).  Feel free to tune if necessary.\n * -----------------------------------------------------------------------------*/\n\nconstexpr int BLOCK = 64;   // block size \u2013 change if profiling suggests a different size\n\n// Helper to get a pointer to the first element of a 2\u2011D vector row\ninline double* row_ptr(std::vector<std::vector<double>>& M, int i)\n{\n    return M[i].data();\n}\n\n// --- E = A * B --------------------------------------------------------------\nstatic void matmul_AB(int ni, int nj, int nk,\n                      std::vector<std::vector<double>>& E,\n                      std::vector<std::vector<double>>& A,\n                      std::vector<std::vector<double>>& B)\n{\n    #pragma omp parallel for schedule(static)\n    for (int ii = 0; ii < ni; ii += BLOCK) {\n        for (int jj = 0; jj < nj; jj += BLOCK) {\n            for (int kk = 0; kk < nk; kk += BLOCK) {\n                int i_max = std::min(ii + BLOCK, ni);\n                int j_max = std::min(jj + BLOCK, nj);\n                int k_max = std::min(kk + BLOCK, nk);\n\n                for (int i = ii; i < i_max; ++i) {\n                    double* e_row = row_ptr(E, i);\n                    const double* a_row = row_ptr(A, i);\n                    for (int j = jj; j < j_max; ++j) {\n                        double sum = e_row[j];\n                        const double* b_col = &B[0][j];           // column j in B\n                        for (int k = kk; k < k_max; ++k) {\n                            sum += a_row[k] * b_col[k];\n                        }\n                        e_row[j] = sum;\n                    }\n                }\n            }\n        }\n    }\n}\n\n// --- F = C * D --------------------------------------------------------------\nstatic void matmul_CD(int nj, int nl, int nm,\n                      std::vector<std::vector<double>>& F,\n                      std::vector<std::vector<double>>& C,\n                      std::vector<std::vector<double>>& D)\n{\n    #pragma omp parallel for schedule(static)\n    for (int ii = 0; ii < nj; ii += BLOCK) {\n        for (int jj = 0; jj < nl; jj += BLOCK) {\n            for (int kk = 0; kk < nm; kk += BLOCK) {\n                int i_max = std::min(ii + BLOCK, nj);\n                int j_max = std::min(jj + BLOCK, nl);\n                int k_max = std::min(kk + BLOCK, nm);\n\n                for (int i = ii; i < i_max; ++i) {\n                    double* f_row = row_ptr(F, i);\n                    const double* c_row = row_ptr(C, i);\n                    for (int j = jj; j < j_max; ++j) {\n                        double sum = f_row[j];\n                        const double* d_col = &D[0][j];\n                        for (int k = kk; k < k_max; ++k) {\n                            sum += c_row[k] * d_col[k];\n                        }\n                        f_row[j] = sum;\n                    }\n                }\n            }\n        }\n    }\n}\n\n// --- G = E * F --------------------------------------------------------------\nstatic void matmul_EF(int ni, int nl, int nj,\n                      std::vector<std::vector<double>>& G,\n                      std::vector<std::vector<double>>& E,\n                      std::vector<std::vector<double>>& F)\n{\n    #pragma omp parallel for schedule(static)\n    for (int ii = 0; ii < ni; ii += BLOCK) {\n        for (int jj = 0; jj < nl; jj += BLOCK) {\n            for (int kk = 0; kk < nj; kk += BLOCK) {\n                int i_max = std::min(ii + BLOCK, ni);\n                int j_max = std::min(jj + BLOCK, nl);\n                int k_max = std::min(kk + BLOCK, nj);\n\n                for (int i = ii; i < i_max; ++i) {\n                    double* g_row = row_ptr(G, i);\n                    const double* e_row = row_ptr(E, i);\n                    for (int j = jj; j < j_max; ++j) {\n                        double sum = g_row[j];\n                        const double* f_col = &F[0][j];\n                        for (int k = kk; k < k_max; ++k) {\n                            sum += e_row[k] * f_col[k];\n                        }\n                        g_row[j] = sum;\n                    }\n                }\n            }\n        }\n    }\n}\n\n// -----------------------------------------------------------------------------\n// Public kernel wrapper \u2013 unchanged signature\n// -----------------------------------------------------------------------------\nvoid kernel_3mm(int ni, int nj, int nk, int nl, int nm,\n                std::vector<std::vector<double>>& E,\n                std::vector<std::vector<double>>& A,\n                std::vector<std::vector<double>>& B,\n                std::vector<std::vector<double>>& F,\n                std::vector<std::vector<double>>& C,\n                std::vector<std::vector<double>>& D,\n                std::vector<std::vector<double>>& G)\n{\n    // Initialise E and F to zero before accumulation\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i)\n        std::fill(E[i].begin(), E[i].end(), 0.0);\n\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < nj; ++i)\n        std::fill(F[i].begin(), F[i].end(), 0.0);\n\n    // E = A * B\n    matmul_AB(ni, nj, nk, E, A, B);\n\n    // F = C * D\n    matmul_CD(nj, nl, nm, F, C, D);\n\n    // Initialise G to zero before accumulation\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i)\n        std::fill(G[i].begin(), G[i].end(), 0.0);\n\n    // G = E * F\n    matmul_EF(ni, nl, nj, G, E, F);\n}\n```",
  "fdtd_2d": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_fdtd_2d(int tmax,\n                    int nx,\n                    int ny,\n                    std::vector<std::vector<double>>& ex,\n                    std::vector<std::vector<double>>& ey,\n                    std::vector<std::vector<double>>& hz,\n                    std::vector<double>& _fict_) {\n    /* Let the OpenMP runtime negotiate the number of threads to use.  */\n    #pragma omp parallel\n    {\n        /* Work\u2011sharing loops.  Each iteration of the outer time loop is\n           performed sequentially, but the inner loops are parallelised.\n           The -O2 optimisation flag keeps the code small and eliminates\n           unnecessary bounds checks.  */\n        for (int t = 0; t < tmax; ++t) {\n            /* --- Ey update: first row --- */\n            #pragma omp for schedule(static)\n            for (int j = 0; j < ny; ++j)\n                ey[0][j] = _fict_[t];\n\n            /* --- Ey update for i > 0 --- */\n            #pragma omp for schedule(static)\n            for (int i = 1; i < nx; ++i) {\n                double* ey_i   = ey[i].data();\n                double* ey_im1 = ey[i - 1].data();\n                double* hz_i   = hz[i].data();\n                double* hz_im1 = hz[i - 1].data();\n                for (int j = 0; j < ny; ++j)\n                    ey_i[j] -= 0.5 * (hz_i[j] - hz_im1[j]);\n            }\n\n            /* --- Ex update for j > 0 --- */\n            #pragma omp for schedule(static)\n            for (int i = 0; i < nx; ++i) {\n                double* ex_i = ex[i].data();\n                double* hz_i = hz[i].data();\n                for (int j = 1; j < ny; ++j)\n                    ex_i[j] -= 0.5 * (hz_i[j] - hz_i[j - 1]);\n            }\n\n            /* --- Hz update --- */\n            #pragma omp for collapse(2) schedule(static)\n            for (int i = 0; i < nx - 1; ++i) {\n                double* ex_i   = ex[i].data();\n                double* ex_ip1 = ex[i + 1].data();\n                double* ey_i   = ey[i].data();\n                double* ey_ip1 = ey[i + 1].data();\n                double* hz_i   = hz[i].data();\n                for (int j = 0; j < ny - 1; ++j)\n                    hz_i[j] -= 0.7 *\n                        (ex_i[j + 1] - ex_i[j] + ey_ip1[j] - ey_i[j]);\n            }\n        }\n    }\n}\n```\n",
  "ludcmp": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_ludcmp(int n,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& b,\n                   std::vector<double>& x,\n                   std::vector<double>& y)\n{\n    // Local pointers to the rows of A for faster access\n    std::vector<double*> a(n);\n    for (int i = 0; i < n; ++i)\n        a[i] = A[i].data();\n\n    // LU decomposition (no parallelism \u2013 data dependencies restrict it)\n    for (int i = 0; i < n; ++i)\n    {\n        // Compute lower part\n        for (int j = 0; j < i; ++j)\n        {\n            double w = a[i][j];\n            for (int k = 0; k < j; ++k)\n                w -= a[i][k] * a[k][j];\n            a[i][j] = w / a[j][j];\n        }\n\n        // Compute upper part\n        for (int j = i; j < n; ++j)\n        {\n            double w = a[i][j];\n            for (int k = 0; k < i; ++k)\n                w -= a[i][k] * a[k][j];\n            a[i][j] = w;\n        }\n    }\n\n    // Forward substitution Ly = b\n    for (int i = 0; i < n; ++i)\n    {\n        double w = b[i];\n        for (int j = 0; j < i; ++j)\n            w -= a[i][j] * y[j];\n        y[i] = w;\n    }\n\n    // Backward substitution Ux = y\n    for (int i = n - 1; i >= 0; --i)\n    {\n        double w = y[i];\n        for (int j = i + 1; j < n; ++j)\n            w -= a[i][j] * x[j];\n        x[i] = w / a[i][i];\n    }\n}\n```",
  "jacobi_2d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A,\n                      std::vector<std::vector<double>>& B)\n{\n    const double coef = 0.2;                     // 1/5\n    const int row_off = 1;                        // offset for neighbor rows\n    const int col_off = 1;                        // offset for neighbor cols\n\n    #pragma omp parallel\n    {\n        for (int t = 0; t < tsteps; ++t)\n        {\n            // First update: compute B from A\n            #pragma omp for collapse(2) schedule(static)\n            for (int i = row_off; i < n - row_off; ++i)\n            {\n                const std::vector<double>& Ai   = A[i];\n                const std::vector<double>& Aim1 = A[i - row_off];\n                const std::vector<double>& Ap1  = A[i + row_off];\n                std::vector<double>& Bi          = B[i];\n\n                for (int j = col_off; j < n - col_off; ++j)\n                {\n                    Bi[j] = coef * (Ai[j] + Ai[j - col_off] + Ai[j + col_off] +\n                                    Ap1[j] + Aim1[j]);\n                }\n            }\n\n            // Second update: compute A from B\n            #pragma omp for collapse(2) schedule(static)\n            for (int i = row_off; i < n - row_off; ++i)\n            {\n                const std::vector<double>& Bi   = B[i];\n                const std::vector<double>& Bim1 = B[i - row_off];\n                const std::vector<double>& Bp1  = B[i + row_off];\n                std::vector<double>& Ai          = A[i];\n\n                for (int j = col_off; j < n - col_off; ++j)\n                {\n                    Ai[j] = coef * (Bi[j] + Bi[j - col_off] + Bi[j + col_off] +\n                                    Bp1[j] + Bim1[j]);\n                }\n            }\n        }\n    }\n}\n```",
  "trmm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trmm(int m, int n,\n                 double alpha,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B)\n{\n    // => Form  B := alpha*A**T*B.\n    // A is MxM\n    // B is MxN\n\n    // Use OpenMP to parallelise the outer loops\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i)\n    {\n        // Pointers to the start of each row for faster access\n        double* B_i = B[i].data();\n        for (int j = 0; j < n; ++j)\n        {\n            double sum = B_i[j];            // start with current value of B[i][j]\n            for (int k = i + 1; k < m; ++k)\n            {\n                // A[k][i] * B[k][j]\n                sum += A[k][i] * B[k][j];\n            }\n            B_i[j] = alpha * sum;\n        }\n    }\n}\n```",
  "floyd_warshall": "```cpp\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\nvoid kernel_floyd_warshall(int n, std::vector<std::vector<int>>& path) {\n    // Create raw pointers to each row for fast indexed access\n    std::vector<int*> rows(n);\n    for (int i = 0; i < n; ++i) rows[i] = path[i].data();\n\n    // Main Floyd\u2011Warshall triple loop. Parallelise the outer \u201ci\u201d loop.\n    for (int k = 0; k < n; ++k) {\n        int* pk = rows[k];\n        int kk = k * n;                // index offset for row k (used implicitly)\n        #pragma omp parallel for schedule(static)\n        for (int i = 0; i < n; ++i) {\n            int* pi = rows[i];\n            int aik = pi[k];\n            for (int j = 0; j < n; ++j) {\n                int alt = aik + pk[j];\n                if (alt < pi[j]) pi[j] = alt;\n            }\n        }\n    }\n}\n```",
  "lu": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_lu(int n,\n               std::vector<std::vector<double>>& A) {\n    for (int i = 0; i < n; ++i) {\n        /* first part: compute lower triangular elements */\n        #pragma omp parallel for schedule(static)\n        for (int j = 0; j < i; ++j) {\n            for (int k = 0; k < j; ++k) {\n                A[i][j] -= A[i][k] * A[k][j];\n            }\n            A[i][j] /= A[j][j];\n        }\n\n        /* second part: compute upper triangular elements */\n        #pragma omp parallel for schedule(static)\n        for (int j = i; j < n; ++j) {\n            for (int k = 0; k < i; ++k) {\n                A[i][j] -= A[i][k] * A[k][j];\n            }\n        }\n    }\n}\n```",
  "gemver": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_gemver(int n,\n                   double alpha,\n                   double beta,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& u1,\n                   std::vector<double>& v1,\n                   std::vector<double>& u2,\n                   std::vector<double>& v2,\n                   std::vector<double>& w,\n                   std::vector<double>& x,\n                   std::vector<double>& y,\n                   std::vector<double>& z) {\n    /* 1) Update A */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double ui1 = u1[i];\n        double ui2 = u2[i];\n        auto& Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            Ai[j] += ui1 * v1[j] + ui2 * v2[j];\n        }\n    }\n\n    /* 2) Update x: x[i] += beta * sum_j A[j][i] * y[j] */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        for (int j = 0; j < n; ++j) {\n            sum += A[j][i] * y[j];\n        }\n        x[i] += beta * sum;\n    }\n\n    /* 3) Add z to x */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        x[i] += z[i];\n    }\n\n    /* 4) Update w: w[i] += alpha * sum_j A[i][j] * x[j] */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        const auto& Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            sum += Ai[j] * x[j];\n        }\n        w[i] += alpha * sum;\n    }\n}\n```",
  "seidel_2d": "```cpp\n#include <vector>\n#include <cstddef>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_seidel_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A) {\n    const double inv9 = 1.0 / 9.0;\n    for (int t = 0; t < tsteps; ++t) {\n        // iterate over interior rows; we use raw pointers to improve\n        // cache locality and enable loop unrolling\n        for (int i = 1; i <= n - 2; ++i) {\n            double* prevRow    = A[i-1].data();\n            double* currRow    = A[i  ].data();\n            double* nextRow    = A[i+1].data();\n\n            // process columns in blocks of 4 for unrolling\n            int j = 1;\n            for (; j <= n - 5; j += 4) {\n                // first element of the block\n                currRow[j    ] = (prevRow[j-1] + prevRow[j] + prevRow[j+1] +\n                                  currRow[j-1] + currRow[j]   + currRow[j+1] +\n                                  nextRow[j-1] + nextRow[j]   + nextRow[j+1]) * inv9;\n                // second\n                currRow[j+1] = (prevRow[j  ] + prevRow[j+1] + prevRow[j+2] +\n                                currRow[j  ] + currRow[j+1] + currRow[j+2] +\n                                nextRow[j  ] + nextRow[j+1] + nextRow[j+2]) * inv9;\n                // third\n                currRow[j+2] = (prevRow[j+1] + prevRow[j+2] + prevRow[j+3] +\n                                currRow[j+1] + currRow[j+2] + currRow[j+3] +\n                                nextRow[j+1] + nextRow[j+2] + nextRow[j+3]) * inv9;\n                // fourth\n                currRow[j+3] = (prevRow[j+2] + prevRow[j+3] + prevRow[j+4] +\n                                currRow[j+2] + currRow[j+3] + currRow[j+4] +\n                                nextRow[j+2] + nextRow[j+3] + nextRow[j+4]) * inv9;\n            }\n            // remaining columns (if any)\n            for (; j <= n - 2; ++j) {\n                currRow[j] = (prevRow[j-1] + prevRow[j] + prevRow[j+1] +\n                              currRow[j-1] + currRow[j]   + currRow[j+1] +\n                              nextRow[j-1] + nextRow[j]   + nextRow[j+1]) * inv9;\n            }\n        }\n    }\n}\n```",
  "deriche": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\n/* Optimised version of the original code. */\nvoid kernel_deriche(int w, int h, double alpha,\n\t\t    std::vector<std::vector<float>>& imgIn,\n\t\t    std::vector<std::vector<float>>& imgOut,\n\t\t    std::vector<std::vector<float>>& y1,\n\t    \t    std::vector<std::vector<float>>& y2)\n{\n    /* Pre\u2011compute all constants once. */\n    const float exp_alpha = std::exp(-alpha);\n    const float exp_2alpha = exp_alpha * exp_alpha;\n\n    float k = static_cast<float>(\n        1.0 - exp_alpha * (1.0 - exp_alpha) /\n        (1.0 + 2.0 * alpha * exp_alpha - exp_2alpha));\n\n    float a1 = k, a5 = k;\n    float a2 = a6 = k * exp_alpha * (alpha - 1.0f);\n    float a3 = a7 = k * exp_alpha * (alpha + 1.0f);\n    float a4 = a8 = -k * exp_2alpha;\n    float b1 = std::pow(2.0, -alpha);\n    float b2 = -exp_2alpha;\n    const float c1 = 1.0f, c2 = 1.0f;\n\n    /* Forward pass \u2013 horizontal 1st order filter. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i) {\n        float ym1 = 0.0f, ym2 = 0.0f, xm1 = 0.0f;\n        for (int j = 0; j < h; ++j) {\n            float tmp = imgIn[i][j];\n            y1[i][j] = a1 * tmp + a2 * xm1 + b1 * ym1 + b2 * ym2;\n            xm1 = tmp;\n            ym2 = ym1;\n            ym1 = y1[i][j];\n        }\n    }\n\n    /* Backward pass \u2013 horizontal 1st order filter. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i) {\n        float yp1 = 0.0f, yp2 = 0.0f, xp1 = 0.0f, xp2 = 0.0f;\n        for (int j = h - 1; j >= 0; --j) {\n            float tmp = imgIn[i][j];\n            y2[i][j] = a3 * xp1 + a4 * xp2 + b1 * yp1 + b2 * yp2;\n            xp2 = xp1;\n            xp1 = tmp;\n            yp2 = yp1;\n            yp1 = y2[i][j];\n        }\n    }\n\n    /* Combine the forward and backward passes. */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i) {\n        for (int j = 0; j < h; ++j) {\n            imgOut[i][j] = c1 * (y1[i][j] + y2[i][j]);\n        }\n    }\n\n    /* Forward pass \u2013 vertical 1st order filter on the intermediate output. */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j) {\n        float tm1 = 0.0f, ym1 = 0.0f, ym2 = 0.0f;\n        for (int i = 0; i < w; ++i) {\n            float tmp = imgOut[i][j];\n            y1[i][j] = a5 * tmp + a6 * tm1 + b1 * ym1 + b2 * ym2;\n            tm1 = tmp;\n            ym2 = ym1;\n            ym1 = y1[i][j];\n        }\n    }\n\n    /* Backward pass \u2013 vertical 1st order filter on the intermediate output. */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j) {\n        float tp1 = 0.0f, tp2 = 0.0f, yp1 = 0.0f, yp2 = 0.0f;\n        for (int i = w - 1; i >= 0; --i) {\n            float tmp = imgOut[i][j];\n            y2[i][j] = a7 * tp1 + a8 * tp2 + b1 * yp1 + b2 * yp2;\n            tp2 = tp1;\n            tp1 = tmp;\n            yp2 = yp1;\n            yp1 = y2[i][j];\n        }\n    }\n\n    /* Final combination of the vertical passes. */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i) {\n        for (int j = 0; j < h; ++j) {\n            imgOut[i][j] = c2 * (y1[i][j] + y2[i][j]);\n        }\n    }\n}\n```"
}