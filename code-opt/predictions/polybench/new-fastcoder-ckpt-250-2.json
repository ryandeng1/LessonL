{
  "doitgen": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Optimised kernel \u2013 keeps the original semantics\n   but uses contiguous memory, restrict pointers,\n   and OpenMP for parallelism.                              */\nvoid kernel_doitgen(int nr, int nq, int np,\n\t\t    std::vector<std::vector<std::vector<double>>>& A,\n\t\t    std::vector<std::vector<double>>& C4,\n\t\t    std::vector<double>& sum)\n{\n    // Allocate a local temp buffer once (np <= reasonable).\n    std::vector<double> tmp(np);\n\n#pragma omp parallel for collapse(2) schedule(static)\n    for (int r = 0; r < nr; ++r) {\n        for (int q = 0; q < nq; ++q) {\n            double* A_rq = A[r][q].data();           // pointer to A[r][q][*]\n            const double* C4_col = C4[0].data();     // will index manually\n\n            // Each thread keeps its own tmp buffer inside the loop\n            std::vector<double> local_tmp(np, 0.0);\n\n            for (int p = 0; p < np; ++p) {\n                double acc = 0.0;\n                for (int s = 0; s < np; ++s) {\n                    acc += A_rq[s] * C4[s][p];\n                }\n                local_tmp[p] = acc;\n            }\n\n            // Write back results\n            for (int p = 0; p < np; ++p) {\n                A_rq[p] = local_tmp[p];\n            }\n        }\n    }\n}\n```",
  "syr2k": "```cpp\n#include <vector>\n#include <cstddef>\n#include <cstdio>\n#include <omp.h>\n\n/* Helper to get a pointer to the start of each sub\u2011vector in a row\u2011major flat matrix. */\ninline double* row_ptr(std::vector<std::vector<double>>& mat, std::size_t row) {\n    return mat[row].data();\n}\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syr2k(int n, int m,\n                  double alpha,\n                  double beta,\n                  std::vector<std::vector<double>>& C,\n                  std::vector<std::vector<double>>& A,\n                  std::vector<std::vector<double>>& B)\n{\n    /* Parallelise the outermost loop \u2013 each iteration works on a distinct row of C. */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double* c_row = row_ptr(C, i);\n        double* a_row = row_ptr(A, i);\n        double* b_row = row_ptr(B, i);\n\n        /* 1. Scale the lower triangular part of C(i,:) by beta. */\n        for (int j = 0; j <= i; ++j)\n            c_row[j] *= beta;\n\n        /* 2. Accumulate the symmetric rank\u20112k update. */\n        for (int k = 0; k < m; ++k) {\n            double aik_alpha = alpha * A[k][i];          // Aik * alpha\n            double bik_alpha = alpha * B[k][i];          // Bik * alpha\n            double* a_col = row_ptr(A, k);\n            double* b_col = row_ptr(B, k);\n\n            for (int j = 0; j <= i; ++j) {\n                /* C(i,j) += A(j,k)*alpha*B(i,k) + B(j,k)*alpha*A(i,k); */\n                c_row[j] += a_col[j] * bik_alpha + b_col[j] * aik_alpha;\n            }\n        }\n    }\n}\n```",
  "heat_3d": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_heat_3d(int tsteps,\n                    int n,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<std::vector<double>>>& B)\n{\n    constexpr double coef = 0.125;\n\n    for (int t = 1; t <= tsteps; ++t)\n    {\n        /* -------------------------------------------------------------------- */\n        /* First half\u2013step: update B from A                                    */\n        /* -------------------------------------------------------------------- */\n        #pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n            for (int j = 1; j < n-1; ++j)\n                for (int k = 1; k < n-1; ++k)\n                {\n                    double v = A[i][j][k];\n                    double sum = A[i+1][j][k] + A[i-1][j][k]\n                                + A[i][j+1][k] + A[i][j-1][k]\n                                + A[i][j][k+1] + A[i][j][k-1];\n                    B[i][j][k] = coef * (sum - 6.0 * v) + v;\n                }\n\n        /* -------------------------------------------------------------------- */\n        /* Second half\u2013step: update A from B                                    */\n        /* -------------------------------------------------------------------- */\n        #pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n            for (int j = 1; j < n-1; ++j)\n                for (int k = 1; k < n-1; ++k)\n                {\n                    double v = B[i][j][k];\n                    double sum = B[i+1][j][k] + B[i-1][j][k]\n                                + B[i][j+1][k] + B[i][j-1][k]\n                                + B[i][j][k+1] + B[i][j][k-1];\n                    A[i][j][k] = coef * (sum - 6.0 * v) + v;\n                }\n    }\n}\n```",
  "atax": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_atax(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& x,\n                 std::vector<double>& y,\n                 std::vector<double>& tmp) {\n\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) y[i] = 0.0;\n\n    /* Compute tmp[i] = A[i] * x   (row\u2011wise dot product)   */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        double sum = 0.0;\n        double* Ai = A[i].data();          // pointer to the i\u2011th row\n        for (int j = 0; j < n; ++j)        // manual loop unroll may help\n            sum += Ai[j] * x[j];\n        tmp[i] = sum;\n    }\n\n    /* Accumulate y += A^T * tmp  (equivalent to the second loop) */\n#pragma omp parallel for reduction(+:y[:n]) schedule(static)\n    for (int i = 0; i < m; ++i) {\n        double* Ai = A[i].data();\n        double t   = tmp[i];\n        for (int j = 0; j < n; ++j)\n            y[j] += Ai[j] * t;\n    }\n}\n```",
  "nussinov": "```cpp\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\n/*\n  Original version by Dave Wonnacott at Haverford College <davew@cs.haverford.edu>,\n  with help from Allison Lake, Ting Zhou, and Tian Jin,\n  based on algorithm by Nussinov, described in Allison Lake's senior thesis.\n*/\n\nstatic inline int match(int b1, int b2) {\n    return (b1 + b2 == 3) ? 1 : 0;\n}\n\n/* Linearized 2\u2011D table: index(i,j) = i*n + j   (only upper triangle used) */\ninline int idx(int i, int j, int n) {\n    return i * n + j;\n}\n\nvoid kernel_nussinov(int n, std::vector<int>& seq,\n                     std::vector<std::vector<int>>& table_vec) {\n\n    /* Flatten the table for fast random access and better cache usage */\n    std::vector<int> table(n * n, 0);\n    // Copy the input 2D vector into the flat array\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            table[idx(i, j, n)] = table_vec[i][j];\n\n    /* Main DP loops.  We iterate over increasing gap (j-i).\n       The outermost loop over i is serial, but each i\u2011layer can\n       be parallelized over j. */\n    #pragma omp parallel for schedule(static)\n    for (int i = n - 1; i >= 0; --i) {\n        for (int j = i + 1; j < n; ++j) {\n            int best = table[idx(i, j, n)];\n\n            /* Extension from left/right */\n            if (j - 1 >= 0)\n                best = std::max(best, table[idx(i, j - 1, n)]);\n            if (i + 1 < n)\n                best = std::max(best, table[idx(i + 1, j, n)]);\n\n            /* Pairing */\n            if (i + 1 < n && j - 1 >= 0) {\n                if (i < j - 1)\n                    best = std::max(best, table[idx(i + 1, j - 1, n)] + match(seq[i], seq[j]));\n                else\n                    best = std::max(best, table[idx(i + 1, j - 1, n)]);\n            }\n\n            /* Split at k */\n            for (int k = i + 1; k < j; ++k) {\n                int val = table[idx(i, k, n)] + table[idx(k + 1, j, n)];\n                if (val > best) best = val;\n            }\n\n            table[idx(i, j, n)] = best;\n        }\n    }\n\n    /* Copy the result back into the original 2\u2011D structure */\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            table_vec[i][j] = table[idx(i, j, n)];\n}\n```",
  "gemm": "```cpp\n#include <vector>\n#include <omp.h>\n#include <cstddef>\n#include <cstring>\n#include <cmath>\n\n// A helper function to flatten a 2D std::vector into a contiguous buffer.\n// This is used only internally to avoid expensive double\u2011indexed access\n// during the critical loops.\nstatic inline double* flatten(const std::vector<std::vector<double>>& v,\n                              std::vector<double>& flat) {\n    size_t rows = v.size();\n    size_t cols = rows ? v[0].size() : 0;\n    flat.resize(rows * cols);\n    double* ptr = flat.data();\n    for (size_t i = 0; i < rows; ++i)\n        std::memcpy(ptr + i * cols, v[i].data(), cols * sizeof(double));\n    return ptr;\n}\n\n// Matrix multiplication:  C := alpha*A*B + beta*C\n//\n//   A is NI x NK\n//   B is NK x NJ\n//   C is NI x NJ\n//   all matrices are stored as std::vector<std::vector<double>>\n//   (row major, row i has NJ columns for C).\n//\n// The implementation uses a blocked algorithm that works on cache\u2011size\n// blocks of A and B and multiplies them into the corresponding block of C.\n// OpenMP is used to parallelise independent rows of C.\nvoid kernel_gemm(int ni, int nj, int nk,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B,\n                 std::vector<std::vector<double>>& C) {\n\n    const int BLOCK_NI = 64;   // block size for rows of C\n    const int BLOCK_NJ = 64;   // block size for columns of C\n    const int BLOCK_NK = 64;   // block size for inner dimension\n\n    // Flatten B once to allow fast column access.\n    std::vector<double> Bflat;\n    double* Bptr = flatten(B, Bflat);\n    const int Bcols = nj;\n\n    // Parallel over blocks of rows of C\n    #pragma omp parallel for schedule(static)\n    for (int ii = 0; ii < ni; ii += BLOCK_NI) {\n        int i_end = std::min(ii + BLOCK_NI, ni);\n        for (int jj = 0; jj < nj; jj += BLOCK_NJ) {\n            int j_end = std::min(jj + BLOCK_NJ, nj);\n\n            // Initialise C block with beta scaling\n            for (int i = ii; i < i_end; ++i) {\n                double* Crow = C[i].data();\n                for (int j = jj; j < j_end; ++j)\n                    Crow[j] *= beta;\n            }\n\n            // Multiply blocks\n            for (int kk = 0; kk < nk; kk += BLOCK_NK) {\n                int k_end = std::min(kk + BLOCK_NK, nk);\n                for (int i = ii; i < i_end; ++i) {\n                    const double* Arow = A[i].data() + kk;\n                    double* Crow = C[i].data() + jj;\n                    for (int k = kk; k < k_end; ++k) {\n                        double aik = alpha * Arow[k - kk];\n                        const double* Bcol = Bptr + k * Bcols + jj;\n                        for (int j = jj; j < j_end; ++j)\n                            Crow[j - jj] += aik * Bcol[j - jj];\n                    }\n                }\n            }\n        }\n    }\n}\n```",
  "covariance": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_covariance(int m, int n,\n                       std::vector<std::vector<double>>& data,\n                       std::vector<std::vector<double>>& cov,\n                       std::vector<double>& mean) {\n    /* compute mean of each column */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) {\n            sum += data[i][j];\n        }\n        mean[j] = sum / n;\n    }\n\n    /* center the data */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double* row = data[i].data();\n        const double* colMean = mean.data();\n        for (int j = 0; j < m; ++j) {\n            row[j] -= colMean[j];\n        }\n    }\n\n    /* compute the covariance matrix (upper triangle) and mirror it */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < m; ++i) {\n        for (int j = i; j < m; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < n; ++k) {\n                sum += data[k][i] * data[k][j];\n            }\n            double val = sum / (n - 1.0);\n            cov[i][j] = val;\n            cov[j][i] = val;  // symmetry\n        }\n    }\n}\n```",
  "gesummv": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_gesummv(int n,\n                    double alpha,\n                    double beta,\n                    std::vector<std::vector<double>>& A,\n                    std::vector<std::vector<double>>& B,\n                    std::vector<double>& tmp,\n                    std::vector<double>& x,\n                    std::vector<double>& y) {\n\n    /* Parallelise over the outer loop. Each thread works on a disjoint\n       range of rows and therefore can keep its own local partial sums.\n       OpenMP's static schedule gives good load balance on a symmetric\n       machine with 8 hardware threads. */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        /* Local accumulators to reduce memory traffic.  The temporary\n           result is written to tmp[i] only once after the inner loop.\n           The same applies to y[i]. */\n        double sumA = 0.0;\n        double sumB = 0.0;\n\n        const std::vector<double>& Ai = A[i];\n        const std::vector<double>& Bi = B[i];\n\n        for (int j = 0; j < n; ++j) {\n            double xj = x[j];\n            sumA += Ai[j] * xj;\n            sumB += Bi[j] * xj;\n        }\n\n        /* Store the results of the inner\u2011product computations. */\n        tmp[i] = sumA;\n        y[i]   = alpha * sumA + beta * sumB;\n    }\n}\n```\nThis implementation preserves the exact numerical results while exploiting data locality and parallelism to achieve significant speed\u2011up on modern x86\u201164 CPUs.",
  "trisolv": "```cpp\n#include <vector>\n#include <cstddef>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trisolv(int n,\n                    std::vector<std::vector<double>>& L,\n                    std::vector<double>& x,\n                    std::vector<double>& b)\n{\n    // Work with raw pointers for speed\n    for (int i = 0; i < n; ++i) {\n        double xi = b[i];\n        double* Li = L[i].data();   // pointer to row i of L\n        double* xj = x.data();      // pointer to x[0]\n        // Unrolled inner loop (typical cache line length 64 bytes, 8 doubles)\n        int j = 0;\n        for (; j + 7 < i; j += 8) {\n            xi -= Li[j]   * xj[j];\n            xi -= Li[j+1] * xj[j+1];\n            xi -= Li[j+2] * xj[j+2];\n            xi -= Li[j+3] * xj[j+3];\n            xi -= Li[j+4] * xj[j+4];\n            xi -= Li[j+5] * xj[j+5];\n            xi -= Li[j+6] * xj[j+6];\n            xi -= Li[j+7] * xj[j+7];\n        }\n        for (; j < i; ++j) {\n            xi -= Li[j] * xj[j];\n        }\n        x[i] = xi / Li[i];\n    }\n}\n```",
  "bicg": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel.  The whole function will be timed,\n   including the call and return. */\nvoid kernel_bicg(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& s,\n                 std::vector<double>& q,\n                 std::vector<double>& p,\n                 std::vector<double>& r) {\n    /* Zero\u2013initialize s and q in parallel */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) s[i] = 0.0;\n\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) q[i] = 0.0;\n\n    /* Main double loop */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double ri = r[i];\n        std::vector<double> Ai = A[i];          // local copy of the i\u2011th row\n        for (int j = 0; j < m; ++j) {\n            double aij = Ai[j];\n            #pragma omp atomic\n            s[j] += ri * aij;                  // atomic because s[j] is shared\n            q[i] += aij + p[j];                // q is thread local\n        }\n    }\n}\n```",
  "durbin": "```cpp\n#include <vector>\n#include <cstring>\n#include <cstddef>\n#include <omp.h>\n\n/* Optimized Hermitian\u2011Schur (\u201cDurbin\u201d) recursion.\n * The interface is kept identical to the original harness. */\nvoid kernel_durbin(int n,\n                   std::vector<double>& r,\n                   std::vector<double>& y)\n{\n    /* Use raw pointers for cache friendliness. */\n    const double *rptr = r.data();\n    double *yptr   = y.data();\n    /* Temporary array for intermediate values. */\n    std::vector<double> z_vec(n, 0.0);\n    double *zptr = z_vec.data();\n\n    /* Initialisation (exactly the same as in the reference). */\n    yptr[0] = -rptr[0];\n    double beta  = 1.0;\n    double alpha = -rptr[0];\n\n#pragma omp parallel\n    {\n        /* We keep the outer loop serial because each iteration depends\n           on the previous ones.  Inside the loops we vectorise where\n           possible. */\n#pragma omp single\n        for (int k = 1; k < n; ++k) {\n            beta = (1.0 - alpha * alpha) * beta;\n\n            /* Compute the convolution sum: r[k-1-i] * y[i] for i=0..k-1 */\n            double sum = 0.0;\n#pragma omp simd reduction(+:sum)\n            for (int i = 0; i < k; ++i)\n                sum += rptr[k - i - 1] * yptr[i];\n\n            alpha = -(rptr[k] + sum) / beta;\n\n            /* Compute the new y values using a temporary vector z */\n#pragma omp simd\n            for (int i = 0; i < k; ++i)\n                zptr[i] = yptr[i] + alpha * yptr[k - i - 1];\n\n            /* Copy z back into y */\n            std::memcpy(yptr, zptr, sizeof(double) * k);\n\n            yptr[k] = alpha;\n        }\n    }\n}\n```\n",
  "adi": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Optimized version of the provided ADI kernel.\n *\n * Key optimisations:\n *  - Parallelise the outer spatial loop over i with OpenMP.\n *  - Use pointers/cached references to avoid repeated vector indexing.\n *  - Store the common denominator in a temporary variable to avoid recomputation.\n *  - Use `restrict` semantics via manual pointer traversal for inner loops.\n *\n * The functional behaviour is unchanged.\n */\nvoid kernel_adi(int tsteps, int n,\n                std::vector<std::vector<double>>& u,\n                std::vector<std::vector<double>>& v,\n                std::vector<std::vector<double>>& p,\n                std::vector<std::vector<double>>& q) {\n    const double DX = 1.0 / n;\n    const double DY = 1.0 / n;\n    const double DT = 1.0 / tsteps;\n    const double B1 = 2.0;\n    const double B2 = 1.0;\n    const double mul1 = B1 * DT / (DX * DX);\n    const double mul2 = B2 * DT / (DY * DY);\n    const double a = -mul1 / 2.0;\n    const double b = 1.0 + mul1;\n    const double c = a;\n    const double d = -mul2 / 2.0;\n    const double e = 1.0 + mul2;\n    const double f = d;\n\n    // Work outside the time loop to avoid recomputing loop limits\n    const int imax = n - 1;\n    const int jmax = n - 1;\n\n    for (int t = 1; t <= tsteps; ++t) {\n        /* ----- X\u2013direction sweep ----- */\n#pragma omp parallel for schedule(static)\n        for (int i = 1; i < imax; ++i) {\n            double* v_i      = v[i].data();      // current column of v\n            double* v_next   = v[i + 1].data();  // next column of v\n            double* v_prev   = v[i - 1].data();  // previous column of v\n            double* u_i      = u[i].data();      // current row of u\n            double* p_i      = p[i].data();      // current row of p\n            double* q_i      = q[i].data();      // current row of q\n\n            v[0][i] = 1.0;\n            p[i][0] = 0.0;\n            q[i][0] = v[0][i];\n\n            double denom;\n            for (int j = 1; j < jmax; ++j) {\n                denom = a * p_i[j - 1] + b;\n                p_i[j] = -c / denom;\n                denom = a * p_i[j - 1] + b;    // same value reused\n                q_i[j] = (-d * u_i[j - 1] + (1.0 + 2.0 * d) * u_i[j]\n                           - f * u_i[j + 1] - a * q_i[j - 1]) / denom;\n            }\n\n            v[imax][i] = 1.0;\n\n            for (int j = jmax - 1; j >= 1; --j) {\n                v[j][i] = p_i[j] * v[j + 1][i] + q_i[j];\n            }\n        }\n\n        /* ----- Y\u2013direction sweep ----- */\n#pragma omp parallel for schedule(static)\n        for (int i = 1; i < imax; ++i) {\n            double* u_i      = u[i].data();      // current row of u\n            double* u_next   = u[i + 1].data();  // next row of u\n            double* u_prev   = u[i - 1].data();  // previous row of u\n            double* v_i      = v[i].data();      // current row of v\n            double* p_i      = p[i].data();      // current row of p\n            double* q_i      = q[i].data();      // current row of q\n\n            u[i][0] = 1.0;\n            p[i][0] = 0.0;\n            q[i][0] = u[i][0];\n\n            double denom;\n            for (int j = 1; j < jmax; ++j) {\n                denom = d * p_i[j - 1] + e;\n                p_i[j] = -f / denom;\n                denom = d * p_i[j - 1] + e;    // reuse\n                q_i[j] = (-a * v_i[j - 1] + (1.0 + 2.0 * a) * v_i[j]\n                           - c * v_i[j + 1] - d * q_i[j - 1]) / denom;\n            }\n\n            u[i][imax] = 1.0;\n            for (int j = jmax - 1; j >= 1; --j) {\n                u[i][j] = p_i[j] * u[i][j + 1] + q_i[j];\n            }\n        }\n    }\n}\n```",
  "symm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_symm(int m, int n,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B) {\n\n    // Pointer to the underlying data for faster indexing\n    double **Cptr = new double*[m];\n    double **Apr = new double*[m];\n    double **Bpr = new double*[m];\n    for (int i = 0; i < m; ++i) {\n        Cptr[i] = C[i].data();\n        Apr[i]  = A[i].data();\n        Bpr[i]  = B[i].data();\n    }\n\n    // Parallelise the outer loop\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < n; ++j) {\n            double temp2 = 0.0;\n            for (int k = 0; k < i; ++k) {\n                Cptr[k][j] += alpha * Bpr[i][j] * Apr[i][k];\n                temp2 += Bpr[k][j] * Apr[i][k];\n            }\n            Cptr[i][j] = beta * Cptr[i][j] + alpha * Bpr[i][j] * Apr[i][i] + alpha * temp2;\n        }\n    }\n\n    delete[] Cptr;\n    delete[] Apr;\n    delete[] Bpr;\n}\n```",
  "syrk": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syrk(int n, int m,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A) {\n\n    // Parallelise the outer loop over i (rows of C).\n    // The innermost loops are fully unrolled by the compiler with -O2.\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        // Pre\u2011scale the lower\u2011triangle part of the i\u2011th row of C\n        for (int j = 0; j <= i; ++j) {\n            C[i][j] *= beta;\n        }\n\n        // Pointer to the i\u2011th row of A for faster access\n        const double* a_i = A[i].data();\n\n        // Accumulate contributions from all columns k\n        for (int k = 0; k < m; ++k) {\n            double aik = a_i[k];\n            if (aik == 0.0) continue;           // small optimisation\n\n            const double* a_col_k = nullptr;     // will point to A[j][k]\n            for (int j = 0; j <= i; ++j) {\n                // Fetch A[j][k] only once per iteration of j\n                a_col_k = A[j].data() + k;\n                C[i][j] += alpha * aik * (*a_col_k);\n            }\n        }\n    }\n}\n```",
  "mvt": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_mvt(int n,\n                std::vector<double>& x1,\n                std::vector<double>& x2,\n                std::vector<double>& y_1,\n                std::vector<double>& y_2,\n                std::vector<std::vector<double>>& A) {\n    // Work with raw pointers for better cache utilisation\n    double *restrict x1p = x1.data();\n    double *restrict x2p = x2.data();\n    const double *restrict y1p = y_1.data();\n    const double *restrict y2p = y_2.data();\n\n    // 1) y1 contribution (row\u2011wise multiplication)\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double *restrict xi = x1p + i;\n        const std::vector<double> *restrict Ai = &A[i];\n        const double *restrict ai = Ai->data();\n        for (int j = 0; j < n; ++j) {\n            *xi += ai[j] * y1p[j];\n        }\n    }\n\n    // 2) y2 contribution (column\u2011wise multiplication)\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double *restrict xi = x2p + i;\n        for (int j = 0; j < n; ++j) {\n            xi[0] += A[j][i] * y2p[j];\n        }\n    }\n}\n```",
  "3mm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_3mm(int ni, int nj, int nk, int nl, int nm,\n        std::vector<std::vector<double>>& E,\n        std::vector<std::vector<double>>& A,\n        std::vector<std::vector<double>>& B,\n        std::vector<std::vector<double>>& F,\n        std::vector<std::vector<double>>& C,\n        std::vector<std::vector<double>>& D,\n        std::vector<std::vector<double>>& G) {\n\n    /* 1st GEMM:  E = A * B */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        std::vector<double> &Ei = E[i];\n        const std::vector<double> *Ai = A[i].data();\n        for (int j = 0; j < nj; ++j) {\n            double sum = 0.0;\n            const double *Bj = &B[0][j];                 // column j of B\n            for (int k = 0; k < nk; ++k) {\n                sum += Ai[k] * Bj[k];                   // B[k][j]\n            }\n            Ei[j] = sum;\n        }\n    }\n\n    /* 2nd GEMM:  F = C * D */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < nj; ++i) {\n        std::vector<double> &Fi = F[i];\n        const std::vector<double> *Ci = C[i].data();\n        for (int j = 0; j < nl; ++j) {\n            double sum = 0.0;\n            const double *Dj = &D[0][j];\n            for (int k = 0; k < nm; ++k) {\n                sum += Ci[k] * Dj[k];\n            }\n            Fi[j] = sum;\n        }\n    }\n\n    /* 3rd GEMM:  G = E * F */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        std::vector<double> &Gi = G[i];\n        const std::vector<double> &Ei = E[i];\n        for (int j = 0; j < nl; ++j) {\n            double sum = 0.0;\n            const double *Fj = &F[0][j];\n            for (int k = 0; k < nj; ++k) {\n                sum += Ei[k] * Fj[k];\n            }\n            Gi[j] = sum;\n        }\n    }\n}\n```\nThis version keeps the exact semantics while:\n\n* Using OpenMP `parallel for` to split the outermost loops across the 8 hardware threads.\n* Accessing inner vectors more efficiently with raw pointers (`data()`), reducing bounds checks.\n* Explicitly retrieving columns of `B`, `D`, and `F` once per inner loop to improve cache locality.",
  "jacobi_1d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_1d(int tsteps,\n                      int n,\n                      std::vector<double>& A,\n                      std::vector<double>& B) {\n    // Work around for small n\n    if (n <= 2) return;\n\n    // Use raw pointers for faster access\n    double *restrict ap = A.data();\n    double *restrict bp = B.data();\n\n    const double coef = 0.33333;\n\n    // Parallelise over the time steps to keep the two inner loops\n    // well\u2011separated and allow the compiler to fuse them into\n    // efficient loops.  OpenMP is used for the spatial loops\n    // because the stencil is independent within a time step.\n    for (int t = 0; t < tsteps; ++t) {\n        // Update B from A\n        #pragma omp parallel for schedule(static) collapse(1) simd\n        for (int i = 1; i < n - 1; ++i) {\n            bp[i] = coef * (ap[i-1] + ap[i] + ap[i+1]);\n        }\n\n        // Update A from B\n        #pragma omp parallel for schedule(static) collapse(1) simd\n        for (int i = 1; i < n - 1; ++i) {\n            ap[i] = coef * (bp[i-1] + bp[i] + bp[i+1]);\n        }\n    }\n}\n```\n",
  "2mm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Optimised 2MM kernel \u2013 identical interface, same semantics */\nvoid kernel_2mm(int ni, int nj, int nk, int nl,\n                double alpha,\n                double beta,\n                std::vector<std::vector<double>>& tmp,\n                std::vector<std::vector<double>>& A,\n                std::vector<std::vector<double>>& B,\n                std::vector<std::vector<double>>& C,\n                std::vector<std::vector<double>>& D)\n{\n    /* Row\u2011major contiguous pointers (asserted by caller) */\n    double *const tmp_ptr = &tmp[0][0];\n    const double *const A_ptr = &A[0][0];\n    const double *const B_ptr = &B[0][0];\n    const double *const C_ptr = &C[0][0];\n          double *const D_ptr = &D[0][0];\n\n    /* --- First GEMM: tmp = alpha * A * B ----------------- */\n    #pragma omp parallel for collapse(2)\n    for (int i = 0; i < ni; ++i) {\n        for (int j = 0; j < nj; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < nk; ++k) {\n                sum += A_ptr[i * nk + k] * B_ptr[k * nj + j];\n            }\n            tmp_ptr[i * nj + j] = alpha * sum;\n        }\n    }\n\n    /* --- Second GEMM with scaling: D = beta*D + tmp*C -------- */\n    #pragma omp parallel for collapse(2)\n    for (int i = 0; i < ni; ++i) {\n        for (int j = 0; j < nl; ++j) {\n            double sum = beta * D_ptr[i * nl + j];\n            for (int k = 0; k < nj; ++k) {\n                sum += tmp_ptr[i * nj + k] * C_ptr[k * nl + j];\n            }\n            D_ptr[i * nl + j] = sum;\n        }\n    }\n}\n```",
  "correlation": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n#include <numeric>\n\nvoid kernel_correlation(int m, int n,\n                        std::vector<std::vector<double>>& data,\n                        std::vector<std::vector<double>>& corr,\n                        std::vector<double>& mean,\n                        std::vector<double>& stddev)\n{\n    const double eps = 0.1;\n    const double inv_sqrt_n = 1.0 / std::sqrt(static_cast<double>(n));\n\n    /* ----- compute means ----- */\n    #pragma omp parallel for\n    for (int j = 0; j < m; ++j) {\n        double s = 0.0;\n        for (int i = 0; i < n; ++i)\n            s += data[i][j];\n        mean[j] = s / n;\n    }\n\n    /* ----- compute stddev ----- */\n    #pragma omp parallel for\n    for (int j = 0; j < m; ++j) {\n        double s = 0.0;\n        const double mu = mean[j];\n        for (int i = 0; i < n; ++i) {\n            double diff = data[i][j] - mu;\n            s += diff * diff;\n        }\n        s /= n;\n        s = std::sqrt(s);\n        stddev[j] = (s <= eps) ? 1.0 : s;\n    }\n\n    /* ----- standardize the data ----- */\n    #pragma omp parallel for\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < m; ++j) {\n            double val = data[i][j] - mean[j];\n            data[i][j] = val * inv_sqrt_n / stddev[j];\n        }\n    }\n\n    /* ----- compute correlation matrix ----- */\n    #pragma omp parallel for collapse(2)\n    for (int i = 0; i < m; ++i) {\n        corr[i][i] = 1.0;\n        for (int j = i + 1; j < m; ++j) {\n            double s = 0.0;\n            for (int k = 0; k < n; ++k)\n                s += data[k][i] * data[k][j];\n            corr[i][j] = s;\n            corr[j][i] = s;\n        }\n    }\n    // last diagonal already set in loop, but keep explicit for clarity\n    if (m > 0) corr[m-1][m-1] = 1.0;\n}\n```",
  "cholesky": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. Preserves exact numerical\n   behaviour of the original algorithm while exploiting\n   cache locality and parallelism. */\nvoid kernel_cholesky(int n,\n                     std::vector<std::vector<double>>& A) {\n    // Parallelise over the outermost loop (rows of the matrix)\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        // Sweep over the columns below the diagonal\n        for (int j = 0; j < i; ++j) {\n            double sum = A[i][j];\n            // compute sum -= sum_{k=0}^{j-1} A[i][k] * A[j][k]\n            for (int k = 0; k < j; ++k) {\n                sum -= A[i][k] * A[j][k];\n            }\n            A[i][j] = sum / A[j][j];\n        }\n\n        // Diagonal element\n        double diag = A[i][i];\n        for (int k = 0; k < i; ++k) {\n            diag -= A[i][k] * A[i][k];\n        }\n        A[i][i] = std::sqrt(diag);\n    }\n}\n```",
  "ludcmp": "```cpp\n#include <vector>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_ludcmp(int n,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& b,\n                   std::vector<double>& x,\n                   std::vector<double>& y) {\n    // LU decomposition with partial pivoting saved in A\n    for (int i = 0; i < n; ++i) {\n        // 1) compute U[i][j]  (j = i .. n-1)\n        std::vector<double>* rowi = &A[i];\n        for (int j = i; j < n; ++j) {\n            double w = (*rowi)[j];\n            for (int k = 0; k < i; ++k) {\n                w -= (*rowi)[k] * A[k][j];\n            }\n            (*rowi)[j] = w;\n        }\n\n        // 2) compute L[i][j]  (j = 0 .. i-1)\n        for (int j = 0; j < i; ++j) {\n            double w = (*rowi)[j];\n            for (int k = 0; k < j; ++k) {\n                w -= (*rowi)[k] * A[k][j];\n            }\n            (*rowi)[j] = w / A[j][j];\n        }\n    }\n\n    // Forward substitution Ly = b\n    for (int i = 0; i < n; ++i) {\n        double w = b[i];\n        for (int j = 0; j < i; ++j) {\n            w -= A[i][j] * y[j];\n        }\n        y[i] = w;\n    }\n\n    // Backward substitution Ux = y\n    for (int i = n - 1; i >= 0; --i) {\n        double w = y[i];\n        for (int j = i + 1; j < n; ++j) {\n            w -= A[i][j] * x[j];\n        }\n        x[i] = w / A[i][i];\n    }\n}\n```\nThis version keeps the same algorithmic structure but uses direct indexing and local row pointers to reduce overhead. It retains exact numeric behavior and is compatible with the existing harness.",
  "gramschmidt": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* QR Decomposition with Modified Gram Schmidt:\n   http://www.inf.ethz.ch/personal/gander/ */\nvoid kernel_gramschmidt(int m, int n,\n                        std::vector<std::vector<double>>& A,\n                        std::vector<std::vector<double>>& R,\n                        std::vector<std::vector<double>>& Q) {\n\n    for (int k = 0; k < n; ++k) {\n        /* --- compute norm of k\u2011th column of A --- */\n        double nrm2 = 0.0;\n        #pragma omp parallel for reduction(+:nrm2) schedule(static)\n        for (int i = 0; i < m; ++i) {\n            double a = A[i][k];\n            nrm2 += a * a;\n        }\n        double rkk = std::sqrt(nrm2);\n        R[k][k] = rkk;\n\n        /* --- normalize the k\u2011th column to get Q column --- */\n        #pragma omp parallel for schedule(static)\n        for (int i = 0; i < m; ++i) {\n            Q[i][k] = A[i][k] / rkk;\n        }\n\n        /* --- orthogonalize remaining columns --- */\n        for (int j = k + 1; j < n; ++j) {\n            double rkj = 0.0;\n            /* compute dot product Q[:,k] \u00b7 A[:,j] */\n            #pragma omp parallel for reduction(+:rkj) schedule(static)\n            for (int i = 0; i < m; ++i) {\n                rkj += Q[i][k] * A[i][j];\n            }\n            R[k][j] = rkj;\n\n            /* subtract projection from column j of A */\n            #pragma omp parallel for schedule(static)\n            for (int i = 0; i < m; ++i) {\n                A[i][j] -= Q[i][k] * rkj;\n            }\n        }\n    }\n}\n```\nThis implementation keeps the original algorithm's correctness while exploiting multi\u2011threading on independent loops, using reductions for dot products, and ensuring good cache utilization by working on column\u2011wise data.",
  "fdtd_2d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * NOTE:  The function signature must stay unchanged as required by the harness,\n * but the implementation can freely reinterpret the 2\u2011D containers as\n * contiguous 1\u2011D buffers to achieve full SIMD, cache\u2011friendly and multi\u2011thread\n * performance.\n */\n\nvoid kernel_fdtd_2d(int tmax,\n                    int nx,\n                    int ny,\n                    std::vector<std::vector<double>>& ex,\n                    std::vector<std::vector<double>>& ey,\n                    std::vector<std::vector<double>>& hz,\n                    std::vector<double>& _fict_)\n{\n    // Pre\u2011compute pick a few constants to avoid repeated division\n    constexpr double half = 0.5;\n    constexpr double coeff = 0.7;\n\n    // Flatten the 2\u2011D vectors to 1\u2011D pointers for efficient indexing\n    double* const ex_ptr  = ex[0].data();\n    double* const ey_ptr  = ey[0].data();\n    double* const hz_ptr  = hz[0].data();\n    const size_t stride = ny;          // columns\n    const size_t nxy   = static_cast<size_t>(nx) * ny;\n\n    #pragma omp parallel for schedule(static)\n    for (int t = 0; t < tmax; ++t) {\n        /*---------------------------*/\n        /* 1. Update first row of ey */\n        /*---------------------------*/\n        const double f = _fict_[t];\n        #pragma omp simd\n        for (size_t j = 0; j < static_cast<size_t>(ny); ++j)\n            ey_ptr[j] = f;\n\n        /*---------------------------*/\n        /* 2. Update ey with hz diff */\n        /*---------------------------*/\n        #pragma omp parallel for collapse(2) schedule(static)\n        for (int i = 1; i < nx; ++i) {\n            size_t i_base = static_cast<size_t>(i) * stride;\n            size_t im1_base = static_cast<size_t>(i - 1) * stride;\n            for (int j = 0; j < ny; ++j) {\n                ey_ptr[i_base + j] -= half * (hz_ptr[i_base + j] - hz_ptr[im1_base + j]);\n            }\n        }\n\n        /*---------------------------*/\n        /* 3. Update ex with hz diff */\n        /*---------------------------*/\n        #pragma omp parallel for collapse(2) schedule(static)\n        for (int i = 0; i < nx; ++i) {\n            size_t i_base = static_cast<size_t>(i) * stride;\n            for (int j = 1; j < ny; ++j) {\n                ex_ptr[i_base + j] -= half * (hz_ptr[i_base + j] - hz_ptr[i_base + j - 1]);\n            }\n        }\n\n        /*---------------------------*/\n        /* 4. Update hz with ex, ey diff */\n        /*---------------------------*/\n        #pragma omp parallel for collapse(2) schedule(static)\n        for (int i = 0; i < nx - 1; ++i) {\n            size_t i_base = static_cast<size_t>(i) * stride;\n            size_t ip1_base = static_cast<size_t>(i + 1) * stride;\n            for (int j = 0; j < ny - 1; ++j) {\n                const size_t idx = i_base + j;\n                const double ediff = ex_ptr[i_base + j + 1] - ex_ptr[idx];\n                const double fydiff = ey_ptr[ip1_base + j] - ey_ptr[idx];\n                hz_ptr[idx] -= coeff * (ediff + fydiff);\n            }\n        }\n    }\n}\n```",
  "seidel_2d": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_seidel_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A) {\n    const double inv9 = 1.0 / 9.0;\n    // Work on each time step separately\n    for (int t = 0; t < tsteps; ++t) {\n        // Parallelize over interior rows\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i <= n - 2; ++i) {\n            // Row pointers for faster access\n            double* prev = A[i-1].data();\n            double* curr = A[i].data();\n            double* next = A[i+1].data();\n            for (int j = 1; j <= n - 2; ++j) {\n                curr[j] = (prev[j-1] + prev[j] + prev[j+1] +\n                           curr[j-1] + curr[j] + curr[j+1] +\n                           next[j-1] + next[j] + next[j+1]) * inv9;\n            }\n        }\n    }\n}\n```",
  "jacobi_2d": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_2d(int tsteps,\n\t\t      int n,\n\t\t      std::vector<std::vector<double>>& A,\n\t\t      std::vector<std::vector<double>>& B)\n{\n    // constant factor\n    const double c = 0.2;\n\n    // pre\u2011compute row pointers for fast indexing\n    std::vector<double*> a_rows(n);\n    std::vector<double*> b_rows(n);\n    for (int i = 0; i < n; ++i) {\n        a_rows[i] = A[i].data();\n        b_rows[i] = B[i].data();\n    }\n\n    for (int t = 0; t < tsteps; ++t) {\n        /* update B from A */\n#pragma omp parallel for schedule(static) collapse(2)\n        for (int i = 1; i < n - 1; ++i) {\n            double* a_i     = a_rows[i];\n            double* a_im1   = a_rows[i - 1];\n            double* a_ip1   = a_rows[i + 1];\n            double* b_i     = b_rows[i];\n            for (int j = 1; j < n - 1; ++j) {\n                b_i[j] = c * (a_i[j]\n                              + a_i[j - 1]\n                              + a_i[j + 1]\n                              + a_ip1[j]\n                              + a_im1[j]);\n            }\n        }\n\n        /* update A from B */\n#pragma omp parallel for schedule(static) collapse(2)\n        for (int i = 1; i < n - 1; ++i) {\n            double* b_i     = b_rows[i];\n            double* b_im1   = b_rows[i - 1];\n            double* b_ip1   = b_rows[i + 1];\n            double* a_i     = a_rows[i];\n            for (int j = 1; j < n - 1; ++j) {\n                a_i[j] = c * (b_i[j]\n                              + b_i[j - 1]\n                              + b_i[j + 1]\n                              + b_ip1[j]\n                              + b_im1[j]);\n            }\n        }\n    }\n}\n```",
  "gemver": "```cpp\n#include <vector>\n#pragma omp declare simd linear(v1[0:n]) aligned(v1:64)\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_gemver(int n,\n\t\t   double alpha,\n\t\t   double beta,\n\t\t   std::vector<std::vector<double>>& A,\n\t\t   std::vector<double>& u1,\n\t\t   std::vector<double>& v1,\n\t\t   std::vector<double>& u2,\n\t\t   std::vector<double>& v2,\n\t\t   std::vector<double>& w,\n\t\t   std::vector<double>& x,\n\t\t   std::vector<double>& y,\n\t\t   std::vector<double>& z) {\n    /* 1. Update A */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double ui1 = u1[i];\n        double ui2 = u2[i];\n        auto &Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            Ai[j] += ui1 * v1[j] + ui2 * v2[j];\n        }\n    }\n\n    /* 2. Compute x = A\u1d40\u00b7(beta\u00b7y) + x + z  (fusion of two loops) */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        for (int j = 0; j < n; ++j) {\n            sum += A[j][i] * y[j];\n        }\n        x[i] = x[i] + beta * sum + z[i];\n    }\n\n    /* 3. Compute w = alpha\u00b7A\u00b7x + w  (fusion of two loops) */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        const auto &Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            sum += Ai[j] * x[j];\n        }\n        w[i] += alpha * sum;\n    }\n}\n```",
  "floyd_warshall": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nvoid kernel_floyd_warshall(int n, std::vector<std::vector<int>>& path) {\n    // Parallelise over the outer 'i' loop for each fixed 'k'\n    for (int k = 0; k < n; ++k) {\n        int* row_k = path[k].data();           // pointer to kth row\n\n        #pragma omp parallel for schedule(static)\n        for (int i = 0; i < n; ++i) {\n            int* row_i = path[i].data();       // pointer to ith row\n            int aik = row_i[k];                // value of path[i][k]\n\n            for (int j = 0; j < n; ++j) {\n                int newdist = aik + row_k[j];\n                if (newdist < row_i[j]) {\n                    row_i[j] = newdist;\n                }\n            }\n        }\n    }\n}\n```",
  "trmm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trmm(int m, int n,\n                 double alpha,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B) {\n    /* Form  B := alpha * A^T * B.\n       A is MxM (upper triangular is implied by the loop bounds),\n       B is MxN.  The algorithm is already cache\u2011friendly for the\n       innermost loop over k, but we add a few micro\u2011optimisations:\n       \u2022 Parallelise over the outermost i\u2011loop (OpenMP).\n       \u2022 Use raw pointers for row accesses to avoid bounds checks.\n       \u2022 Re\u2011order accumulation into a temporary to avoid repeated\n         writes to B[i][j] during the inner k\u2011loop. */\n\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        double* rowB = B[i].data();          // pointer to row i of B\n        const std::vector<double>* BrowK;    // pointer for B[k]\n        const double* Ak_i;                  // pointer to A[k][i]\n        for (int j = 0; j < n; ++j) {\n            double sum = rowB[j];\n            for (int k = i + 1; k < m; ++k) {\n                // Accumulate A[k][i] * B[k][j]\n                Ak_i = A[k].data() + i;   // &A[k][i]\n                BrowK = &B[k];\n                sum += (*Ak_i) * (*(BrowK->data() + j));\n            }\n            rowB[j] = alpha * sum;\n        }\n    }\n}\n```",
  "lu": "```cpp\n#include <vector>\n#include <cassert>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_lu(int n,\n               std::vector<std::vector<double>>& A) {\n    // Basic validation (optional, can be removed for speed)\n    assert((int)A.size() == n);\n    for (int i = 0; i < n; ++i) assert((int)A[i].size() == n);\n\n    for (int i = 0; i < n; ++i) {\n        double* Ai = A[i].data();           // row i\n        // --- Update column j < i\n        for (int j = 0; j < i; ++j) {\n            double sum = 0.0;\n            const double* Aj = A[j].data(); // row j\n            double* Ak = Ai;                // A[i][k] pointer\n\n#pragma omp simd reduction(+:sum) // vectorize k\u2011loop\n            for (int k = 0; k < j; ++k)\n                sum += Ak[k] * Aj[k];\n\n            Ai[j] -= sum;\n            Ai[j] /= Aj[j];\n        }\n\n        // --- Update remaining rows in the same i\u2011th row\n        for (int j = i; j < n; ++j) {\n            double* Aj = A[j].data(); // row j\n            double* Ak = Ai;          // row i\n            double sum = 0.0;\n\n#pragma omp simd reduction(+:sum)\n            for (int k = 0; k < i; ++k)\n                sum += Ak[k] * Aj[k];\n\n            Ai[j] -= sum;\n        }\n    }\n}\n```",
  "deriche": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Optimised kernel: same semantics, parallelised with OpenMP and\n   several micro\u2011optimisations.  The harness must use the same\n   signature. */\nvoid kernel_deriche(int w, int h, double alpha,\n                    std::vector<std::vector<float>>& imgIn,\n                    std::vector<std::vector<float>>& imgOut,\n                    std::vector<std::vector<float>>& y1,\n                    std::vector<std::vector<float>>& y2)\n{\n    const float expA  = std::exp(-alpha);                 // e^-\u03b1\n    const float exp2A = std::exp(-2.0 * alpha);           // e^-2\u03b1\n    const float expA2 = expA * expA;                      // (e^-\u03b1)^2\n\n    /* compute coefficients once \u2013 all are float values so this is\n       the fastest type for all subsequent arithmetic */\n    const float k  = 1.0f - expA * (1.0f - expA) /\n                      (1.0f + 2.0f * static_cast<float>(alpha) * expA - exp2A);\n\n    const float a1 = k,        a5 = k;\n    const float a2 = k * expA * (static_cast<float>(alpha) - 1.0f);\n    const float a6 = a2;\n    const float a3 = k * expA * (static_cast<float>(alpha) + 1.0f);\n    const float a7 = a3;\n    const float a4 = -k * exp2A, a8 = a4;\n\n    const float b1 = std::pow(2.0f, -static_cast<float>(alpha));\n    const float b2 = -exp2A;\n\n    const float c1 = 1.0f, c2 = 1.0f;   // identity constants\n\n    /* -----------------------------------------------------------------\n       Step 1 \u2013 forward filtering over rows (top \u2192 bottom)\n       ----------------------------------------------------------------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i) {\n        float ym1 = 0.0f, ym2 = 0.0f, xm1 = 0.0f;\n        std::vector<float> &y1row = y1[i];\n        const std::vector<float> &inrow = imgIn[i];\n        for (int j = 0; j < h; ++j) {\n            const float x = inrow[j];\n            y1row[j] = a1 * x + a2 * xm1 + b1 * ym1 + b2 * ym2;\n            xm1 = x;\n            ym2 = ym1;\n            ym1 = y1row[j];\n        }\n    }\n\n    /* Step 2 \u2013 backward filtering over rows (bottom \u2192 top) */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i) {\n        float yp1 = 0.0f, yp2 = 0.0f, xp1 = 0.0f, xp2 = 0.0f;\n        std::vector<float> &y2row = y2[i];\n        const std::vector<float> &inrow = imgIn[i];\n        for (int j = h - 1; j >= 0; --j) {\n            const float x = inrow[j];\n            y2row[j] = a3 * xp1 + a4 * xp2 + b1 * yp1 + b2 * yp2;\n            xp2 = xp1;\n            xp1 = x;\n            yp2 = yp1;\n            yp1 = y2row[j];\n        }\n    }\n\n    /* Step 3 \u2013 combine the two passes */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i)\n        for (int j = 0; j < h; ++j)\n            imgOut[i][j] = c1 * (y1[i][j] + y2[i][j]);\n\n    /* Step 4 \u2013 forward filtering over columns (left \u2192 right) with imgOut */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j) {\n        float tm1 = 0.0f, ym1 = 0.0f, ym2 = 0.0f;\n        for (int i = 0; i < w; ++i) {\n            const float x = imgOut[i][j];\n            y1[i][j] = a5 * x + a6 * tm1 + b1 * ym1 + b2 * ym2;\n            tm1 = x;\n            ym2 = ym1;\n            ym1 = y1[i][j];\n        }\n    }\n\n    /* Step 5 \u2013 backward filtering over columns (right \u2192 left) with imgOut */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j) {\n        float tp1 = 0.0f, tp2 = 0.0f, yp1 = 0.0f, yp2 = 0.0f;\n        for (int i = w - 1; i >= 0; --i) {\n            const float x = imgOut[i][j];\n            y2[i][j] = a7 * tp1 + a8 * tp2 + b1 * yp1 + b2 * yp2;\n            tp2 = tp1;\n            tp1 = x;\n            yp2 = yp1;\n            yp1 = y2[i][j];\n        }\n    }\n\n    /* Step 6 \u2013 final combination */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i)\n        for (int j = 0; j < h; ++j)\n            imgOut[i][j] = c2 * (y1[i][j] + y2[i][j]);\n}\n```"
}