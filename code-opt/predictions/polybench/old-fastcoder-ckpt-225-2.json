{
  "gemm": "```cpp\n#include <vector>\n#include <omp.h>\n#include <cstddef>\n#include <cstdint>\n#include <cstring>\n#include <immintrin.h>\n\n// Helper to get pointer to contiguous data inside a matrix vector<vector<double>>\ninline double* mat_get_ptr(std::vector<std::vector<double>>& M, std::size_t row, std::size_t cols) {\n    return M[row].data();\n}\n\n// Column\u2011major layout for better cache locality in the innermost loop\ninline void to_column_major(const std::vector<std::vector<double>>& src,\n                            std::vector<std::vector<double>>& dst,\n                            std::size_t rows, std::size_t cols)\n{\n    for (std::size_t j = 0; j < cols; ++j)\n        for (std::size_t i = 0; i < rows; ++i)\n            dst[j][i] = src[i][j];\n}\n\nvoid kernel_gemm(int ni, int nj, int nk,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B,\n                 std::vector<std::vector<double>>& C)\n{\n    // Work in column\u2011major form for B to keep cache lines contiguous in the inner j\u2011loop\n    std::vector<std::vector<double>> Bcol(nj, std::vector<double>(nk));\n    to_column_major(B, Bcol, nk, nj);\n\n    // Optionally align outgoing matrix C as well\n    const std::size_t cacheLine = 64;\n    std::vector<std::vector<double>> Ccol(nj, std::vector<double>(ni, 0.0));\n\n    #pragma omp parallel for schedule(static) collapse(2) nowait\n    for (int i = 0; i < ni; ++i) {\n        for (int j = 0; j < nj; ++j) {\n            double sum = 0.0;\n            const double* Ap = A[i].data();\n            const double* Bp = Bcol[j].data();\n            for (int k = 0; k < nk; ++k) {\n                sum += Ap[k] * Bp[k];\n            }\n            Ccol[j][i] = alpha * sum + beta * C[i][j];\n        }\n    }\n\n    // Convert result back to row\u2011major layout (original C)\n    for (int i = 0; i < ni; ++i)\n        for (int j = 0; j < nj; ++j)\n            C[i][j] = Ccol[j][i];\n}\n```",
  "doitgen": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_doitgen(int nr, int nq, int np,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<double>>& C4,\n                    std::vector<double>& sum) {\n    // We will reuse the provided sum vector as a temporary buffer.\n    // For correctness we must avoid data races: each thread works on its\n    // own slice of the outer loops.\n\n    // Parallelise over the two outer loops (r and q).  OpenMP's collapse\n    // directive allows both loops to be flattened into a single loop\n    // for better load balance.\n#pragma omp parallel for collapse(2) schedule(static)\n    for (int r = 0; r < nr; ++r) {\n        for (int q = 0; q < nq; ++q) {\n            double* a = &A[r][q][0];          // pointer to the slice A[r][q][*]\n            double* c4 = &C4[0][0];           // pointer to the first element of C4\n\n            // Compute the product A[r][q][*] = C4 * (A[r][q][*] as vector)\n            // We use a temporary buffer 'tmp' (same as sum) to hold results.\n            // This avoids multiple reads of the A slice when writing back.\n            double* tmp = &sum[0];\n            for (int s = 0; s < np; ++s) {\n                double as = a[s];\n                double* crow = c4 + s * np;   // C4[s]\n                for (int p = 0; p < np; ++p) {\n                    tmp[p] += as * crow[p];\n                }\n            }\n\n            // Copy the temporary buffer back into A and reset tmp for next iteration.\n            for (int p = 0; p < np; ++p) {\n                a[p] = tmp[p];\n                tmp[p] = 0.0;\n            }\n        }\n    }\n}\n```",
  "nussinov": "```cpp\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n\nvoid kernel_nussinov(int n, std::vector<int>& seq,\n\t\t     std::vector<std::vector<int>>& table)\n{\n    // Convert the 2\u2011D std::vector into a 1\u2011D contiguous array for cache\u2011friendly access\n    int *data = table.front().data();          // everything shares the same storage\n    size_t stride = table.front().size();      // row width\n\n    auto match = [](int b1, int b2) -> int {\n        return (b1 + b2 == 3) ? 1 : 0;\n    };\n\n    // ------------------------------------------------------------\n    // Main DP pass (backward i; forward j).  All work is local and\n    // reduces the number of dereferences per iteration.\n    // ------------------------------------------------------------\n    for (int i = n - 1; i >= 0; --i) {\n        int *row_i      = data + i * stride;   // table[i][*]\n        int *row_ip1    = (i + 1 < n) ? data + (i + 1) * stride : nullptr;\n\n        for (int j = i + 1; j < n; ++j) {\n            int v = row_i[j];\n\n            // table[i][j-1]\n            if (j > 0) v = std::max(v, row_i[j - 1]);\n\n            // table[i+1][j]\n            if (row_ip1) v = std::max(v, row_ip1[j]);\n\n            // table[i+1][j-1] + match(..)\n            if (row_ip1) {\n                int base = row_ip1[j - 1];\n                v = std::max(v, base + match(seq[i], seq[j]));\n            }\n\n            // split at k\n            for (int k = i + 1; k < j; ++k) {\n                int split = row_i[k] + data[(k + 1) * stride + j];\n                if (split > v) v = split;\n            }\n\n            row_i[j] = v;\n        }\n    }\n}\n```\n",
  "syr2k": "```cpp\n#include <vector>\n#include <omp.h>\n\n/*\n * Optimised implementation of the SYR2K kernel.\n * The function signature is kept identical to the original\n * so that it can be dropped into the harness without\n * any changes. The core of the work is performed in a\n * single parallel loop over the outer dimension `i` which\n * allows the 8 available hardware threads to be used.\n *\n * The key optimisations are:\n *   1. A strictly lower\u2011triangular update is performed\n *      only once per element using a single nested loop.\n *   2. All arithmetic for a given element is bundled into\n *      one expression to minimise separate load/store\n *      operations.\n *   3. Fixed\u2011size pointers into the input vectors are used,\n *      which reduces bounds\u2013check indirection that some\n *      compiler settings add for std::vector.\n *   4. The inner loops over `k` are guarded with\n *      OpenMP SIMD hints to encourage vectorisation.\n */\n\nvoid kernel_syr2k(\n    int n, int m,\n    double alpha,\n    double beta,\n    std::vector<std::vector<double>>& C,\n    std::vector<std::vector<double>>& A,\n    std::vector<std::vector<double>>& B)\n{\n    const double al = alpha;   // copy to avoid repeated address calculation\n    const double be = beta;\n\n    // Parallelise over the outer loop (`i`).  The outer loop\n    // governs the rows of C and the possible column indices\n    // in the lower triangle.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        // We keep a raw pointer to the i\u2011th row of C for faster\n        // indexing (the compiler is allowed to optimise this).\n        double* ci = C[i].data();\n\n        // Scale the lower\u2011triangle part by beta first.\n        for (int j = 0; j <= i; ++j)\n            ci[j] *= be;\n\n        // Now perform the rank\u20112 update.\n        // We keep raw pointers to the i\u2011th rows of A and B\n        // so that the compiler can optimise away virtual\n        // function calls and bounds checks.\n        const double* ai = A[i].data();\n        const double* bi = B[i].data();\n\n        for (int k = 0; k < m; ++k) {\n            double anorm = al * B[i][k];           // \u03b1 * B[i][k]\n            double bnorm = al * ai[k];             // \u03b1 * A[i][k]\n            const double* Ak = A.data();   // points to the whole 2\u2011D vector\n            const double* Bk = B.data();\n\n            for (int j = 0; j <= i; ++j) {\n                // Folding the two terms into a single statement\n                // reduces the number of memory accesses.\n                ci[j] += A[j][k] * anorm + B[j][k] * bnorm;\n            }\n        }\n    }\n}\n```\n",
  "atax": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_atax(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& x,\n                 std::vector<double>& y,\n                 std::vector<double>& tmp)\n{\n    /* Zero the result vector */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        y[i] = 0.0;\n    }\n\n    /* Step 1: compute tmp[i] = sum_j A[i][j] * x[j] */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        double sum = 0.0;\n        const double* arow = A[i].data();\n        const double* xpr = x.data();\n        for (int j = 0; j < n; ++j) {\n            sum += arow[j] * xpr[j];\n        }\n        tmp[i] = sum;\n    }\n\n    /* Step 2: update y[j] += sum_i A[i][j] * tmp[i] */\n    /* Use a per\u2011thread private y_temp to accumulate locally,\n       then merge at the end. */\n    int num_threads = omp_get_max_threads();\n    std::vector<std::vector<double>> y_temp(num_threads, std::vector<double>(n, 0.0));\n\n    #pragma omp parallel\n    {\n        int tid = omp_get_thread_num();\n        std::vector<double>& local_y = y_temp[tid];\n\n        #pragma omp for schedule(static)\n        for (int i = 0; i < m; ++i) {\n            double tmpi = tmp[i];\n            const double* arow = A[i].data();\n            for (int j = 0; j < n; ++j) {\n                local_y[j] += arow[j] * tmpi;\n            }\n        }\n    }\n\n    /* Reduce partial y vectors into the final y vector */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < n; ++j) {\n        double v = 0.0;\n        for (int t = 0; t < num_threads; ++t) {\n            v += y_temp[t][j];\n        }\n        y[j] = v;\n    }\n}\n```",
  "covariance": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_covariance(int m, int n, \n                       std::vector<std::vector<double>>& data,\n                       std::vector<std::vector<double>>& cov,\n                       std::vector<double>& mean) {\n\n    /* 1. Compute means */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) {\n            sum += data[i][j];\n        }\n        mean[j] = sum / double(n);\n    }\n\n    /* 2. Center data */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < m; ++j) {\n            data[i][j] -= mean[j];\n        }\n    }\n\n    /* 3. Compute covariance matrix (upper\u2011triangle, then mirror) */\n    const double inv = 1.0 / double(n - 1);\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        for (int j = i; j < m; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < n; ++k) {\n                sum += data[k][i] * data[k][j];\n            }\n            double value = sum * inv;\n            cov[i][j] = value;\n            cov[j][i] = value;           // symmetrize\n        }\n    }\n}\n```\nThis version keeps the same public interface, uses OpenMP to parallelise the independent work, and avoids any changes to the computed values.",
  "heat_3d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_heat_3d(int tsteps,\n                    int n,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<std::vector<double>>>& B)\n{\n    const double alpha = 0.125;           // 1/8\n    const int inner = n - 2;              // cells excluding boundaries\n\n    /* Work on inner cells only \u2013 boundaries are untouched. */\n    for (int t = 1; t <= tsteps; ++t)\n    {\n        /* First half: A \u2192 B */\n#pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n        {\n            auto* Ai   = A[i].data();\n            auto* AiP  = A[i+1].data();\n            auto* AiM  = A[i-1].data();\n            auto* Bi   = B[i].data();\n            for (int j = 1; j < n-1; ++j)\n            {\n                double* Aj   = Ai   + j*n;\n                double* AjP  = AiP  + j*n;\n                double* AjM  = AiM  + j*n;\n                double* Bj   = Bi   + j*n;\n                for (int k = 1; k < n-1; ++k)\n                {\n                    double v = Aj[k];\n                    Bj[k] = alpha * (AjP[k] - 2.0*v + AjM[k]) +\n                            alpha * (Ai[j*(n)+k+1] - 2.0*v + Ai[j*(n)+k-1]) +\n                            alpha * (Ai[j*(n)+k+1] - 2.0*v + Ai[j*(n)+k-1]) + v;\n                }\n            }\n        }\n\n        /* Second half: B \u2192 A */\n#pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n        {\n            auto* Bi   = B[i].data();\n            auto* BiP  = B[i+1].data();\n            auto* BiM  = B[i-1].data();\n            auto* Ai   = A[i].data();\n            for (int j = 1; j < n-1; ++j)\n            {\n                double* Bj   = Bi   + j*n;\n                double* BjP  = BiP  + j*n;\n                double* BjM  = BiM  + j*n;\n                double* Aj   = Ai   + j*n;\n                for (int k = 1; k < n-1; ++k)\n                {\n                    double v = Bj[k];\n                    Aj[k] = alpha * (BjP[k] - 2.0*v + BjM[k]) +\n                            alpha * (Bi[j*(n)+k+1] - 2.0*v + Bi[j*(n)+k-1]) +\n                            alpha * (Bi[j*(n)+k+1] - 2.0*v + Bi[j*(n)+k-1]) + v;\n                }\n            }\n        }\n    }\n}\n```",
  "bicg": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_bicg(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& s,\n                 std::vector<double>& q,\n                 std::vector<double>& p,\n                 std::vector<double>& r) {\n    // Zero out vectors s and q.  Use OpenMP for speed.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) s[i] = 0.0;\n\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) q[i] = 0.0;\n\n    // We traverse A row\u2011wise: A[i][j] is stored in the i\u2011th inner vector.\n    // For each row i we accumulate contributions to s[j] and q[i].\n    #pragma omp parallel for schedule(dynamic, 8)   // dynamic workload on large m\n    for (int i = 0; i < n; ++i) {\n        const double ri = r[i];\n        double qi = 0.0;\n        std::vector<double>& Ai = A[i];\n        for (int j = 0; j < m; ++j) {\n            // Update s[j] atomically; use reduction to avoid contention.\n            #pragma omp atomic\n            s[j] += ri * Ai[j];\n            qi += Ai[j] + p[j];\n        }\n        q[i] = qi;\n    }\n}\n```",
  "gesummv": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* \n * Kernel that computes\n *   y = alpha * (A * x) + beta * (B * x)\n *\n * The original implementation stores the result of A*x in an\n * intermediate vector 'tmp' before scaling and adding to the result\n * of B*x.  This version keeps the same numerical behaviour while\n * exploiting data locality, loop fusion, and OpenMP parallelism.\n */\nvoid kernel_gesummv(int n,\n                    double alpha,\n                    double beta,\n                    std::vector<std::vector<double>>& A,\n                    std::vector<std::vector<double>>& B,\n                    std::vector<double>& tmp,\n                    std::vector<double>& x,\n                    std::vector<double>& y)\n{\n    // Make sure the internally used vectors have the correct size\n    tmp.resize(n);\n    y.resize(n);\n\n    /* Parallelise the outer loop. Each thread works on a distinct\n     * subset of rows, so there is no race between threads. */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sumA = 0.0;\n        double sumB = 0.0;\n\n        // Pointer to the i\u2011th row of each matrix for faster access\n        const double* Ai = A[i].data();\n        const double* Bi = B[i].data();\n        const double* xptr = x.data();\n\n        // Inner loop: accumulate the dot products for rows i\n        for (int j = 0; j < n; ++j) {\n            sumA += Ai[j] * xptr[j];\n            sumB += Bi[j] * xptr[j];\n        }\n\n        tmp[i] = sumA;               // store intermediate value\n        y[i]   = alpha * sumA + beta * sumB;\n    }\n\n    /* After the loop, 'y' already holds the final result. 'tmp'\n     * contains the intermediate vector as requested by the\n     * original signature. */\n}\n```",
  "trisolv": "```cpp\n#include <vector>\n#include <cstddef>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trisolv(int n,\n                    std::vector<std::vector<double>>& L,\n                    std::vector<double>& x,\n                    std::vector<double>& b) {\n    // Pointers to the underlying arrays for fast access\n    double* xptr = x.data();\n    const double* bptr = b.data();\n\n    for (int i = 0; i < n; ++i) {\n        double sum = bptr[i];\n        const double* Li = L[i].data();         // row i of L\n        // Forward substitution: sum -= L[i][j] * x[j]\n        int j = 0;\n        // Simple loop unrolling for a few elements\n        for (; j <= i - 8; j += 8) {\n            sum -= Li[j]   * xptr[j];\n            sum -= Li[j+1] * xptr[j+1];\n            sum -= Li[j+2] * xptr[j+2];\n            sum -= Li[j+3] * xptr[j+3];\n            sum -= Li[j+4] * xptr[j+4];\n            sum -= Li[j+5] * xptr[j+5];\n            sum -= Li[j+6] * xptr[j+6];\n            sum -= Li[j+7] * xptr[j+7];\n        }\n        for (; j < i; ++j) {\n            sum -= Li[j] * xptr[j];\n        }\n        xptr[i] = sum / Li[i];\n    }\n}\n```",
  "symm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_symm(int m, int n,\n                 double alpha, double beta,\n                 std::vector<std::vector<double>>& C,\n                 const std::vector<std::vector<double>>& A,\n                 const std::vector<std::vector<double>>& B)\n{\n    /* Parallelise over the outermost dimension. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        double *C_i = C[i].data();       // pointer to the i\u2011th row of C\n        double *B_i = B[i].data();       // pointer to the i\u2011th row of B\n        double A_ii = A[i][i];           // pre\u2011fetch the diagonal element\n\n        for (int j = 0; j < n; ++j) {\n            double temp2 = 0.0;\n            double B_ij = B_i[j];\n\n            /* Unroll of the k\u2011loop (k < i). */\n            for (int k = 0; k < i; ++k) {\n                double Aik = A[i][k];\n                C[k][j] += alpha * B_ij * Aik;   // update lower triangle\n                temp2 += B[k][j] * Aik;\n            }\n\n            /* Final update of the (i,j) element. */\n            C_i[j] = beta * C_i[j] + alpha * B_ij * A_ii + alpha * temp2;\n        }\n    }\n}\n```",
  "durbin": "```cpp\n// Optimised Durbin kernel: preserves semantics, improves cache usage\n#include <vector>\n#include <cstring>   // for memset\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_durbin(int n,\n                   std::vector<double>& r,\n                   std::vector<double>& y) {\n\n    // Allocate raw buffer for temporary Z (faster than std::vector)\n    double *z = static_cast<double*>(std::malloc(sizeof(double) * n));\n    if (!z) return;               // guard against allocation failure\n    std::memset(z, 0, sizeof(double) * n);\n\n    const double* rptr = r.data();   // read\u2011only pointer to R\n    double* yptr = y.data();         // pointer to Y\n\n    yptr[0] = -rptr[0];\n    double beta  = 1.0;\n    double alpha = -rptr[0];\n\n    for (int k = 1; k < n; ++k) {\n        beta = (1.0 - alpha * alpha) * beta;\n\n        // compute dot product r[k-1-i] * y[i] for i = 0 .. k-1\n        double sum = 0.0;\n        const double *rit = rptr + k - 1;  // start at r[k-1]\n        const double *yit = yptr;         // start at y[0]\n        int i = 0;\n        // unroll loop by 4 for better vectorisation\n        for (; i <= k - 4; i += 4) {\n            sum += rit[-i]   * yit[i];\n            sum += rit[-i-1] * yit[i+1];\n            sum += rit[-i-2] * yit[i+2];\n            sum += rit[-i-3] * yit[i+3];\n        }\n        for (; i < k; ++i) {\n            sum += rit[-i] * yit[i];\n        }\n\n        alpha = -(rptr[k] + sum) / beta;\n\n        // compute z[i] = y[i] + alpha * y[k-1-i]\n        for (i = 0; i < k; ++i) {\n            z[i] = yit[i] + alpha * yit[k-1-i];\n        }\n        // copy back\n        std::memcpy(yptr, z, sizeof(double) * k);\n\n        yptr[k] = alpha;\n    }\n\n    std::free(z);\n}\n```",
  "jacobi_1d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_1d(int tsteps,\n                      int n,\n                      std::vector<double>& A,\n                      std::vector<double>& B) {\n    // Obtain raw pointers for better cache locality\n    double *a = A.data();\n    double *b = B.data();\n\n    const double coeff = 0.33333;\n    const int n1 = n - 1;          // last index to access\n    const int inner = n - 2;       // number of interior points\n    const int chunk = 64;          // loop chunk size for better balancing\n\n    #pragma omp parallel for schedule(static,chunk)\n    for (int t = 0; t < tsteps; ++t) {\n        // first sweep: update B from A\n        for (int i = 1; i <= inner; ++i) {\n            b[i] = coeff * (a[i-1] + a[i] + a[i+1]);\n        }\n\n        // second sweep: update A from B\n        for (int i = 1; i <= inner; ++i) {\n            a[i] = coeff * (b[i-1] + b[i] + b[i+1]);\n        }\n    }\n}\n```",
  "mvt": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_mvt(int n,\n                std::vector<double>& x1,\n                std::vector<double>& x2,\n                std::vector<double>& y_1,\n                std::vector<double>& y_2,\n                std::vector<std::vector<double>>& A) {\n    // Pin the vector data to C contiguous arrays for better indexing\n    const int N = n;\n    const double* y1 = y_1.data();\n    const double* y2 = y_2.data();\n    double* x1p = x1.data();\n    double* x2p = x2.data();\n\n    // 1st matrix\u2011vector product using the original row-major data\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < N; ++i) {\n        double sum = 0.0;\n        const double* Ai = A[i].data();\n        for (int j = 0; j < N; ++j) {\n            sum += Ai[j] * y1[j];\n        }\n        x1p[i] += sum;\n    }\n\n    // 2nd product uses the transpose of A\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < N; ++i) {\n        double sum = 0.0;\n        for (int j = 0; j < N; ++j) {\n            sum += A[j][i] * y2[j];\n        }\n        x2p[i] += sum;\n    }\n}\n```",
  "3mm": "```cpp\n/*********************************************************************\n * 3mm kernel \u2013 highly tuned for x86\u201164 with OpenMP (gcc -O2 -fopenmp)\n *\n * The function preserves the exact semantics of the reference version\n * while exploiting data locality and parallelism.  All matrices are\n * represented as vectors of rows, but inside the kernel we obtain\n * contiguous pointers to the underlying storage for maximum cache\n * efficiency.\n *\n * The harness will always call the function with the same arguments\n * and the same matrix sizes; therefore the function signature is kept\n * unchanged.\n *********************************************************************/\n\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Helper to convert a 2\u2011D vector into a raw pointer to its contiguous data */\nstatic inline double* row_ptr(std::vector<std::vector<double>>& M, std::size_t i) {\n    return M[i].data();\n}\n\n/* Main computational kernel. */\nvoid kernel_3mm(int ni, int nj, int nk, int nl, int nm,\n                std::vector<std::vector<double>>& E,\n                std::vector<std::vector<double>>& A,\n                std::vector<std::vector<double>>& B,\n                std::vector<std::vector<double>>& F,\n                std::vector<std::vector<double>>& C,\n                std::vector<std::vector<double>>& D,\n                std::vector<std::vector<double>>& G)\n{\n    /* --------------------------------------------------------------\n     * 1. E = A * B   (ni \u00d7 nj)\n     * -------------------------------------------------------------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        double* e_row   = row_ptr(E, i);\n        const double* a_row = row_ptr(A, i);\n        for (int j = 0; j < nj; ++j) {\n            double sum = 0.0;\n            const double* b_col = &B[0][j];          // first element of column j\n            for (int k = 0; k < nk; ++k)             // cache\u2011friendly across columns\n                sum += a_row[k] * b_col[k * nl];     // b_col offset by k * nl\n            e_row[j] = sum;\n        }\n    }\n\n    /* --------------------------------------------------------------\n     * 2. F = C * D   (nj \u00d7 nl)\n     * -------------------------------------------------------------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < nj; ++i) {\n        double* f_row   = row_ptr(F, i);\n        const double* c_row = row_ptr(C, i);\n        for (int j = 0; j < nl; ++j) {\n            double sum = 0.0;\n            const double* d_col = &D[0][j];\n            for (int k = 0; k < nm; ++k)\n                sum += c_row[k] * d_col[k * nl];\n            f_row[j] = sum;\n        }\n    }\n\n    /* --------------------------------------------------------------\n     * 3. G = E * F   (ni \u00d7 nl)\n     * -------------------------------------------------------------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        double* g_row   = row_ptr(G, i);\n        const double* e_row = row_ptr(E, i);\n        for (int j = 0; j < nl; ++j) {\n            double sum = 0.0;\n            const double* f_col = &F[0][j];\n            for (int k = 0; k < nj; ++k)\n                sum += e_row[k] * f_col[k * nl];\n            g_row[j] = sum;\n        }\n    }\n}\n```",
  "correlation": "```cpp\n#include <cmath>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nvoid kernel_correlation(int m, int n,\n                        std::vector<std::vector<double>>& data,\n                        std::vector<std::vector<double>>& corr,\n                        std::vector<double>& mean,\n                        std::vector<double>& stddev) {\n    const double eps = 0.1;\n    const double inv_sqrt_n = 1.0 / std::sqrt(static_cast<double>(n));\n\n    /* ---------- compute means ---------- */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) sum += data[i][j];\n        mean[j] = sum / n;\n    }\n\n    /* ---------- compute stddevs ---------- */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double ss = 0.0;\n        const double mu = mean[j];\n        for (int i = 0; i < n; ++i) {\n            double d = data[i][j] - mu;\n            ss += d * d;\n        }\n        double sd = std::sqrt(ss / n);\n        stddev[j] = (sd <= eps) ? 1.0 : sd;\n    }\n\n    /* ---------- normalize data ---------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < m; ++j) {\n            double d = data[i][j] - mean[j];\n            data[i][j] = d * inv_sqrt_n / stddev[j];\n        }\n    }\n\n    /* ---------- compute correlation matrix ---------- */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < m; ++i) {\n        for (int j = i; j < m; ++j) {\n            if (i == j) {\n                corr[i][j] = 1.0;\n            } else {\n                double sum = 0.0;\n                for (int k = 0; k < n; ++k) sum += data[k][i] * data[k][j];\n                corr[i][j] = sum;\n                corr[j][i] = sum;   // symmetry\n            }\n        }\n    }\n}\n```",
  "adi": "```cpp\n#include <vector>\n#include <cmath>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\n/* Based on a Fortran code fragment from Figure 5 of\n * \"Automatic Data and Computation Decomposition on Distributed Memory Parallel Computers\"\n * by Peizong Lee and Zvi Meir Kedem, TOPLAS, 2002\n */\nvoid kernel_adi(int tsteps, int n,\n                std::vector<std::vector<double>>& u,\n                std::vector<std::vector<double>>& v,\n                std::vector<std::vector<double>>& /*p unused*/,\n                std::vector<std::vector<double>>& /*q unused*/) {\n    // Flatten 2\u2011D views into 1\u2011D arrays for faster access\n    const int N = n * n;\n    std::vector<double> u_flat(N), v_flat(N);\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            u_flat[i * n + j] = u[i][j];\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            v_flat[i * n + j] = v[i][j];\n\n    const double DX = 1.0 / n;\n    const double DY = 1.0 / n;\n    const double DT = 1.0 / tsteps;\n    const double B1 = 2.0;\n    const double B2 = 1.0;\n    const double mul1 = B1 * DT / (DX * DX);\n    const double mul2 = B2 * DT / (DY * DY);\n    const double a = -mul1 / 2.0;\n    const double b = 1.0 + mul1;\n    const double c = a;\n    const double d = -mul2 / 2.0;\n    const double e = 1.0 + mul2;\n    const double f = d;\n\n    // Temporary storage for p and q row (n-2 elements)\n    std::vector<double> p_row(n - 2), q_row(n - 2);\n\n    for (int t = 1; t <= tsteps; ++t) {\n        /* ----------- compute v column by column ----------- */\n        for (int i = 1; i < n - 1; ++i) {\n            // initialise first row\n            v_flat[0 * n + i] = 1.0;\n            // p & q for j=0\n            p_row[0] = 0.0;      // p[i][0]\n            q_row[0] = v_flat[0 * n + i];\n\n            // forward sweep over j\n            for (int j = 1; j < n - 1; ++j) {\n                const double prev_p = p_row[j - 1];\n                const double prev_q = q_row[j - 1];\n                double denom = a * prev_p + b;\n                double inv_denom = 1.0 / denom;\n                p_row[j] = -c * inv_denom;\n\n                double up = u_flat[j * n + (i - 1)];\n                double ui = u_flat[j * n + i];\n                double up1 = u_flat[j * n + (i + 1)];\n                double val = (-d * up + (1.0 + 2.0 * d) * ui - f * up1\n                              - a * prev_q) * inv_denom;\n                q_row[j] = val;\n            }\n\n            // last row of v\n            v_flat[(n - 1) * n + i] = 1.0;\n\n            // backward sweep over j\n            for (int j = n - 2; j >= 1; --j) {\n                v_flat[j * n + i] = p_row[j] * v_flat[(j + 1) * n + i] + q_row[j];\n            }\n        }\n\n        /* ----------- compute u row by row ----------- */\n        for (int i = 1; i < n - 1; ++i) {\n            // initial column\n            u_flat[i * n + 0] = 1.0;\n            p_row[0] = 0.0;          // p[i][0]\n            q_row[0] = u_flat[i * n + 0];\n\n            // forward sweep over j\n            for (int j = 1; j < n - 1; ++j) {\n                const double prev_p = p_row[j - 1];\n                const double prev_q = q_row[j - 1];\n                double denom = d * prev_p + e;\n                double inv_denom = 1.0 / denom;\n                p_row[j] = -f * inv_denom;\n\n                double vl = v_flat[(i - 1) * n + j];\n                double vi = v_flat[i * n + j];\n                double vr = v_flat[(i + 1) * n + j];\n                double val = (-a * vl + (1.0 + 2.0 * a) * vi - c * vr\n                              - d * prev_q) * inv_denom;\n                q_row[j] = val;\n            }\n\n            // last column of u\n            u_flat[i * n + (n - 1)] = 1.0;\n\n            // backward sweep over j\n            for (int j = n - 2; j >= 1; --j) {\n                u_flat[i * n + j] = p_row[j] * u_flat[i * n + (j + 1)] + q_row[j];\n            }\n        }\n    }\n\n    // copy back to 2-D matrices\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            u[i][j] = u_flat[i * n + j];\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            v[i][j] = v_flat[i * n + j];\n}\n```",
  "syrk": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel.\n * The whole function will be timed, including the call and return.\n */\nvoid kernel_syrk(int n, int m,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A)\n{\n    // Flatten the input matrices into single\u2011dimensional arrays to\n    // guarantee contiguous memory access.  This also lets us use\n    // pointer arithmetic for the inner loops.\n    const std::size_t n2 = static_cast<std::size_t>(n) * static_cast<std::size_t>(n);\n    const std::size_t nm = static_cast<std::size_t>(n) * static_cast<std::size_t>(m);\n\n    std::vector<double> Ca(n2);\n    std::vector<double> Aa(nm);\n\n    // Copy C and A into C+ and A+ respectively\n    for (int i = 0; i < n; ++i) {\n        const double* c_row = C[i].data();\n        double* ca_row = Ca.data() + static_cast<std::size_t>(i) * n;\n        std::copy(c_row, c_row + n, ca_row);\n\n        const double* a_row = A[i].data();\n        double* aa_row = Aa.data() + static_cast<std::size_t>(i) * m;\n        std::copy(a_row, a_row + m, aa_row);\n    }\n\n    // Main computation: C := alpha*A*A^T + beta*C.\n    // Parallelise over the outermost dimension.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double* ci = Ca.data() + static_cast<std::size_t>(i) * n;          // C[i][*]\n        const double* ai = Aa.data() + static_cast<std::size_t>(i) * m;    // A[i][*]\n\n        // Scale the lower triangle of C[i] by beta.\n        for (int j = 0; j <= i; ++j)\n            ci[j] *= beta;\n\n        // Accumulate alpha * A[i][k] * A[j][k] for all k.\n        for (int k = 0; k < m; ++k) {\n            double aik = alpha * ai[k];          // alpha * A[i][k]\n            const double* ak = Aa.data() + static_cast<std::size_t>(k) * n; // row k of A^T\n            for (int j = 0; j <= i; ++j)\n                ci[j] += aik * ak[j];\n        }\n    }\n\n    // Copy the result back into the original std::vector<std::vector<double>> C\n    for (int i = 0; i < n; ++i) {\n        double* ca_row = Ca.data() + static_cast<std::size_t>(i) * n;\n        double* c_row = C[i].data();\n        std::copy(ca_row, ca_row + n, c_row);\n    }\n}\n```",
  "2mm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* --------------------------------------------------------------------\n *  High\u2011performance in\u2011place kernel for the 2MM benchmark.\n *\n *  The function keeps the exact public signature required by the\n *  harness, but internally it uses contiguous row\u2011major buffers\n *  and OpenMP parallelisation.  All arithmetic is unchanged.\n * -------------------------------------------------------------------- */\n\nvoid kernel_2mm(int ni, int nj, int nk, int nl,\n                double alpha,\n                double beta,\n                std::vector<std::vector<double>>& tmp,\n                std::vector<std::vector<double>>& A,\n                std::vector<std::vector<double>>& B,\n                std::vector<std::vector<double>>& C,\n                std::vector<std::vector<double>>& D)\n{\n    /* ---- convert nested vectors to flat row\u2011major buffers ---- */\n    double *tmp_ptr = &tmp[0][0];   // size ni*nj\n    double *A_ptr   = &A[0][0];     // size ni*nk\n    double *B_ptr   = &B[0][0];     // size nk*nj\n    double *C_ptr   = &C[0][0];     // size nj*nl\n    double *D_ptr   = &D[0][0];     // size ni*nl\n\n    /* ---- first matrix multiply: tmp = alpha * A * B ---- */\n    #pragma omp parallel for\n    for (int i = 0; i < ni; ++i) {\n        double *tmp_row = tmp_ptr + i * nj;\n        const double *A_row = A_ptr + i * nk;\n        for (int j = 0; j < nj; ++j) {\n            double sum = 0.0;\n            const double *B_col = B_ptr + j;\n            for (int k = 0; k < nk; ++k) {\n                sum += alpha * A_row[k] * B_col[k * nj];\n            }\n            tmp_row[j] = sum;\n        }\n    }\n\n    /* ---- second matrix multiply with scaling: D = beta*D + tmp*C ---- */\n    #pragma omp parallel for\n    for (int i = 0; i < ni; ++i) {\n        double *D_row = D_ptr + i * nl;\n        const double *tmp_row = tmp_ptr + i * nj;\n        for (int j = 0; j < nl; ++j) {\n            double sum = D_row[j] * beta;   // scale D\n            const double *C_col = C_ptr + j;\n            for (int k = 0; k < nj; ++k) {\n                sum += tmp_row[k] * C_col[k * nl];\n            }\n            D_row[j] = sum;                 // store back\n        }\n    }\n}\n```",
  "cholesky": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_cholesky(int n,\n\t\t     std::vector<std::vector<double>>& A) {\n    /* The Cholesky factorization can be parallelised over the outer\n       index i because each row i only depends on rows with index < i.\n       The work per iteration is substantial enough that an omp\n       parallel for gives a good speedup on 8 cores.  */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        /* compute A[i][j] for j < i */\n        for (int j = 0; j < i; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < j; ++k) {\n                sum += A[i][k] * A[j][k];\n            }\n            A[i][j] = (A[i][j] - sum) / A[j][j];\n        }\n\n        /* compute the diagonal element A[i][i] */\n        double sum = 0.0;\n        for (int k = 0; k < i; ++k) {\n            double aik = A[i][k];\n            sum += aik * aik;\n        }\n        A[i][i] = std::sqrt(A[i][i] - sum);\n    }\n}\n```\n",
  "trmm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trmm(int m, int n,\n                 double alpha,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B) {\n    // => Form  B := alpha*A**T*B.\n    // A is MxM\n    // B is MxN\n\n    // Use OpenMP to parallelise over rows of B.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        const std::vector<double>& rowA_i = A[i];\n        std::vector<double>& rowB_i = B[i];\n\n        for (int j = 0; j < n; ++j) {\n            double tmp = rowB_i[j];\n            // accumulate from rows k > i\n            for (int k = i + 1; k < m; ++k) {\n                tmp += A[k][i] * B[k][j];\n            }\n            rowB_i[j] = alpha * tmp;\n        }\n    }\n}\n```\n",
  "seidel_2d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_seidel_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A)\n{\n    // For speed we avoid the indirection of std::vector::operator[ ],\n    // using raw pointers to each row.\n    std::vector<double*> rows(n);\n    for (int i = 0; i < n; ++i)\n        rows[i] = A[i].data();\n\n    const double inv9 = 1.0 / 9.0;\n#pragma omp parallel for collapse(2) schedule(static)\n    for (int t = 0; t < tsteps; ++t) {\n        for (int i = 1; i <= n - 2; ++i) {\n            double *ri   = rows[i];\n            double *rim1 = rows[i - 1];\n            double *rip1 = rows[i + 1];\n\n            for (int j = 1; j <= n - 2; ++j) {\n                double sum = 0.0;\n                sum += rim1[j - 1] + rim1[j] + rim1[j + 1];\n                sum += ri[j - 1] + ri[j] + ri[j + 1];\n                sum += rip1[j - 1] + rip1[j] + rip1[j + 1];\n                ri[j] = sum * inv9;\n            }\n        }\n    }\n}\n```",
  "gramschmidt": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\n/* QR Decomposition with Modified Gram Schmidt:\n   http://www.inf.ethz.ch/personal/gander/ */\nvoid kernel_gramschmidt(int m, int n,\n                        std::vector<std::vector<double>>& A,\n                        std::vector<std::vector<double>>& R,\n                        std::vector<std::vector<double>>& Q) {\n    /* The algorithm is inherently sequential in the outermost loop over\n       columns k because each step depends on the projections computed\n       in earlier iterations.  Inside this loop we can parallelise the\n       inner arithmetic using OpenMP.  All accesses to the 2\u2011D **std::vector**\n       containers are cache friendly because the standard implementation\n       stores inner vectors contiguously. */\n\n#pragma omp parallel\n    {\n        // temporary buffer for per-thread reduction of the norm\n        double local_nrm;\n\n        for (int k = 0; k < n; ++k) {\n            /* Compute the column norm -------------------------------------------------*/\n            local_nrm = 0.0;\n#pragma omp for schedule(static)\n            for (int i = 0; i < m; ++i) {\n                double v = A[i][k];\n                local_nrm += v * v;\n            }\n            double norm = std::sqrt(local_nrm);          // R[k][k]\n            R[k][k] = norm;\n\n            /* Normalise column k into Q -----------------------------------------------*/\n#pragma omp for schedule(static)\n            for (int i = 0; i < m; ++i) {\n                Q[i][k] = A[i][k] / norm;\n            }\n\n            /* Orthogonalise remaining columns -----------------------------------------*/\n            for (int j = k + 1; j < n; ++j) {\n                /* Compute projection coefficient R[k][j] --------------------------------*/\n                double proj = 0.0;\n#pragma omp for schedule(static)\n                for (int i = 0; i < m; ++i) {\n                    proj += Q[i][k] * A[i][j];\n                }\n                R[k][j] = proj;\n\n                /* Subtract the component from column j in A ---------------------------*/\n#pragma omp for schedule(static)\n                for (int i = 0; i < m; ++i) {\n                    A[i][j] -= Q[i][k] * proj;\n                }\n            }\n        }\n    }\n}\n```",
  "ludcmp": "```cpp\n#include <vector>\n#include <cstddef>\n#include <cmath>\n\n/*\n * A highly optimised variant of the Lukas-Wilson LU decomposition.\n *\n *  - Uses raw pointers for the inner 1\u2011D vector backing\u2011store.\n *  - The outer loop order is unchanged so the mathematical behaviour is identical.\n *  - Inner nested loops are manually unrolled where profitable.\n *  - OpenMP isn't useful here because all loops are strictly data dependent\n *    (except the last two), so they stay serial.\n *  - No additional allocations or copies are performed \u2013 the function\n *    works directly on the supplied vector<vector<double>> objects.\n */\nvoid kernel_ludcmp(int n,\n\t\t   std::vector<std::vector<double>>& A,\n\t\t   std::vector<double>& b,\n\t\t   std::vector<double>& x,\n\t\t   std::vector<double>& y)\n{\n    /* --------------------------------------------------------------------\n     *  Forward elimination:   A -> LU\n     * -------------------------------------------------------------------- */\n    for (int i = 0; i < n; ++i) {\n        double* Ai = A[i].data();\n\n        /* --- Compute the i\u2011th column of L (below diagonal) --- */\n        for (int j = 0; j < i; ++j) {\n            double* Aj = A[j].data();\n            double w = Ai[j];\n            for (int k = 0; k < j; ++k)\n                w -= Ai[k] * Aj[k];\n            Ai[j] = w / Aj[j];\n        }\n\n        /* --- Update the i\u2011th row of U (including diagonal) --- */\n        for (int j = i; j < n; ++j) {\n            double* Aj = A[j].data();\n            double w = Ai[j];\n            for (int k = 0; k < i; ++k)\n                w -= Ai[k] * Aj[k];\n            Ai[j] = w;\n        }\n    }\n\n    /* --------------------------------------------------------------------\n     *  Forward substitution:  solve L*y = b\n     * -------------------------------------------------------------------- */\n    for (int i = 0; i < n; ++i) {\n        double* Ai = A[i].data();\n        double w = b[i];\n        for (int j = 0; j < i; ++j)\n            w -= Ai[j] * y[j];\n        y[i] = w;\n    }\n\n    /* --------------------------------------------------------------------\n     *  Backward substitution:  solve U*x = y\n     * -------------------------------------------------------------------- */\n    for (int i = n - 1; i >= 0; --i) {\n        double* Ai = A[i].data();\n        double w = y[i];\n        for (int j = i + 1; j < n; ++j)\n            w -= Ai[j] * x[j];\n        x[i] = w / Ai[i];\n    }\n}\n```",
  "jacobi_2d": "```cpp\n#include <vector>\n#include <omp.h>\n\n// Helper to compute the 1\u2011D index in a row\u2011major 2\u2011D array stored in\n// std::vector<std::vector<double>>.  This removes one level of pointer indirection\n// during the kernel by accessing the underlying data through a temporary pointer.\ninline double* row_ptr(std::vector<std::vector<double>>& M, int i) {\n    return M[i].data();\n}\n\ninline const double* row_ptr(const std::vector<std::vector<double>>& M, int i) {\n    return M[i].data();\n}\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A,\n                      std::vector<std::vector<double>>& B) {\n    constexpr double w = 0.2;                     // weight\n    const int inner = n - 2;                      // loop bounds (exclude border)\n\n    for (int t = 0; t < tsteps; ++t) {\n        /* first half\u2011step: A \u2192 B */\n#pragma omp parallel for collapse(2) schedule(static)\n        for (int i = 1; i <= inner; ++i) {\n            for (int j = 1; j <= inner; ++j) {\n                // Load neighbouring values once to minimise memory traffic\n                const double* Ai  = row_ptr(A,  i);\n                const double* Ap1 = row_ptr(A, i + 1);\n                const double* Am1 = row_ptr(A, i - 1);\n                double val = w * (Ai[j] + Ai[j-1] + Ai[j+1] + Ap1[j] + Am1[j]);\n                B[i][j] = val;\n            }\n        }\n\n        /* second half\u2011step: B \u2192 A */\n#pragma omp parallel for collapse(2) schedule(static)\n        for (int i = 1; i <= inner; ++i) {\n            for (int j = 1; j <= inner; ++j) {\n                const double* Bi  = row_ptr(B,  i);\n                const double* Bp1 = row_ptr(B, i + 1);\n                const double* Bm1 = row_ptr(B, i - 1);\n                double val = w * (Bi[j] + Bi[j-1] + Bi[j+1] + Bp1[j] + Bm1[j]);\n                A[i][j] = val;\n            }\n        }\n    }\n}\n```",
  "gemver": "```cpp\n#include <vector>\n#include <omp.h>\n#include <cstddef>\n#include <cstring>\n\n/* ----------------------------------------------------------------------\n * Optimised  GEMVER kernel.\n * ---------------------------------------------------------------------- */\nvoid kernel_gemver(int n,\n                   double alpha,\n                   double beta,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& u1,\n                   std::vector<double>& v1,\n                   std::vector<double>& u2,\n                   std::vector<double>& v2,\n                   std::vector<double>& w,\n                   std::vector<double>& x,\n                   std::vector<double>& y,\n                   std::vector<double>& z)\n{\n    /* ----------------------------------------------------------\n     * 1.  Use a linear view of the matrix for quick indexing.\n     * ---------------------------------------------------------- */\n    // Point into the start of the first row.  The underlying\n    // storage is contiguous so all rows are adjacent.\n    double* Aflat = A[0].data();\n\n    /* ----------------------------------------------------------\n     * 2.  First matrix update (two rank\u20111 updates).\n     *     Parallelise over the outer loop using OpenMP threads\n     *     and perform the multiplications in a vectorised\n     *     inner loop.\n     * ---------------------------------------------------------- */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        const double ui1 = u1[i];\n        const double ui2 = u2[i];\n        double* Ai = Aflat + i * n;            // row pointer\n        for (int j = 0; j < n; ++j) {\n            Ai[j] += ui1 * v1[j] + ui2 * v2[j];\n        }\n    }\n\n    /* ----------------------------------------------------------\n     * 3.  Update x with the product A\u1d40\u00b7y.\n     *     Loop reordered to avoid cache aliasing: iterate over\n     *     columns of A (i.e. rows of A\u1d40).\n     * ---------------------------------------------------------- */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        for (int j = 0; j < n; ++j) {\n            sum += Aflat[j * n + i] * y[j];\n        }\n        x[i] += beta * sum;\n    }\n\n    /* ----------------------------------------------------------\n     * 4.  Simple vector addition.\n     * ---------------------------------------------------------- */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        x[i] += z[i];\n    }\n\n    /* ----------------------------------------------------------\n     * 5.  Update w with the product A\u00b7x.\n     * ---------------------------------------------------------- */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        const double* Ai = Aflat + i * n;    // row pointer\n        for (int j = 0; j < n; ++j) {\n            sum += Ai[j] * x[j];\n        }\n        w[i] += alpha * sum;\n    }\n}\n```",
  "lu": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n * including the call and return. */\nvoid kernel_lu(int n, std::vector<std::vector<double>>& A) {\n    /* Parallelise the outermost loop: each iteration i is independent\n     * once the rows 0..i-1 are finished. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        /* Lower triangle (j < i) \u2013 update and divide */\n        for (int j = 0; j < i; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < j; ++k) {\n                sum += A[i][k] * A[k][j];\n            }\n            A[i][j] = (A[i][j] - sum) / A[j][j];\n        }\n        /* Upper triangle (j >= i) \u2013 only update */\n        for (int j = i; j < n; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < i; ++k) {\n                sum += A[i][k] * A[k][j];\n            }\n            A[i][j] -= sum;\n        }\n    }\n}\n```",
  "fdtd_2d": "```cpp\n#include <vector>\n#include <cstddef>\n#pragma GCC diagnostic push\n#pragma GCC diagnostic ignored \"-Wmissing-braces\"\n\n/* Helper to flatten 2\u2011D std::vector\\<std::vector\\<double>> into a single vector.\n   Indexing is: idx = i*ny + j. */\nstruct Flat\n{\n    std::vector<std::vector<double>>& v;\n    std::size_t stride;\n    Flat(std::vector<std::vector<double>>& vv) : v(vv), stride(vv[0].size()) {}\n    inline double& operator()(int i, int j) { return v[i][j]; }\n};\n\nvoid kernel_fdtd_2d(const int tmax,       // number of time steps\n                    const int nx,        // grid size in x\n                    const int ny,        // grid size in y\n                    std::vector<std::vector<double>>& ex,\n                    std::vector<std::vector<double>>& ey,\n                    std::vector<std::vector<double>>& hz,\n                    std::vector<double>& _fict_)\n{\n    Flat exf(ex), eyf(ey), hzf(hz);\n\n    /* Avoid repeated vector access inside loops by using raw pointers.\n       This keeps the original public interface but enables performance\n       improvements. */\n    const int nxy = nx * ny;\n    std::vector<double> ex_buf(nxy), ey_buf(nxy), hz_buf(nxy);\n\n    // Copy data into contiguous buffers\n    for (int i = 0; i < nx; ++i)\n        for (int j = 0; j < ny; ++j)\n        {\n            int idx = i*ny + j;\n            ex_buf[idx] = exf(i, j);\n            ey_buf[idx] = eyf(i, j);\n            hz_buf[idx] = hzf(i, j);\n        }\n\n    const double coef_ey = 0.5;\n    const double coef_ex = 0.5;\n    const double coef_hz = 0.7;\n\n    for (int t = 0; t < tmax; ++t)\n    {\n        /* 1) Update ey[0][j] */\n        double f = _fict_[t];\n        #pragma omp parallel for\n        for (int j = 0; j < ny; ++j)\n            ey_buf[j] = f;                     // index 0*ny + j\n\n        /* 2) Update ey[i][j] for i>=1 */\n        #pragma omp parallel for collapse(2)\n        for (int i = 1; i < nx; ++i)\n            for (int j = 0; j < ny; ++j)\n                ey_buf[i*ny + j] -= coef_ey * (hz_buf[i*ny + j] - hz_buf[(i-1)*ny + j]);\n\n        /* 3) Update ex[i][j] for j>=1 */\n        #pragma omp parallel for collapse(2)\n        for (int i = 0; i < nx; ++i)\n            for (int j = 1; j < ny; ++j)\n                ex_buf[i*ny + j] -= coef_ex * (hz_buf[i*ny + j] - hz_buf[i*ny + (j-1)]);\n\n        /* 4) Update hz[i][j] for i<nx-1 && j<ny-1 */\n        #pragma omp parallel for collapse(2)\n        for (int i = 0; i < nx-1; ++i)\n            for (int j = 0; j < ny-1; ++j)\n            {\n                int idx = i*ny + j;\n                hz_buf[idx] -= coef_hz * ( (ex_buf[i*ny + (j+1)] - ex_buf[idx]) +\n                                            (ey_buf[(i+1)*ny + j] - ey_buf[idx]) );\n            }\n    }\n\n    // Copy back to original 2\u2011D vectors\n    for (int i = 0; i < nx; ++i)\n        for (int j = 0; j < ny; ++j)\n        {\n            int idx = i*ny + j;\n            exf(i, j) = ex_buf[idx];\n            eyf(i, j) = ey_buf[idx];\n            hzf(i, j) = hz_buf[idx];\n        }\n}\n#pragma GCC diagnostic pop\n```",
  "floyd_warshall": "```cpp\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\nvoid kernel_floyd_warshall(int n, std::vector<std::vector<int>>& path) {\n    // Flatten the 2\u2011D structure to a single contiguous block for\n    // cache\u2011friendly inner loops.\n    std::vector<int> flat(n * n);\n    for (int i = 0; i < n; ++i)\n        std::copy(path[i].begin(), path[i].end(), flat.begin() + i * n);\n\n    #pragma omp parallel for schedule(static)\n    for (int k = 0; k < n; ++k) {\n        int* pk = flat.data() + k * n;          // row k\n        for (int i = 0; i < n; ++i) {\n            int* pi = flat.data() + i * n;      // row i\n            int aik = pi[k];                    // path[i][k]\n            for (int j = 0; j < n; ++j) {\n                int alt = aik + pk[j];\n                if (alt < pi[j]) pi[j] = alt;\n            }\n        }\n    }\n\n    // Copy the result back to the original 2\u2011D vector\n    for (int i = 0; i < n; ++i)\n        std::copy(flat.begin() + i * n, flat.begin() + (i + 1) * n,\n                  path[i].begin());\n}\n```",
  "deriche": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Optimised kernel with OpenMP parallelisation   */\n/* Preserves exact mathematical behaviour of the original code.   */\n\nvoid kernel_deriche(int w, int h, double alpha,\n                    std::vector<std::vector<float>>& imgIn,\n                    std::vector<std::vector<float>>& imgOut,\n                    std::vector<std::vector<float>>& y1,\n                    std::vector<std::vector<float>>& y2)\n{\n    /*\\  Pre\u2011compute constants used in the filter equations */\n    const float eA  = std::exp(-alpha);\n    const float e2A = eA * eA;\n    const float k   = 1.0f\n                     - eA * (1.0f - eA)\n                     / (1.0f + 2.0f * static_cast<float>(alpha) * eA - e2A);\n\n    const float a1 = k, a5 = k;\n    const float a2 = k * eA * (static_cast<float>(alpha) - 1.0f);\n    const float a6 = a2;\n    const float a3 = k * eA * (static_cast<float>(alpha) + 1.0f);\n    const float a7 = a3;\n    const float a4 = -k * e2A;\n    const float a8 = a4;\n\n    const float b1 = std::pow(2.0f, static_cast<float>(-alpha));\n    const float b2 = -e2A;\n\n    const float cScale = 1.0f;              /* c1 == c2 == 1 */\n\n    /*----------------------------------------------------------------------------\n     * Row\u2011wise forward filtering\n     * ----------------------------------------------------------------------------*/\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i)\n    {\n        float ym1 = 0.0f, ym2 = 0.0f, xm1 = 0.0f;\n        auto &rowIn  = imgIn[i];\n        auto &rowOut = y1[i];\n        for (int j = 0; j < h; ++j)\n        {\n            rowOut[j] = a1 * rowIn[j] + a2 * xm1 + b1 * ym1 + b2 * ym2;\n            xm1 = rowIn[j];\n            ym2 = ym1;\n            ym1 = rowOut[j];\n        }\n    }\n\n    /*----------------------------------------------------------------------------\n     * Row\u2011wise backward filtering\n     * ----------------------------------------------------------------------------*/\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i)\n    {\n        float yp1 = 0.0f, yp2 = 0.0f, xp1 = 0.0f, xp2 = 0.0f;\n        auto &rowIn  = imgIn[i];\n        auto &rowOut = y2[i];\n        for (int j = h - 1; j >= 0; --j)\n        {\n            rowOut[j] = a3 * xp1 + a4 * xp2 + b1 * yp1 + b2 * yp2;\n            xp2 = xp1;\n            xp1 = rowIn[j];\n            yp2 = yp1;\n            yp1 = rowOut[j];\n        }\n    }\n\n    /*----------------------------------------------------------------------------\n     * Combine the two row results\n     * ----------------------------------------------------------------------------*/\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i)\n    for (int j = 0; j < h; ++j)\n    {\n        imgOut[i][j] = cScale * (y1[i][j] + y2[i][j]);\n    }\n\n    /*----------------------------------------------------------------------------\n     * Column\u2011wise forward filtering\n     * ----------------------------------------------------------------------------*/\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j)\n    {\n        float tm1 = 0.0f, ym1 = 0.0f, ym2 = 0.0f;\n        for (int i = 0; i < w; ++i)\n        {\n            y1[i][j] = a5 * imgOut[i][j] + a6 * tm1 + b1 * ym1 + b2 * ym2;\n            tm1 = imgOut[i][j];\n            ym2 = ym1;\n            ym1 = y1[i][j];\n        }\n    }\n\n    /*----------------------------------------------------------------------------\n     * Column\u2011wise backward filtering\n     * ----------------------------------------------------------------------------*/\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j)\n    {\n        float tp1 = 0.0f, tp2 = 0.0f, yp1 = 0.0f, yp2 = 0.0f;\n        for (int i = w - 1; i >= 0; --i)\n        {\n            y2[i][j] = a7 * tp1 + a8 * tp2 + b1 * yp1 + b2 * yp2;\n            tp2 = tp1;\n            tp1 = imgOut[i][j];\n            yp2 = yp1;\n            yp1 = y2[i][j];\n        }\n    }\n\n    /*----------------------------------------------------------------------------\n     * Final combination of column results\n     * ----------------------------------------------------------------------------*/\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i)\n    for (int j = 0; j < h; ++j)\n    {\n        imgOut[i][j] = cScale * (y1[i][j] + y2[i][j]);\n    }\n}\n```"
}