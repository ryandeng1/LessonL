{
  "atax": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_atax(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& x,\n                 std::vector<double>& y,\n                 std::vector<double>& tmp) {\n\n    /* --- Zero output arrays --------------------------------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        y[i] = 0.0;\n    }\n\n    /* --- Main kernel ---------------------------------------- */\n    #pragma omp parallel for schedule(static) private(tmp)\n    for (int i = 0; i < m; ++i) {\n        double sum = 0.0;                         // scalar tmp[i]\n        const std::vector<double>& Ai = A[i];\n        const double* xi   = x.data();\n\n        /* first loop: tmp[i] = sum_j A[i][j] * x[j] */\n        for (int j = 0; j < n; ++j) {\n            sum += Ai[j] * xi[j];\n        }\n\n        /* second loop: add A[i][j] * tmp[i] to y[j] */\n        const double t = sum;\n        #pragma omp atomic\n        for (int j = 0; j < n; ++j) {\n            y[j] += Ai[j] * t;\n        }\n    }\n}\n```",
  "doitgen": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_doitgen(int nr, int nq, int np,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<double>>& C4,\n                    std::vector<double>& sum) {\n\n    // Parallelise over r and q \u2013 the two outermost loops\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int r = 0; r < nr; ++r) {\n        for (int q = 0; q < nq; ++q) {\n\n            // Pointers to the current slices of A and C4 for faster indexing\n            double* a_row   = A[r][q].data();          // A[r][q][s]\n            double* c4_row  = C4[q].data();           // C4[s][p] (implicitly via indexing)\n\n            // First, compute the partial sums for each p\n            for (int p = 0; p < np; ++p) {\n                double acc = 0.0;\n                for (int s = 0; s < np; ++s) {\n                    acc += a_row[s] * C4[s][p];\n                }\n                sum[p] = acc;\n            }\n\n            // Then overwrite the A slice with the computed values\n            for (int p = 0; p < np; ++p) {\n                a_row[p] = sum[p];\n            }\n        }\n    }\n}\n```\n",
  "syr2k": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syr2k(int n, int m,\n                  double alpha,\n                  double beta,\n                  std::vector<std::vector<double>>& C,\n                  std::vector<std::vector<double>>& A,\n                  std::vector<std::vector<double>>& B) {\n\n    // Parallelise over outer loop (i).  Each thread works on a distinct block.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        // Working pointer to row i of C for faster j\u2011loop access\n        double* Ci = C[i].data();\n\n        // 1) Scale lower triangle by beta\n        for (int j = 0; j <= i; ++j) {\n            Ci[j] *= beta;\n        }\n\n        // 2) Update with rank\u20112 update\n        // Use local copies of alpha for efficiency\n        const double a = alpha;\n\n        // We need rows j and i of A and B for each k\n        for (int k = 0; k < m; ++k) {\n            const double* Ak = A[i].data() + k;   // A[i][k]\n            const double* Bk = B[i].data() + k;   // B[i][k]\n            // Loop over j <= i\n            for (int j = 0; j <= i; ++j) {\n                // A[j][k] and B[j][k]\n                double Ajk = A[j][k];\n                double Bjk = B[j][k];\n                Ci[j] += (Ajk * a * Bk[0]) + (Bjk * a * Ak[0]);\n            }\n        }\n    }\n}\n```",
  "nussinov": "```cpp\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\n/*\n  Optimized version by ChatGPT.  The algorithm keeps the\n  original Nussinov DP but restructures the loops for independent\n  iterations and adds OpenMP parallelisation.\n*/\n\ninline int match(int b1, int b2) noexcept   // inline to avoid calling overhead\n{\n    return (b1 + b2 == 3) ? 1 : 0;\n}\n\nvoid kernel_nussinov(int n, std::vector<int>& seq,\n                     std::vector<std::vector<int>>& table)\n{\n    /* Process the table by increasing diagonal length.\n       For a given length L the entries (i, j = i+L-1) are\n       independent and thus can be computed in parallel. */\n\n    for (int len = 2; len <= n; ++len) {               // length of the subsequence\n        const int limit = n - len + 1;                 // number of i\u2019s for this length\n#pragma omp parallel for schedule(static)\n        for (int i = 0; i < limit; ++i) {\n            const int j = i + len - 1;\n            int best = table[i][j];                   // initialise with existing value\n\n            // 1) skip i or j\n            if (table[i][j-1] > best) best = table[i][j-1];\n            if (table[i+1][j] > best) best = table[i+1][j];\n\n            // 2) pair i with j\n            if (i < j-1)\n                best = std::max(best, table[i+1][j-1] + match(seq[i], seq[j]));\n            else\n                best = std::max(best, table[i+1][j-1]);\n\n            // 3) split between k\n            for (int k = i + 1; k < j; ++k) {\n                const int tmp = table[i][k] + table[k+1][j];\n                if (tmp > best) best = tmp;\n            }\n\n            table[i][j] = best;\n        }\n    }\n}\n```",
  "gemm": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_gemm(int ni, int nj, int nk,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B,\n                 std::vector<std::vector<double>>& C) {\n    // Parallelise over the outer loop (rows of C).  Each thread works\n    // on a distinct row, so no data races occur.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        double* Ci = C[i].data();          // Pointer to the i\u2011th row of C\n        const std::vector<double>& Ai = A[i];  // Reference to the i\u2011th row of A\n\n        /* 1. Scale the row of C by beta (exactly as in the original). */\n        for (int j = 0; j < nj; ++j) {\n            Ci[j] *= beta;\n        }\n\n        /* 2. Accumulate alpha*A[i][k]*B[k][j] for all k. */\n        for (int k = 0; k < nk; ++k) {\n            double aik = alpha * Ai[k];          // Reuse the scaled A[i][k]\n            const std::vector<double>& Bk = B[k]; // Reference to the k\u2011th row of B\n            const double* Bk_ptr = Bk.data();    // Pointer for the inner loop\n            for (int j = 0; j < nj; ++j) {\n                Ci[j] += aik * Bk_ptr[j];\n            }\n        }\n    }\n}\n```",
  "covariance": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_covariance(int m, int n,\n                       std::vector<std::vector<double>>& data,\n                       std::vector<std::vector<double>>& cov,\n                       std::vector<double>& mean)\n{\n    // --- 1. column means ---------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) {\n            sum += data[i][j];\n        }\n        mean[j] = sum / n;\n    }\n\n    // --- 2. center the data -----------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double* row = data[i].data();\n        for (int j = 0; j < m; ++j) {\n            row[j] -= mean[j];\n        }\n    }\n\n    // --- 3. covariance matrix ---------------------------------------------\n    // parallelise over the upper\u2011triangle indices (i,j)\n    #pragma omp parallel for schedule(static, 4)\n    for (int i = 0; i < m; ++i) {\n        for (int j = i; j < m; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < n; ++k) {\n                sum += data[k][i] * data[k][j];\n            }\n            double val = sum / (n - 1.0);\n            cov[i][j] = val;\n            cov[j][i] = val;            // mirror symmetry\n        }\n    }\n}\n```",
  "heat_3d": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_heat_3d(int tsteps,\n                    int n,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<std::vector<double>>>& B)\n{\n    const double coeff = 0.125;\n    const int inner = n - 2;   // number of interior points along one axis\n\n#pragma omp parallel for collapse(3) schedule(static)\n    for (int t = 0; t < tsteps; ++t) {\n        /* update B from A */\n        for (int i = 1; i <= inner; ++i) {\n            for (int j = 1; j <= inner; ++j) {\n                double* Aij = A[i][j].data();\n                double* Bij = B[i][j].data();\n                const double* Apri = A[i+1][j].data();\n                const double* Apmi = A[i-1][j].data();\n                const double* Ajpi = A[i][j+1].data();\n                const double* Ajmi = A[i][j-1].data();\n                double* Biplus = B[i][j+1].data(); // unused but kept for symmetry\n                for (int k = 1; k <= inner; ++k) {\n                    double a = Aij[k];\n                    Bij[k] = coeff * (Apri[k] - 2.0*a + Apmi[k])\n                           + coeff * (Ajpi[k] - 2.0*a + Ajmi[k])\n                           + coeff * (Aij[k+1] - 2.0*a + Aij[k-1])\n                           + a;\n                }\n            }\n        }\n\n        /* update A from B */\n        for (int i = 1; i <= inner; ++i) {\n            for (int j = 1; j <= inner; ++j) {\n                double* Aij = A[i][j].data();\n                double* Bij = B[i][j].data();\n                const double* Bpri = B[i+1][j].data();\n                const double* Bpmi = B[i-1][j].data();\n                const double* Bjpi = B[i][j+1].data();\n                const double* Bjmi = B[i][j-1].data();\n                for (int k = 1; k <= inner; ++k) {\n                    double b = Bij[k];\n                    Aij[k] = coeff * (Bpri[k] - 2.0*b + Bpmi[k])\n                           + coeff * (Bjpi[k] - 2.0*b + Bjmi[k])\n                           + coeff * (Bij[k+1] - 2.0*b + Bij[k-1])\n                           + b;\n                }\n            }\n        }\n    }\n}\n```\n\nThis version:\n\n* Uses `#pragma omp parallel for collapse(3)` to parallelise all 3 inner loops.\n* Accesses vector data via raw pointers (`data()`) to avoid repeated indexing overhead.\n* Keeps all computations identical to the original logic.",
  "trisolv": "```cpp\n#include <vector>\n#include <cstring>  // for memcpy\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trisolv(int n,\n                    std::vector<std::vector<double>>& L,\n                    std::vector<double>& x,\n                    std::vector<double>& b) {\n    // Flatten L into a contiguous buffer to improve cache locality\n    std::vector<double> L_flat;\n    L_flat.reserve(static_cast<std::size_t>(n) * n);\n\n    for (int i = 0; i < n; ++i) {\n        // copy row i of L into L_flat\n        L_flat.insert(L_flat.end(), L[i].begin(), L[i].end());\n    }\n\n    // Pointers to easier access\n    const double* l_ptr = L_flat.data();\n    const double* b_ptr = b.data();\n    double* x_ptr = x.data();\n\n    // Main forward substitution\n    for (int i = 0; i < n; ++i) {\n        double sum = b_ptr[i];\n        const double* l_row = l_ptr + static_cast<std::size_t>(i) * n;\n        for (int j = 0; j < i; ++j)\n            sum -= l_row[j] * x_ptr[j];\n        x_ptr[i] = sum / l_row[i];\n    }\n}\n```",
  "gesummv": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Optimised computational kernel.\n * The function signature is unchanged from the original version. */\nvoid kernel_gesummv(int n,\n                    double alpha,\n                    double beta,\n                    std::vector<std::vector<double>>& A,\n                    std::vector<std::vector<double>>& B,\n                    std::vector<double>& tmp,\n                    std::vector<double>& x,\n                    std::vector<double>& y)\n{\n    /* Parallelise the outer loop \u2013 iterations are independent. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double tmp_i = 0.0;\n        double y_i   = 0.0;\n        const double *Ai   = A[i].data();\n        const double *Bi   = B[i].data();\n        const double *xptr = x.data();\n\n        /* Inner loop is vectorisable.  Unroll a bit for extra speed. */\n        int j = 0;\n        for (; j <= n - 8; j += 8) {\n            // Unrolled block of 8 iterations\n            double a0 = Ai[j   ], a1 = Ai[j+1], a2 = Ai[j+2], a3 = Ai[j+3];\n            double a4 = Ai[j+4], a5 = Ai[j+5], a6 = Ai[j+6], a7 = Ai[j+7];\n\n            double b0 = Bi[j   ], b1 = Bi[j+1], b2 = Bi[j+2], b3 = Bi[j+3];\n            double b4 = Bi[j+4], b5 = Bi[j+5], b6 = Bi[j+6], b7 = Bi[j+7];\n\n            double x0 = xptr[j   ], x1 = xptr[j+1], x2 = xptr[j+2], x3 = xptr[j+3];\n            double x4 = xptr[j+4], x5 = xptr[j+5], x6 = xptr[j+6], x7 = xptr[j+7];\n\n            tmp_i += a0 * x0 + a1 * x1 + a2 * x2 + a3 * x3\n                  + a4 * x4 + a5 * x5 + a6 * x6 + a7 * x7;\n\n            y_i   += b0 * x0 + b1 * x1 + b2 * x2 + b3 * x3\n                  + b4 * x4 + b5 * x5 + b6 * x6 + b7 * x7;\n        }\n        /* Handle any remaining elements */\n        for (; j < n; ++j) {\n            tmp_i += Ai[j] * xptr[j];\n            y_i   += Bi[j] * xptr[j];\n        }\n\n        /* Store the temporaries and combine with the scalars */\n        tmp[i] = tmp_i;\n        y[i]   = alpha * tmp_i + beta * y_i;\n    }\n}\n```",
  "syrk": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syrk(int n, int m,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A)\n{\n    /* Parallelise over the outer loop.\n       Each thread works on a distinct set of rows of C, so no\n       data races occur. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i)\n    {\n        /* Pre\u2011multiply the existing lower\u2011triangle part of C by beta,\n           so that the later inner products only need to add the\n           alpha * A[i][k] * A[j][k] term. */\n        double* Ci = C[i].data();      // pointer to the i\u2011th row of C\n        for (int j = 0; j <= i; ++j)\n            Ci[j] *= beta;\n\n        /* Accumulate the symmetric product.\n           Use a pointer to the i\u2011th row of A for speed. */\n        const double* Ai = A[i].data();   // A[i][*]\n        for (int k = 0; k < m; ++k)\n        {\n            double aik = alpha * Ai[k];   // alpha * A[i][k]\n            for (int j = 0; j <= i; ++j)\n                Ci[j] += aik * A[j][k];\n        }\n    }\n}\n```",
  "adi": "```cpp\n#include <vector>\n#include <cstdlib>\n#include <cstring>\n#include <omp.h>\n\n/*  Replacement for the original kernel.\n    The function signature, argument order and semantics are\n    unchanged, so it can be dropped in place of the original. */\n\nstatic inline double* at(std::vector<std::vector<double>>& M, int i, int j) {\n    return &M[i][j];\n}\n\n/* Helper for 1D linear index conversion */\nstatic inline int idx(int i, int j, int n) { return i * n + j; }\n\nvoid kernel_adi(int tsteps, int n,\n                std::vector<std::vector<double>>& u,\n                std::vector<std::vector<double>>& v,\n                std::vector<std::vector<double>>& p,\n                std::vector<std::vector<double>>& q) {\n    /* Work on a contiguous flat buffer to improve cache behaviour\n       while keeping the original 2\u2011D semantics.  We allocate\n       temporary buffers once per call and reuse them for all\n       time steps.  The outer dimension \u201ci\u201d (0..n\u20111) is kept\n       separate to match original indexing. */\n    int N = n;\n    int stride = N;\n    int size   = N * N;\n\n    std::vector<double> uFlat(size), vFlat(size),\n                        pFlat(size), qFlat(size);\n\n    /* copy initial contents of input vectors into flat buffers */\n    for (int i = 0; i < N; ++i)\n        std::memcpy(&uFlat[idx(i,0,N)], &u[i][0], N*sizeof(double));\n    for (int i = 0; i < N; ++i)\n        std::memcpy(&vFlat[idx(i,0,N)], &v[i][0], N*sizeof(double));\n\n    /* coefficients */\n    double DX = 1.0 / N;\n    double DY = 1.0 / N;\n    double DT = 1.0 / tsteps;\n    double B1 = 2.0;\n    double B2 = 1.0;\n    double mul1 = B1 * DT / (DX * DX);\n    double mul2 = B2 * DT / (DY * DY);\n    double a = -mul1 / 2.0;\n    double b = 1.0 + mul1;\n    double c = a;\n    double d = -mul2 / 2.0;\n    double e = 1.0 + mul2;\n    double f = d;\n\n    /* Main time loop */\n    for (int t = 1; t <= tsteps; ++t) {\n        /* ----------  vertical sweep for each column ---------- */\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i < N - 1; ++i) {\n            /* boundary conditions */\n            vFlat[idx(0,i,N)]   = 1.0;\n            pFlat[idx(i,0,N)]   = 0.0;\n            qFlat[idx(i,0,N)]   = vFlat[idx(0,i,N)];\n\n            /* forward sweep (j increasing) */\n            for (int j = 1; j < N - 1; ++j) {\n                double denom = a * pFlat[idx(i,j-1,N)] + b;\n                pFlat[idx(i,j,N)] = -c / denom;\n                double num = -d * uFlat[idx(j,i-1,N)]\n                           + (1.0 + 2.0 * d) * uFlat[idx(j,i,N)]\n                           - f * uFlat[idx(j,i+1,N)]\n                           - a * qFlat[idx(i,j-1,N)];\n                qFlat[idx(i,j,N)] = num / denom;\n            }\n\n            vFlat[idx(N-1,i,N)] = 1.0;\n\n            /* backward sweep (j decreasing) */\n            for (int j = N - 2; j >= 1; --j) {\n                vFlat[idx(j,i,N)] = pFlat[idx(i,j,N)] * vFlat[idx(j+1,i,N)]\n                                   + qFlat[idx(i,j,N)];\n            }\n        }\n\n        /* ----------  horizontal sweep for each row ---------- */\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i < N - 1; ++i) {\n            uFlat[idx(i,0,N)] = 1.0;\n            pFlat[idx(i,0,N)] = 0.0;\n            qFlat[idx(i,0,N)] = uFlat[idx(i,0,N)];\n\n            for (int j = 1; j < N - 1; ++j) {\n                double denom = d * pFlat[idx(i,j-1,N)] + e;\n                pFlat[idx(i,j,N)] = -f / denom;\n                double num = -a * vFlat[idx(i-1,j,N)]\n                           + (1.0 + 2.0 * a) * vFlat[idx(i,j,N)]\n                           - c * vFlat[idx(i+1,j,N)]\n                           - d * qFlat[idx(i,j-1,N)];\n                qFlat[idx(i,j,N)] = num / denom;\n            }\n\n            uFlat[idx(i,N-1,N)] = 1.0;\n\n            for (int j = N - 2; j >= 1; --j) {\n                uFlat[idx(i,j,N)] = pFlat[idx(i,j,N)] * uFlat[idx(i,j+1,N)]\n                                   + qFlat[idx(i,j,N)];\n            }\n        }\n    }\n\n    /* Copy back results into the original 2\u2011D vectors */\n    for (int i = 0; i < N; ++i)\n        std::memcpy(&u[i][0], &uFlat[idx(i,0,N)], N*sizeof(double));\n    for (int i = 0; i < N; ++i)\n        std::memcpy(&v[i][0], &vFlat[idx(i,0,N)], N*sizeof(double));\n}\n```",
  "bicg": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_bicg(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& s,\n                 std::vector<double>& q,\n                 std::vector<double>& p,\n                 std::vector<double>& r)\n{\n    /* reset s and q as in the reference implementation */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) s[i] = 0.0;\n\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) q[i] = 0.0;\n\n    /* Main loop: each iteration over i updates all s[j] and a single q[i] */\n    #pragma omp parallel\n    {\n        /* each thread keeps a small private accumulator for s[j] */\n        std::vector<double> s_local(m, 0.0);\n\n        #pragma omp for schedule(static)\n        for (int i = 0; i < n; ++i) {\n            double ri = r[i];\n            double*  Ai = A[i].data();      // pointer to the j\u2011th row\n            double*  pi = p.data();          // pointer to the p vector\n\n            /* compute q[i] and accumulate partial s[j] */\n            double qi = 0.0;\n            for (int j = 0; j < m; ++j) {\n                double a = Ai[j];\n                s_local[j] += ri * a;\n                qi += a + pi[j];\n            }\n            q[i] = qi;\n        }\n\n        /* merge thread\u2011local s accumulators into the global s vector */\n        #pragma omp critical\n        {\n            for (int j = 0; j < m; ++j) s[j] += s_local[j];\n        }\n    }\n}\n```\nThe code preserves the exact mathematically\u2011equivalent behavior while exploiting multithreading, private accumulators, and contiguous memory access for higher performance.",
  "3mm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_3mm(int ni, int nj, int nk, int nl, int nm,\n                std::vector<std::vector<double>> &E,\n                std::vector<std::vector<double>> &A,\n                std::vector<std::vector<double>> &B,\n                std::vector<std::vector<double>> &F,\n                std::vector<std::vector<double>> &C,\n                std::vector<std::vector<double>> &D,\n                std::vector<std::vector<double>> &G)\n{\n    /* 1st GEMM :  E = A * B   (ni x nk) * (nk x nj) -> (ni x nj)  */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i)\n    {\n        const std::vector<double> &Ai = A[i];\n        std::vector<double>       &Ei = E[i];\n        for (int j = 0; j < nj; ++j)\n        {\n            double sum = 0.0;\n            for (int k = 0; k < nk; ++k)\n                sum += Ai[k] * B[k][j];\n            Ei[j] = sum;\n        }\n    }\n\n    /* 2nd GEMM :  F = C * D   (nj x nm) * (nm x nl) -> (nj x nl)  */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < nj; ++i)\n    {\n        const std::vector<double> &Ci = C[i];\n        std::vector<double>       &Fi = F[i];\n        for (int j = 0; j < nl; ++j)\n        {\n            double sum = 0.0;\n            for (int k = 0; k < nm; ++k)\n                sum += Ci[k] * D[k][j];\n            Fi[j] = sum;\n        }\n    }\n\n    /* 3rd GEMM :  G = E * F   (ni x nj) * (nj x nl) -> (ni x nl)  */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i)\n    {\n        const std::vector<double> &Ei = E[i];\n        std::vector<double>       &Gi = G[i];\n        for (int j = 0; j < nl; ++j)\n        {\n            double sum = 0.0;\n            for (int k = 0; k < nj; ++k)\n                sum += Ei[k] * F[k][j];\n            Gi[j] = sum;\n        }\n    }\n}\n```",
  "symm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_symm(int m, int n,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B)\n{\n    /* Flatten the 2\u2011D vectors to 1\u2011D contiguous arrays for better cache\n       utilisation while preserving the original layout semantics.\n       C[i][j]  \u2192  C_flat[i + m*j]    (column\u2011major order)\n       A[i][k]  \u2192  A_flat[i + m*k]\n       B[i][j]  \u2192  B_flat[i + m*j]    (same as C)\n    */\n    std::vector<double> C_flat(m * n);\n    std::vector<double> B_flat(m * n);\n    std::vector<double> A_flat(m * m);\n\n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < n; ++j)\n            C_flat[i + m * j] = C[i][j];\n        for (int j = 0; j < n; ++j)\n            B_flat[i + m * j] = B[i][j];\n    }\n    for (int i = 0; i < m; ++i)\n        for (int k = 0; k < m; ++k)\n            A_flat[i + m * k] = A[i][k];\n\n    /* Parallelise the outermost loop. Each thread works on a distinct\n       column of the result matrix.  The inner loop over k accesses\n       columns of A, which are contiguous in our layout.\n    */\n#pragma omp parallel for schedule(static, 8)\n    for (int j = 0; j < n; ++j) {\n        for (int i = 0; i < m; ++i) {\n            double temp2 = 0.0;\n            int idxB = i + m * j;\n            double Bi = B_flat[idxB];\n            for (int k = 0; k < i; ++k) {\n                /* Update lower part of C */\n                int idxC = k + m * j;\n                C_flat[idxC] += alpha * Bi * A_flat[i + m * k];\n                temp2 += B_flat[k + m * j] * A_flat[i + m * k];\n            }\n            int idxC = i + m * j;\n            C_flat[idxC] = beta * C_flat[idxC] + alpha * Bi * A_flat[i + m * i] + alpha * temp2;\n        }\n    }\n\n    /* Copy back the computed result into the original 2\u2011D array. */\n    for (int i = 0; i < m; ++i)\n        for (int j = 0; j < n; ++j)\n            C[i][j] = C_flat[i + m * j];\n}\n```\n",
  "durbin": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. */\nvoid kernel_durbin(int n,\n                   std::vector<double>& r,\n                   std::vector<double>& y)\n{\n    // Working with raw pointers for speed\n    double* rp = r.data();\n    double* yp = y.data();\n\n    // Initial values\n    yp[0] = -rp[0];\n    double beta = 1.0;\n    double alpha = -rp[0];\n\n    for (int k = 1; k < n; ++k) {\n        // Compute the dot\u2011product sum in parallel\n        double sum = 0.0;\n#pragma omp parallel for reduction(+:sum) schedule(static)\n        for (int i = 0; i < k; ++i) {\n            sum += rp[k - i - 1] * yp[i];\n        }\n\n        // Update alpha\n        alpha = -(rp[k] + sum) / beta;\n\n        // Update the first k elements of y in parallel\n#pragma omp parallel for schedule(static)\n        for (int i = 0; i < k; ++i) {\n            double yi_old = yp[i];          // old value of y[i]\n            double yk = yp[k - i - 1];      // old value of y[k-i-1]\n            yp[i] = yi_old + alpha * yk;    // new value\n        }\n\n        // Store the new reflection coefficient\n        yp[k] = alpha;\n\n        // Update beta for next iteration\n        beta = (1.0 - alpha * alpha) * beta;\n    }\n}\n```",
  "jacobi_1d": "```cpp\n#include <vector>\n#include <omp.h>\n\nvoid kernel_jacobi_1d(int tsteps,\n                      int n,\n                      std::vector<double>& A,\n                      std::vector<double>& B) {\n    const double inv3 = 0.33333;\n    double *pA = A.data();\n    double *pB = B.data();\n\n    for (int t = 0; t < tsteps; ++t) {\n        /* First update: B[i] = 1/3 (A[i\u20111] + A[i] + A[i+1]) */\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            pB[i] = inv3 * (pA[i-1] + pA[i] + pA[i+1]);\n        }\n\n        /* Second update: A[i] = 1/3 (B[i\u20111] + B[i] + B[i+1]) */\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            pA[i] = inv3 * (pB[i-1] + pB[i] + pB[i+1]);\n        }\n    }\n}\n```",
  "2mm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel.  The whole function will be timed,\n   including the call and return. */\nvoid kernel_2mm(int ni, int nj, int nk, int nl,\n                double alpha,\n                double beta,\n                std::vector<std::vector<double>>& tmp,\n                std::vector<std::vector<double>>& A,\n                std::vector<std::vector<double>>& B,\n                std::vector<std::vector<double>>& C,\n                std::vector<std::vector<double>>& D) {\n\n    /* ------------------------------------------------------------------\n     *  1)  First matrix multiply    tmp = alpha * A  * B\n     * ------------------------------------------------------------------*/\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        double* ti = tmp[i].data();          // row pointer\n        const double* ai = A[i].data();      // row A[i]\n        for (int j = 0; j < nj; ++j) {\n            double sum = 0.0;\n            const double* bj = nullptr;      // column B[:,j]\n            for (int k = 0; k < nk; ++k) {\n                bj = B[k].data();            // reuse pointer\n                sum += alpha * ai[k] * bj[j];\n            }\n            ti[j] = sum;\n        }\n    }\n\n    /* ------------------------------------------------------------------\n     *  2)  Second matrix multiply   D = beta * D + tmp * C\n     * ------------------------------------------------------------------*/\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        double* di = D[i].data();           // row pointer D[i]\n        const double* ti = tmp[i].data();   // row tmp[i]\n        for (int j = 0; j < nl; ++j) {\n            double sum = beta * di[j];\n            for (int k = 0; k < nj; ++k) {\n                sum += ti[k] * C[k][j];\n            }\n            di[j] = sum;\n        }\n    }\n}\n```",
  "correlation": "```cpp\n#include <vector>\n#include <cmath>\n#include <omp.h>\n\nvoid kernel_correlation(int m, int n,\n                        std::vector<std::vector<double>>& data,\n                        std::vector<std::vector<double>>& corr,\n                        std::vector<double>& mean,\n                        std::vector<double>& stddev)\n{\n    const double eps = 0.1;\n    const double inv_sqrt_n = 1.0 / std::sqrt(static_cast<double>(n));\n\n    /* ------------------------------------------------------------------\n     * 1) Compute column means and standard deviations in parallel.\n     * ------------------------------------------------------------------ */\n    #pragma omp parallel for\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) {\n            sum += data[i][j];\n        }\n        mean[j] = sum / static_cast<double>(n);\n    }\n\n    #pragma omp parallel for\n    for (int j = 0; j < m; ++j) {\n        double ss = 0.0;\n        const double mu = mean[j];\n        for (int i = 0; i < n; ++i) {\n            double x = data[i][j] - mu;\n            ss += x * x;\n        }\n        stddev[j] = std::sqrt(ss / static_cast<double>(n));\n        if (stddev[j] <= eps) stddev[j] = 1.0;\n    }\n\n    /* ------------------------------------------------------------------\n     * 2) Normalise the data once per column and store a preprocessing\n     *    factor that eliminates the repeated sqrt(n) calculation.\n     * ------------------------------------------------------------------ */\n    std::vector<double> denom(m);\n    for (int j = 0; j < m; ++j) {\n        denom[j] = inv_sqrt_n / stddev[j];\n    }\n\n    #pragma omp parallel for\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < m; ++j) {\n            double v = data[i][j] - mean[j];\n            data[i][j] = v * denom[j];\n        }\n    }\n\n    /* ------------------------------------------------------------------\n     * 3) Compute correlation matrix.  The matrix is symmetric so we\n     *    compute only the upper\u2011triangle and mirror it.\n     * ------------------------------------------------------------------ */\n    #pragma omp parallel for\n    for (int i = 0; i < m - 1; ++i) {\n        corr[i][i] = 1.0;\n        for (int j = i + 1; j < m; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < n; ++k) {\n                sum += data[k][i] * data[k][j];\n            }\n            corr[i][j] = sum;\n            corr[j][i] = sum;\n        }\n    }\n    corr[m-1][m-1] = 1.0;\n}\n```",
  "mvt": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Optimised version of kernel_mvt that preserves the exact semantics of the original.\n * Each thread works on a distinct slice of the result vectors `x1` and `x2`, thus\n * there is no data race and no need for atomic operations.\n */\nvoid kernel_mvt(int n,\n                std::vector<double>& x1,\n                std::vector<double>& x2,\n                std::vector<double>& y_1,\n                std::vector<double>& y_2,\n                std::vector<std::vector<double>>& A) {\n    // Use raw pointers for faster indexing\n    const double* restrict y1p = y_1.data();\n    const double* restrict y2p = y_2.data();\n    double* restrict x1p = x1.data();\n    double* restrict x2p = x2.data();\n\n    // We need two separate pointer blocks for the matrix to avoid rebinding.\n    // A is stored in row-major order; A[j][i] accesses the element in column i, row j.\n    // To keep the cache line usage optimal, we access the original matrix\n    // in row-major order twice, once for x1 and once for x2, using pointer arithmetic.\n    const double* restrict Aptr = nullptr;\n\n    // Parallelise over the outer dimension; each thread gets a fixed `i`.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        const double* ai = A[i].data();          // row i of A\n        double   sumX1 = x1p[i];                 // initialise with current value\n        // First part: x1[i] += sum_j A[i][j] * y1[j]\n        for (int j = 0; j < n; ++j) {\n            sumX1 += ai[j] * y1p[j];\n        }\n        x1p[i] = sumX1;\n    }\n\n    // Second part: x2[i] += sum_j A[j][i] * y2[j]\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double   sumX2 = x2p[i];                 // initialise with current value\n        for (int j = 0; j < n; ++j) {\n            sumX2 += A[j][i] * y2p[j];\n        }\n        x2p[i] = sumX2;\n    }\n}\n```",
  "cholesky": "```cpp\n#include <cmath>\n\nvoid kernel_cholesky(int n, std::vector<std::vector<double>>& A) {\n    // Alias for quicker access once per row\n    for (int i = 0; i < n; ++i) {\n        double* row_i = A[i].data();          // row i\n        const double* row_i_const = row_i;    // for read-only use\n        for (int j = 0; j < i; ++j) {\n            double* row_j = A[j].data();      // row j\n            double sum = 0.0;\n            for (int k = 0; k < j; ++k) {\n                sum += row_i[k] * row_j[k];\n            }\n            row_i[j] = (row_i[j] - sum) / row_j[j];\n        }\n\n        // diagonal element\n        double sum = 0.0;\n        for (int k = 0; k < i; ++k) {\n            sum += row_i[k] * row_i[k];\n        }\n        row_i[i] = std::sqrt(row_i[i] - sum);\n    }\n}\n```",
  "fdtd_2d": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_fdtd_2d(int tmax,\n                    int nx,\n                    int ny,\n                    std::vector<std::vector<double>>& ex,\n                    std::vector<std::vector<double>>& ey,\n                    std::vector<std::vector<double>>& hz,\n                    std::vector<double>& _fict_) {\n    const double coeff_ey = 0.5;\n    const double coeff_ex = 0.5;\n    const double coeff_hz = 0.7;\n\n    for (int t = 0; t < tmax; ++t) {\n        /* Update EY[0][j] */\n        #pragma omp parallel for\n        for (int j = 0; j < ny; ++j) {\n            ey[0][j] = _fict_[t];\n        }\n\n        /* Update EY[i][j] for i>=1 */\n        #pragma omp parallel for\n        for (int i = 1; i < nx; ++i) {\n            const double* hz_i     = hz[i].data();\n            const double* hz_im1   = hz[i-1].data();\n            double*      ey_i      = ey[i].data();\n\n            for (int j = 0; j < ny; ++j) {\n                ey_i[j] -= coeff_ey * (hz_i[j] - hz_im1[j]);\n            }\n        }\n\n        /* Update EX[i][j] for j>=1 */\n        #pragma omp parallel for\n        for (int i = 0; i < nx; ++i) {\n            const double* hz_i = hz[i].data();\n            double*      ex_i  = ex[i].data();\n\n            for (int j = 1; j < ny; ++j) {\n                ex_i[j] -= coeff_ex * (hz_i[j] - hz_i[j-1]);\n            }\n        }\n\n        /* Update HZ[i][j] for i< nx-1 and j< ny-1 */\n        #pragma omp parallel for collapse(2)\n        for (int i = 0; i < nx-1; ++i) {\n            for (int j = 0; j < ny-1; ++j) {\n                hz[i][j] -= coeff_hz *\n                            (ex[i][j+1] - ex[i][j] + ey[i+1][j] - ey[i][j]);\n            }\n        }\n    }\n}\n```",
  "jacobi_2d": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A,\n                      std::vector<std::vector<double>>& B)\n{\n    /* Local cache of row pointers for faster indexed access */\n    std::vector<double*> Arow(n), Brow(n);\n    for (int i = 0; i < n; ++i) {\n        Arow[i] = A[i].data();\n        Brow[i] = B[i].data();\n    }\n\n    /* Pre\u2011compute the factor */\n    const double coef = 0.2;\n\n    for (int t = 0; t < tsteps; ++t) {\n        /* First half of the Jacobi sweep */\n        #pragma omp parallel for collapse(2) schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            for (int j = 1; j < n - 1; ++j) {\n                Brow[i][j] = coef *\n                    (Arow[i][j] + Arow[i][j-1] + Arow[i][j+1] +\n                     Arow[i+1][j] + Arow[i-1][j]);\n            }\n        }\n\n        /* Second half of the Jacobi sweep */\n        #pragma omp parallel for collapse(2) schedule(static)\n        for (int i = 1; i < n - 1; ++i) {\n            for (int j = 1; j < n - 1; ++j) {\n                Arow[i][j] = coef *\n                    (Brow[i][j] + Brow[i][j-1] + Brow[i][j+1] +\n                     Brow[i+1][j] + Brow[i-1][j]);\n            }\n        }\n    }\n}\n```",
  "gramschmidt": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/*\n * QR Decomposition with Modified Gram\u2013Schmidt\n * Optimised for speed on a modern x86\u201164 system with OpenMP\n * The algorithm itself is unchanged \u2013 only the inner loops\n * have been rewritten for a contiguous data layout and\n * parallelised.\n */\n\nvoid kernel_gramschmidt(int m, int n,\n                        std::vector<std::vector<double>>& A,\n                        std::vector<std::vector<double>>& R,\n                        std::vector<std::vector<double>>& Q)\n{\n    /* Allocate a contiguous buffer for A \u2013 all accesses become\n       cache friendly. The input matrix A is overwritten, as in the\n       original algorithm. */\n    std::vector<double> Ac(m * n);\n\n    /* Flatten the input matrix */\n    for (int i = 0; i < m; ++i)\n        for (int j = 0; j < n; ++j)\n            Ac[i * n + j] = A[i][j];\n\n    /* Main algorithm: k\u2011loop */\n    for (int k = 0; k < n; ++k) {\n        /* --- 1. Compute the norm of column k --- */\n        double nrm = 0.0;\n#pragma omp parallel for reduction(+:nrm) schedule(static)\n        for (int i = 0; i < m; ++i) {\n            double v = Ac[i * n + k];\n            nrm += v * v;\n        }\n        nrm = std::sqrt(nrm);\n        R[k][k] = nrm;\n\n        /* --- 2. Compute Q[:,k] = A[:,k] / R[k][k] --- */\n#pragma omp parallel for schedule(static)\n        for (int i = 0; i < m; ++i) {\n            Q[i][k] = Ac[i * n + k] / nrm;\n        }\n\n        /* --- 3. Orthogonalise remaining columns --- */\n#pragma omp parallel for schedule(dynamic)\n        for (int j = k + 1; j < n; ++j) {\n            /* R[k][j] = dot(Q[:,k], A[:,j]) */\n            double dot = 0.0;\n            for (int i = 0; i < m; ++i) {\n                dot += Q[i][k] * Ac[i * n + j];\n            }\n            R[k][j] = dot;\n\n            /* A[:,j] -= Q[:,k] * R[k][j] */\n#pragma omp parallel for\n            for (int i = 0; i < m; ++i) {\n                Ac[i * n + j] -= Q[i][k] * dot;\n            }\n        }\n    }\n\n    /* Write back the flattened results to the original matrix A */\n    for (int i = 0; i < m; ++i)\n        for (int j = 0; j < n; ++j)\n            A[i][j] = Ac[i * n + j];\n}\n```",
  "trmm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trmm(int m, int n,\n                 double alpha,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B) {\n    /* Perform B := alpha * A.T * B\n       A is m\u00d7m, B is m\u00d7n.  The computation can be parallelized\n       over the rows of B (i.e., over i).  No change in semantics\n       from the reference implementation. */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        // Each thread works on its own row of B.\n        for (int j = 0; j < n; ++j) {\n            double sum = B[i][j];           // start with existing B[i][j]\n            for (int k = i + 1; k < m; ++k) {\n                sum += A[k][i] * B[k][j];\n            }\n            B[i][j] = alpha * sum;\n        }\n    }\n}\n```",
  "ludcmp": "```cpp\n#include <vector>\n#include <cstddef>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_ludcmp(int n,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& b,\n                   std::vector<double>& x,\n                   std::vector<double>& y) {\n    /* ------------------------------------------------------------------\n       LU decomposition with partial pivoting disabled (original code\n       performs Doolittle factorization without row swaps).  The\n       implementation below keeps the same semantics but is\n       qualification\u2011optimized for cache locality and compiler\n       vectorization.\n    ------------------------------------------------------------------ */\n\n    /* Pre\u2011fetch row pointers for faster access. */\n    std::vector<double*> row_ptrs(n);\n    for (int i = 0; i < n; ++i) row_ptrs[i] = A[i].data();\n\n    /* ------------------------------------------------------------------\n       LU factorization\n    ------------------------------------------------------------------ */\n    for (int i = 0; i < n; ++i) {\n        double* Ai = row_ptrs[i];\n\n        /* Compute lower part A[i][j] / A[j][j] for j < i */\n        for (int j = 0; j < i; ++j) {\n            double w = Ai[j];\n            double* Aj = row_ptrs[j];\n            #pragma GCC ivdep\n            for (int k = 0; k < j; ++k) {\n                w -= Ai[k] * Aj[k];\n            }\n            Ai[j] = w / Aj[j];\n        }\n\n        /* Compute upper part A[i][j] for j >= i */\n        for (int j = i; j < n; ++j) {\n            double w = Ai[j];\n            #pragma GCC ivdep\n            for (int k = 0; k < i; ++k) {\n                w -= Ai[k] * row_ptrs[k][j];\n            }\n            Ai[j] = w;\n        }\n    }\n\n    /* ------------------------------------------------------------------\n       Forward substitution to solve L*y = b\n    ------------------------------------------------------------------ */\n    for (int i = 0; i < n; ++i) {\n        double w = b[i];\n        double* Ai = row_ptrs[i];\n        #pragma GCC ivdep\n        for (int j = 0; j < i; ++j) {\n            w -= Ai[j] * y[j];\n        }\n        y[i] = w;\n    }\n\n    /* ------------------------------------------------------------------\n       Backward substitution to solve U*x = y\n    ------------------------------------------------------------------ */\n    for (int i = n - 1; i >= 0; --i) {\n        double w = y[i];\n        double* Ai = row_ptrs[i];\n        #pragma GCC ivdep\n        for (int j = i + 1; j < n; ++j) {\n            w -= Ai[j] * x[j];\n        }\n        x[i] = w / Ai[i];\n    }\n}\n```",
  "floyd_warshall": "```cpp\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\nvoid kernel_floyd_warshall(std::size_t n, std::vector<std::vector<int>>& path) {\n    // Flatten the 2\u2011D vector into a 1\u2011D contiguous buffer for fast access.\n    std::vector<int> buf(n * n);\n    for (std::size_t i = 0; i < n; ++i)\n        std::copy(path[i].begin(), path[i].end(), buf.begin() + i * n);\n\n    const std::size_t stride = n;\n    // Main Floyd\u2011Warshall loop with OpenMP outer loop.\n    for (std::size_t k = 0; k < n; ++k) {\n        const std::size_t k_offset = k * stride;\n        // Parallel over rows.\n        #pragma omp parallel for schedule(static)\n        for (std::size_t i = 0; i < n; ++i) {\n            const std::size_t i_offset = i * stride;\n            const int aik = buf[i_offset + k];\n            // Skip if aik is INF-like to avoid unnecessary work (not required but cheap).\n            for (std::size_t j = 0; j < n; ++j) {\n                int& dst = buf[i_offset + j];\n                int new_dist = aik + buf[k_offset + j];\n                if (new_dist < dst) dst = new_dist;\n            }\n        }\n    }\n\n    // Copy back to the original 2\u2011D vector structure.\n    for (std::size_t i = 0; i < n; ++i)\n        std::copy(buf.begin() + i * n, buf.begin() + (i + 1) * n, path[i].begin());\n}\n```",
  "gemver": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_gemver(int n,\n                   double alpha,\n                   double beta,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& u1,\n                   std::vector<double>& v1,\n                   std::vector<double>& u2,\n                   std::vector<double>& v2,\n                   std::vector<double>& w,\n                   std::vector<double>& x,\n                   std::vector<double>& y,\n                   std::vector<double>& z)\n{\n    /* 1) Update A:  A[i][j] += u1[i]*v1[j] + u2[i]*v2[j] */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double ui1 = u1[i];\n        double ui2 = u2[i];\n        std::vector<double> &Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            Ai[j] += ui1 * v1[j] + ui2 * v2[j];\n        }\n    }\n\n    /* 2) Update x:  x[i] += beta * \u03a3_j A[j][i] * y[j] */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double bi = beta;\n        double yi = y[i];          // unused in this loop but kept for symmetry\n        double * xi = &x[i];\n        for (int j = 0; j < n; ++j) {\n            *xi += bi * A[j][i] * y[j];\n        }\n    }\n\n    /* 3) Add z to x */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        x[i] += z[i];\n    }\n\n    /* 4) Update w:  w[i] += alpha * \u03a3_j A[i][j] * x[j] */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double ai = alpha;\n        double xi = x[i];\n        std::vector<double> &Ai = A[i];\n        double * wi = &w[i];\n        for (int j = 0; j < n; ++j) {\n            *wi += ai * Ai[j] * x[j];\n        }\n    }\n}\n```",
  "lu": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_lu(int n,\n\t       std::vector<std::vector<double>>& A) {\n\n    /* Convert vector of vectors into an array of row pointers\n       for fast pointer-based access. */\n    std::vector<double*> row(n);\n    for (int i = 0; i < n; ++i)\n        row[i] = A[i].data();\n\n    /* Perform LU factorisation with explicit bounds checks\n       removed for speed. The algorithm follows the same\n       mathematical steps as the reference. */\n    for (int i = 0; i < n; ++i) {\n        /* U part : j < i */\n        for (int j = 0; j < i; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < j; ++k)\n                sum += row[i][k] * row[k][j];\n            row[i][j] -= sum;\n            row[i][j] /= row[j][j];\n        }\n\n        /* L part : j \u2265 i */\n        for (int j = i; j < n; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < i; ++k)\n                sum += row[i][k] * row[k][j];\n            row[i][j] -= sum;\n        }\n    }\n}\n```",
  "deriche": "```cpp\n#include <cmath>\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\n/* Optimised kernel \u2013 same interface, identical semantics */\nvoid kernel_deriche(int w, int h, double alpha,\n                    std::vector<std::vector<float>>& imgIn,\n                    std::vector<std::vector<float>>& imgOut,\n                    std::vector<std::vector<float>>& y1,\n                    std::vector<std::vector<float>>& y2)\n{\n    /* Pre\u2011compute constants once */\n    const float exp_a  = std::exp(-static_cast<float>(alpha));\n    const float exp_2a = exp_a * exp_a;               // exp(-2\u03b1)\n    const float k = 1.0f - exp_a * (1.0f - exp_a) /\n                          (1.0f + 2.0f * static_cast<float>(alpha) * exp_a - exp_2a);\n\n    const float a1 = k, a5 = k;\n    const float a2 = k * exp_a * (static_cast<float>(alpha) - 1.0f);\n    const float a6 = a2;\n    const float a3 = k * exp_a * (static_cast<float>(alpha) + 1.0f);\n    const float a7 = a3;\n    const float a4 = a8 = -k * exp_2a;\n\n    const float b1 = std::pow(2.0f, -static_cast<float>(alpha));\n    const float b2 = -exp_2a;\n\n    const float c1 = 1.0f, c2 = 1.0f;\n\n    /* ---------- 1st pass : forward scan in rows ---------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i) {\n        float ym1 = 0.0f, ym2 = 0.0f, xm1 = 0.0f;\n        for (int j = 0; j < h; ++j) {\n            const float val = imgIn[i][j];\n            const float y = a1 * val + a2 * xm1 + b1 * ym1 + b2 * ym2;\n            y1[i][j] = y;\n            xm1 = val;\n            ym2 = ym1;\n            ym1 = y;\n        }\n    }\n\n    /* ---------- 2nd pass : backward scan in rows ---------- */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < w; ++i) {\n        float xp1 = 0.0f, xp2 = 0.0f, yp1 = 0.0f, yp2 = 0.0f;\n        for (int j = h - 1; j >= 0; --j) {\n            const float y = a3 * xp1 + a4 * xp2 + b1 * yp1 + b2 * yp2;\n            y2[i][j] = y;\n            xp2 = xp1;\n            xp1 = imgIn[i][j];\n            yp2 = yp1;\n            yp1 = y;\n        }\n    }\n\n    /* ---------- 3rd pass : combine forward and backward ---------- */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i) {\n        for (int j = 0; j < h; ++j) {\n            imgOut[i][j] = c1 * (y1[i][j] + y2[i][j]);\n        }\n    }\n\n    /* ---------- 4th pass : forward scan in columns ---------- */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j) {\n        float tm1 = 0.0f, ym1 = 0.0f, ym2 = 0.0f;\n        for (int i = 0; i < w; ++i) {\n            const float val = imgOut[i][j];\n            const float y = a5 * val + a6 * tm1 + b1 * ym1 + b2 * ym2;\n            y1[i][j] = y;\n            tm1 = val;\n            ym2 = ym1;\n            ym1 = y;\n        }\n    }\n\n    /* ---------- 5th pass : backward scan in columns ---------- */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < h; ++j) {\n        float tp1 = 0.0f, tp2 = 0.0f, yp1 = 0.0f, yp2 = 0.0f;\n        for (int i = w - 1; i >= 0; --i) {\n            const float y = a7 * tp1 + a8 * tp2 + b1 * yp1 + b2 * yp2;\n            y2[i][j] = y;\n            tp2 = tp1;\n            tp1 = imgOut[i][j];\n            yp2 = yp1;\n            yp1 = y;\n        }\n    }\n\n    /* ---------- 6th pass : final combine ---------- */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int i = 0; i < w; ++i) {\n        for (int j = 0; j < h; ++j) {\n            imgOut[i][j] = c2 * (y1[i][j] + y2[i][j]);\n        }\n    }\n}\n```",
  "seidel_2d": "```cpp\n#include <vector>\n#include <algorithm>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_seidel_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A) {\n    // Pre\u2011compute constants\n    constexpr double inv9 = 1.0 / 9.0;\n\n    // Temporary pointers for rows to avoid repeated A[i] lookups\n    double *row_prev, *row_cur, *row_next;\n\n    for (int t = 0; t < tsteps; ++t) {\n        for (int i = 1; i <= n - 2; ++i) {\n            row_prev = A[i - 1].data();\n            row_cur  = A[i].data();\n            row_next = A[i + 1].data();\n\n            // Vectorised / unrolled loop over j\n            int j = 1;\n            for (; j <= n - 5; j += 4) {\n                double sum0 = (row_prev[j - 1] + row_prev[j]     + row_prev[j + 1] +\n                               row_cur [j - 1] + row_cur [j]     + row_cur [j + 1] +\n                               row_next[j - 1] + row_next[j]     + row_next[j + 1]) * inv9;\n                double sum1 = (row_prev[j]   + row_prev[j + 1]   + row_prev[j + 2] +\n                               row_cur [j]   + row_cur [j + 1]   + row_cur [j + 2] +\n                               row_next[j]   + row_next[j + 1]   + row_next[j + 2]) * inv9;\n                double sum2 = (row_prev[j + 1]+ row_prev[j + 2]   + row_prev[j + 3] +\n                               row_cur [j + 1]+ row_cur [j + 2]   + row_cur [j + 3] +\n                               row_next[j + 1]+ row_next[j + 2]   + row_next[j + 3]) * inv9;\n                double sum3 = (row_prev[j + 2]+ row_prev[j + 3]   + row_prev[j + 4] +\n                               row_cur [j + 2]+ row_cur [j + 3]   + row_cur [j + 4] +\n                               row_next[j + 2]+ row_next[j + 3]   + row_next[j + 4]) * inv9;\n\n                row_cur[j]     = sum0;\n                row_cur[j + 1] = sum1;\n                row_cur[j + 2] = sum2;\n                row_cur[j + 3] = sum3;\n            }\n\n            // Handle remaining columns\n            for (; j <= n - 2; ++j) {\n                row_cur[j] = (row_prev[j - 1] + row_prev[j] + row_prev[j + 1] +\n                              row_cur [j - 1] + row_cur [j] + row_cur [j + 1] +\n                              row_next[j - 1] + row_next[j] + row_next[j + 1]) * inv9;\n            }\n        }\n    }\n}\n```"
}