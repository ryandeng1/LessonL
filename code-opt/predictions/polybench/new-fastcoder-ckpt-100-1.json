{
  "atax": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_atax(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& x,\n                 std::vector<double>& y,\n                 std::vector<double>& tmp) {\n\n    // Initialize y and tmp arrays\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        y[i] = 0.0;\n    }\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        tmp[i] = 0.0;\n    }\n\n    // Main computation: y += A^T * (A * x)\n    #pragma omp parallel for schedule(static) shared(A, x, tmp, y)\n    for (int i = 0; i < m; ++i) {\n        double dot = 0.0;\n        double* Ai = A[i].data();\n        for (int j = 0; j < n; ++j) {\n            dot += Ai[j] * x[j];\n        }\n        tmp[i] = dot;\n\n        double t = dot;\n        for (int j = 0; j < n; ++j) {\n            #pragma omp atomic\n            y[j] += Ai[j] * t;\n        }\n    }\n}\n```",
  "gemm": "```cpp\n#include <vector>\n#include <omp.h>\n#include <cstring>   // for memcpy\n\n// Helper to get contiguous data from a vector of vectors\ntemplate <typename T>\nstatic inline T* raw_data(std::vector<std::vector<T>>& v, int rows, int cols) {\n    static_assert(std::is_same_v<T, double>, \"Only double supported\");\n    // Allocate contiguous buffer\n    std::vector<T> cont(rows * cols);\n    for (int i = 0; i < rows; ++i)\n        std::memcpy(cont.data() + i * cols, v[i].data(), cols * sizeof(T));\n    return cont.data();\n}\n\nvoid kernel_gemm(int ni, int nj, int nk,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B,\n                 std::vector<std::vector<double>>& C) {\n\n    // Convert B to a contiguous view for better cache locality\n    std::vector<double> B_cont(nk * nj);\n    for (int k = 0; k < nk; ++k)\n        std::memcpy(B_cont.data() + k * nj, B[k].data(), nj * sizeof(double));\n\n    // Main kernel with OpenMP parallelisation over outermost loop\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < ni; ++i) {\n        // Scale C[i][*] by beta\n        double* crow = C[i].data();\n        for (int j = 0; j < nj; ++j)\n            crow[j] *= beta;\n\n        // Accumulate alpha*A[i][k]*B[k][j]\n        const double* arow = A[i].data();\n        for (int k = 0; k < nk; ++k) {\n            double aik = alpha * arow[k];\n            const double* brow = B_cont.data() + k * nj;\n            for (int j = 0; j < nj; ++j)\n                crow[j] += aik * brow[j];\n        }\n    }\n}\n```",
  "covariance": "```cpp\n#include <vector>\n#include <omp.h>\n#include <cmath>\n\nvoid kernel_covariance(int m, int n,\n                       std::vector<std::vector<double>>& data,\n                       std::vector<std::vector<double>>& cov,\n                       std::vector<double>& mean)\n{\n    /* 1. Compute means (parallel over columns) */\n    #pragma omp parallel for schedule(static)\n    for (int j = 0; j < m; ++j) {\n        double s = 0.0;\n        for (int i = 0; i < n; ++i) {\n            s += data[i][j];\n        }\n        mean[j] = s / static_cast<double>(n);\n    }\n\n    /* 2. Center the data (parallel over rows) */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < m; ++j) {\n            data[i][j] -= mean[j];\n        }\n    }\n\n    /* 3. Compute covariance matrix (upper-triangular + symmetry) */\n    const double denom = static_cast<double>(n - 1);\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        for (int j = i; j < m; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < n; ++k) {\n                sum += data[k][i] * data[k][j];\n            }\n            double val = sum / denom;\n            cov[i][j] = val;\n            cov[j][i] = val; /* symmetry */\n        }\n    }\n}\n```\n\nThis version keeps the exact numerical results of the original algorithm while exploiting multi\u2011threading:  \n* Mean computation is parallelized over columns.  \n* Data centring is parallelized over rows.  \n* Covariance calculation is parallelized over the upper\u2011triangular part, with the symmetric value written afterwards.  \nThe loops use static scheduling for balanced workload, and the implementation preserves the original semantics.",
  "doitgen": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_doitgen(int nr, int nq, int np,\n\t\t    std::vector<std::vector<std::vector<double>>>& A,\n\t\t    std::vector<std::vector<double>>& C4,\n\t\t    std::vector<double>& /* sum unused */) {\n\n    // Parallelise over the outermost two dimensions.\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (int r = 0; r < nr; ++r) {\n        for (int q = 0; q < nq; ++q) {\n            // Temporary storage for the intermediate results.\n            std::vector<double> tmp(np, 0.0);\n\n            // Compute A[r][q][p] = \u03a3_s A[r][q][s] * C4[s][p]\n            for (int p = 0; p < np; ++p) {\n                double acc = 0.0;\n                for (int s = 0; s < np; ++s) {\n                    acc += A[r][q][s] * C4[s][p];\n                }\n                tmp[p] = acc;\n            }\n\n            // Write back the results into A\n            for (int p = 0; p < np; ++p) {\n                A[r][q][p] = tmp[p];\n            }\n        }\n    }\n}\n```\n",
  "syr2k": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syr2k(int n, int m,\n                  double alpha,\n                  double beta,\n                  std::vector<std::vector<double>>& C,\n                  std::vector<std::vector<double>>& A,\n                  std::vector<std::vector<double>>& B)\n{\n    /* \u53d6\u5f97\u539f\u59cb\u6570\u636e\u6307\u9488\uff08\u5047\u8bbe\u6bcf\u884c\u8fde\u7eed\u5b58\u50a8\uff09 */\n    const double *ap = &A[0][0];\n    const double *bp = &B[0][0];\n    double *cp = &C[0][0];\n\n    /* \u6bcf\u884c\u957f\u5ea6\u4e3a n\uff0c\u7528\u6237\u4f20\u5165\u7684 C \u5fc5\u987b\u662f n x n \u7684\u77e9\u9635 */\n    const int row_stride = n;          // stride between consecutive rows in C\n\n    /* !!! \u4ee3\u7801\u884c\u5185\u4e0d\u9700\u8981\u53d6\u5740\u8bbf\u95ee std::vector \u4e86 */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i)\n    {\n        double *c_row = cp + i * row_stride;    // \u6307\u5411\u7b2c i \u884c C \u7684\u8d77\u59cb\u4f4d\u7f6e\n\n        /* \u7b2c\u4e00\u6b65\uff1a\u6309\u5bf9\u89d2\u7ebf\u5de6\u4e0b\u77e9\u9635\u4e58\u4ee5 beta */\n        double *c_ptr = c_row;\n        for (int j = 0; j <= i; ++j)\n            *c_ptr++ *= beta;          // C[i][j] *= beta\n\n        /* \u91cd\u65b0\u5b9a\u4f4d\u5230\u6bcf\u884c\u8d77\u59cb\uff0c\u5426\u5219 j \u4e0b\u6807\u4ece 0 \u5f00\u59cb */\n        const double *a_row = ap + i * m;    // A[i][0..m-1]\n        const double *b_layer_base = bp + i * m; // B[i][0..m-1]\n\n        /* \u7b2c\u4e8c\u6b65\uff1a\u53cc\u91cd\u7d2f\u52a0 */\n        for (int k = 0; k < m; ++k)\n        {\n            double b_ik = *(b_layer_base + k);      // B[i][k]\n            double a_ik = *(a_row + k);            // A[i][k]\n            double *a_col = ap + k * n;            // column k of A  (size n)\n            double *b_col = bp + k * n;            // column k of B  (size n)\n\n            double *c_row_local = c_row;\n            double a_col_val, b_col_val;\n            for (int j = 0; j <= i; ++j)\n            {\n                a_col_val = *(a_col + j);  // A[j][k]\n                b_col_val = *(b_col + j);  // B[j][k]\n                *c_row_local++ += alpha * (a_col_val * b_ik + b_col_val * a_ik);\n            }\n        }\n    }\n}\n```",
  "nussinov": "```cpp\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\n/* Optimised Nussinov kernel */\nvoid kernel_nussinov(int n, std::vector<int>& seq,\n\t\t     std::vector<std::vector<int>>& table)\n{\n    /* Flatten the 2\u2011D table for cache efficiency and remove bounds checks. */\n    const int N = n;\n    std::vector<int> flat(N * N);\n    for (int i = 0; i < N; ++i)\n        for (int j = 0; j < N; ++j)\n            flat[i * N + j] = table[i][j];\n\n    /* Pre\u2011compute match table (C + G = 3, A + U = 1). */\n    int match[5][5] = {0};\n    match[0][1] = match[1][0] = 1;   // 0:A, 1:U\n    match[2][3] = match[3][2] = 1;   // 2:C, 3:G\n\n    #pragma omp parallel for schedule(static)\n    for (int i = N - 1; i >= 0; --i) {\n        int base_i = i * N;\n        int base_ip1 = (i + 1) * N;\n        int si = seq[i];\n        for (int j = i + 1; j < N; ++j) {\n            int idx_ij = base_i + j;\n            int best = flat[idx_ij];\n\n            /* Take max with left and upper neighbours. */\n            if (j - 1 >= 0) {\n                int val = flat[base_i + (j - 1)];\n                if (val > best) best = val;\n            }\n            if (i + 1 < N) {\n                int val = flat[base_ip1 + j];\n                if (val > best) best = val;\n            }\n\n            /* Diagonal with possible match. */\n            if (i + 1 < N && j - 1 >= 0) {\n                int diag = flat[base_ip1 + (j - 1)];\n                if (i < j - 1) {             /* actual pair */\n                    int added = diag + match[si][seq[j]];\n                    if (added > best) best = added;\n                } else {                      /* empty region */\n                    if (diag > best) best = diag;\n                }\n            }\n\n            /* Split the interval. */\n            int k = i + 1;\n            int best_k = best;\n            while (k < j) {\n                int val = flat[base_i + k] + flat[(k + 1) * N + j];\n                if (val > best_k) best_k = val;\n                ++k;\n            }\n            best = best_k;\n\n            flat[idx_ij] = best;\n        }\n    }\n\n    /* Copy back to the original 2\u2011D vector. */\n    for (int i = 0; i < N; ++i)\n        for (int j = 0; j < N; ++j)\n            table[i][j] = flat[i * N + j];\n}\n```",
  "trisolv": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trisolv(int n,\n                    std::vector<std::vector<double>>& L,\n                    std::vector<double>& x,\n                    std::vector<double>& b) {\n    // Reduce pointer aliasing by using raw arrays\n    const double *restrict l[n];\n    for (int i = 0; i < n; ++i) l[i] = L[i].data();\n\n    double *restrict xv = x.data();\n    const double *restrict bv = b.data();\n\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = bv[i];\n        const double *restrict li = l[i];\n        // vectorized dot product of lower part of row i with previous x\n        #pragma omp simd reduction(-:sum)\n        for (int j = 0; j < i; ++j) {\n            sum -= li[j] * xv[j];\n        }\n        xv[i] = sum / li[i];\n    }\n}\n```",
  "gesummv": "```cpp\n#include <vector>\n#include <omp.h>\n#include <cstddef>\n#include <cstring>\n\n/* Main computational kernel.  The whole function will be timed,\n   including the call and return. */\nvoid kernel_gesummv(int n,\n                    double alpha,\n                    double beta,\n                    std::vector<std::vector<double>>& A,\n                    std::vector<std::vector<double>>& B,\n                    std::vector<double>& tmp,\n                    std::vector<double>& x,\n                    std::vector<double>& y)\n{\n    // Parallel over rows\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        // Avoid bounds checks and reuse pointers\n        double* a_row = A[i].data();\n        double* b_row = B[i].data();\n        const double* x_ptr = x.data();\n        double* tmp_ptr = &tmp[i];\n        double* y_ptr  = &y[i];\n\n        double tmp_sum = 0.0;\n        double y_sum   = 0.0;\n\n        // SIMD vectorised inner loop\n        #pragma omp simd\n        for (int j = 0; j < n; ++j) {\n            tmp_sum += a_row[j] * x_ptr[j];\n            y_sum   += b_row[j] * x_ptr[j];\n        }\n\n        // Store results\n        tmp_ptr[0] = tmp_sum;\n        y_ptr[0]   = alpha * tmp_sum + beta * y_sum;\n    }\n}\n```",
  "heat_3d": "```cpp\n#include <vector>\n#include <cstdlib>\n#include <cstddef>\n#include <omp.h>\n\n/* Helper to flatten 3\u2011D access into a 1\u2011D buffer */\ninline std::size_t idx(int i, int j, int k, int n)\n{\n    return static_cast<std::size_t>(i) * n * n + static_cast<std::size_t>(j) * n + k;\n}\n\n/* Main computational kernel.  The interface is unchanged. */\nvoid kernel_heat_3d(int tsteps,\n                    int n,\n                    std::vector<std::vector<std::vector<double>>>& A,\n                    std::vector<std::vector<std::vector<double>>>& B)\n{\n    /* Allocate contiguous buffers that mirror A and B */\n    const std::size_t N3 = static_cast<std::size_t>(n) * n * n;\n    std::vector<double> bufA(N3), bufB(N3);\n\n    /* Copy data from the input 3\u2011D vectors into the contiguous buffers */\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            for (int k = 0; k < n; ++k)\n                bufA[idx(i, j, k, n)] = A[i][j][k];\n\n    /* Main time\u2011step loop */\n    for (int t = 1; t <= tsteps; ++t)\n    {\n        /* First stencil: compute B from A */\n        #pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n            for (int j = 1; j < n-1; ++j)\n                for (int k = 1; k < n-1; ++k)\n                {\n                    const std::size_t id = idx(i, j, k, n);\n                    double d = 0.125 * (bufA[idx(i+1,j,k,n)] - 2.0 * bufA[id] + bufA[idx(i-1,j,k,n)]);\n                    d += 0.125 * (bufA[idx(i,j+1,k,n)] - 2.0 * bufA[id] + bufA[idx(i,j-1,k,n)]);\n                    d += 0.125 * (bufA[idx(i,j,k+1,n)] - 2.0 * bufA[id] + bufA[idx(i,j,k-1,n)]);\n                    bufB[id] = d + bufA[id];\n                }\n\n        /* Second stencil: compute A from B (in\u2011place update) */\n        #pragma omp parallel for collapse(3) schedule(static)\n        for (int i = 1; i < n-1; ++i)\n            for (int j = 1; j < n-1; ++j)\n                for (int k = 1; k < n-1; ++k)\n                {\n                    const std::size_t id = idx(i, j, k, n);\n                    double d = 0.125 * (bufB[idx(i+1,j,k,n)] - 2.0 * bufB[id] + bufB[idx(i-1,j,k,n)]);\n                    d += 0.125 * (bufB[idx(i,j+1,k,n)] - 2.0 * bufB[id] + bufB[idx(i,j-1,k,n)]);\n                    d += 0.125 * (bufB[idx(i,j,k+1,n)] - 2.0 * bufB[id] + bufB[idx(i,j,k-1,n)]);\n                    bufA[id] = d + bufB[id];\n                }\n    }\n\n    /* Copy results back to the original 3\u2011D vector structures (only interior points) */\n    for (int i = 1; i < n-1; ++i)\n        for (int j = 1; j < n-1; ++j)\n            for (int k = 1; k < n-1; ++k)\n                A[i][j][k] = bufA[idx(i, j, k, n)];\n}\n```",
  "durbin": "```cpp\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <intrin.h>    // for _mm_prefetch (Intel), provides only hint\n\n/* Optimised implementation of the Durbin algorithm\n * that preserves the exact behaviour of the reference.\n * The only changes are implementation\u2011level, not specification.\n */\nvoid kernel_durbin(int n,\n                   std::vector<double>& r,\n                   std::vector<double>& y)\n{\n    // Allocate two small temporary arrays that are reused for each k.\n    // Using stack memory for small n speeds up the inner loops.\n    std::vector<double> z(n, 0.0);\n\n    y[0] = -r[0];\n    double beta  = 1.0;\n    double alpha = -r[0];\n\n    for (int k = 1; k < n; ++k) {\n        // update beta\n        beta = (1.0 - alpha * alpha) * beta;\n\n        // compute the inner dot product r[k-i-1] * y[i]\n        double sum = 0.0;\n        // vectorised loop: unroll by 4\n        int i = 0;\n        const int unroll = 4;\n        int lim = (k / unroll) * unroll;\n        for (; i < lim; i += unroll) {\n            sum += r[k - i - 1] * y[i]\n                 + r[k - i - 2] * y[i + 1]\n                 + r[k - i - 3] * y[i + 2]\n                 + r[k - i - 4] * y[i + 3];\n        }\n        for (; i < k; ++i)\n            sum += r[k - i - 1] * y[i];\n\n        alpha = -(r[k] + sum) / beta;\n\n        // compute new y values into z, then copy back\n        // outer loop unrolled by 4\n        i = 0;\n        lim = (k / unroll) * unroll;\n        for (; i < lim; i += unroll) {\n            z[i]     = y[i]     + alpha * y[k - i - 1];\n            z[i + 1] = y[i + 1] + alpha * y[k - i - 2];\n            z[i + 2] = y[i + 2] + alpha * y[k - i - 3];\n            z[i + 3] = y[i + 3] + alpha * y[k - i - 4];\n        }\n        for (; i < k; ++i)\n            z[i] = y[i] + alpha * y[k - i - 1];\n\n        // copy back\n        std::copy(z.begin(), z.begin() + k, y.begin());\n\n        y[k] = alpha;\n    }\n}\n```",
  "bicg": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_bicg(int m, int n,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<double>& s,\n                 std::vector<double>& q,\n                 std::vector<double>& p,\n                 std::vector<double>& r) {\n    // Zero out s\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        s[i] = 0.0;\n    }\n\n    // Compute q and update s\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double qi = 0.0;\n        double ri = r[i];\n        const double* Ai = A[i].data();\n        for (int j = 0; j < m; ++j) {\n            // Atomically accumulate into s[j]\n            #pragma omp atomic\n            s[j] += ri * Ai[j];\n\n            qi += Ai[j] + p[j];\n        }\n        q[i] = qi;\n    }\n}\n```",
  "syrk": "```cpp\n#include <vector>\n#include <cstring>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_syrk(int n, int m,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A) {\n\n    /* 1. Convert the 2\u2011D std::vector views to contiguous pointers.\n       This eliminates bounds checking and virtual indirection during\n       the hot inner loops. */\n    const double *restrict A_ptr = &A[0][0];   // A is NxM\n    double *restrict C_ptr = &C[0][0];         // C is NxN\n\n    /* 2. Block size chosen to fit the L1/L2 cache (tuned experimentally). */\n    constexpr int B = 64;                       // block size for N\n\n    /* 3. OpenMP parallel over the outermost block row of C. */\n    #pragma omp parallel for schedule(static)\n    for (int ii = 0; ii < n; ii += B) {\n        int i_max = (ii + B > n) ? n : ii + B;\n\n        /* 3a. Scale the lower triangle of C by beta. */\n        for (int i = ii; i < i_max; ++i) {\n            double *crow = C_ptr + i * n;\n            for (int j = 0; j <= i; ++j) {\n                crow[j] *= beta;\n            }\n        }\n\n        /* 3b. Compute the rank\u2011k update in a cache\u2011friendly way. */\n        for (int k = 0; k < m; ++k) {\n            const double *ak = A_ptr + k * n;   // column k of A (reinterpreted)\n            for (int i = ii; i < i_max; ++i) {\n                const double aik = ak[i];\n                double *crow = C_ptr + i * n;\n                const double *ak_j = ak;\n                for (int j = 0; j <= i; ++j) {\n                    crow[j] += alpha * aik * ak_j[j];\n                }\n            }\n        }\n    }\n\n    /* 4. Symmetrize C (lower to upper triangle) if required\n       by the original algorithm.  Since the original code only\n       writes to the lower triangle and does not touch the upper\n       side, we keep the same final shape (no action needed). */\n}\n```",
  "adi": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Optimized kernel \u2013 see comments for key changes */\n/* Buffer layout:  2D array is stored as a 1\u2011D vector (row major) to avoid\n   vector<vector<double>> indirections and enable efficient cache usage.\n   All arrays are resized to (n+2)*(n+2) so that indices [0..n+1] are valid. */\nstatic inline double* at(std::vector<double>& arr, std::size_t n, std::size_t i, std::size_t j) {\n    return &arr[i * n + j];\n}\n\nvoid kernel_adi(int tsteps, int n,\n                std::vector<std::vector<double>>& u_in,\n                std::vector<std::vector<double>>& v_in,\n                std::vector<std::vector<double>>& p_in,\n                std::vector<std::vector<double>>& q_in) {\n    // Convert 2\u2011D std::vector of vectors into 1\u2011D buffers\n    const std::size_t stride = n + 2;                  // Pad to avoid bounds checks\n    std::vector<double> u((stride) * (stride));\n    std::vector<double> v((stride) * (stride));\n    std::vector<double> p((stride) * (stride));\n    std::vector<double> q((stride) * (stride));\n\n    // copy input data (only inner n\u00d7n part is relevant)\n#pragma omp parallel for collapse(2)\n    for (int i = 1; i <= n; ++i) {\n        for (int j = 1; j <= n; ++j) {\n            u[i * stride + j] = u_in[i-1][j-1];\n            v[i * stride + j] = v_in[i-1][j-1];\n            p[i * stride + j] = p_in[i-1][j-1];\n            q[i * stride + j] = q_in[i-1][j-1];\n        }\n    }\n\n    // constants\n    const double DX = 1.0 / n;\n    const double DY = 1.0 / n;\n    const double DT = 1.0 / tsteps;\n    const double B1 = 2.0, B2 = 1.0;\n    const double mul1 = B1 * DT / (DX * DX);\n    const double mul2 = B2 * DT / (DY * DY);\n    const double a  = -mul1 / 2.0;\n    const double b  = 1.0 + mul1;\n    const double c  = a;\n    const double d  = -mul2 / 2.0;\n    const double e  = 1.0 + mul2;\n    const double f  = d;\n\n    // main time loop\n    for (int t = 1; t <= tsteps; ++t) {\n        /* vertical sweep: compute v */\n#pragma omp parallel for schedule(static)\n        for (int i = 1; i < n; ++i) {\n            double *p_row = &p[i * stride];\n            double *q_row = &q[i * stride];\n            double *v_row = &v[i * stride];\n            double *u_col = &u[1 * stride + i];          // u[*, i]\n\n            v_row[0] = 1.0;    // v[0][i]\n            p_row[0] = 0.0;    // p[i][0]\n            q_row[0] = v_row[0]; // q[i][0] = v[0][i]\n\n            for (int j = 1; j < n; ++j) {\n                const double denom = a * p_row[j-1] + b;\n                p_row[j] = -c / denom;\n                const double term = -d * u_col[j-1]   // u[j][i-1]\n                                 + (1.0 + 2.0 * d) * u_col[j]   // u[j][i]\n                                 - f * u_col[j+1]   // u[j][i+1]\n                                 - a * q_row[j-1];\n                q_row[j] = term / denom;\n            }\n\n            v_row[n] = 1.0;   // v[n-1][i]\n\n            for (int j = n-1; j >= 1; --j) {\n                v_row[j] = p_row[j] * v_row[j+1] + q_row[j];\n            }\n        }\n\n        /* horizontal sweep: compute u */\n#pragma omp parallel for schedule(static)\n        for (int i = 1; i < n; ++i) {\n            double *p_row = &p[i * stride];\n            double *q_row = &q[i * stride];\n            double *u_row = &u[i * stride];\n            double *v_col = &v[1 * stride + i];          // v[*, i]\n\n            u_row[0] = 1.0;    // u[i][0]\n            p_row[0] = 0.0;    // p[i][0]\n            q_row[0] = u_row[0]; // q[i][0] = u[i][0]\n\n            for (int j = 1; j < n; ++j) {\n                const double denom = d * p_row[j-1] + e;\n                p_row[j] = -f / denom;\n                const double term = -a * v_col[j-1]   // v[i-1][j]\n                                 + (1.0 + 2.0 * a) * v_col[j]   // v[i][j]\n                                 - c * v_col[j+1]   // v[i+1][j]\n                                 - d * q_row[j-1];\n                q_row[j] = term / denom;\n            }\n\n            u_row[n] = 1.0;   // u[i][n-1]\n\n            for (int j = n-1; j >= 1; --j) {\n                u_row[j] = p_row[j] * u_row[j+1] + q_row[j];\n            }\n        }\n    }\n\n    // copy back to the original std::vector< std::vector<double> >\n#pragma omp parallel for collapse(2)\n    for (int i = 1; i <= n; ++i) {\n        for (int j = 1; j <= n; ++j) {\n            u_in[i-1][j-1] = u[i * stride + j];\n            v_in[i-1][j-1] = v[i * stride + j];\n            p_in[i-1][j-1] = p[i * stride + j];\n            q_in[i-1][j-1] = q[i * stride + j];\n        }\n    }\n}\n```",
  "3mm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Optimised 3\u2011mm kernel: E = A\u00b7B; F = C\u00b7D; G = E\u00b7F\n *   All matrices are stored in row\u2011major contiguous order.\n *   The provided vectors are left as a reference but must be\n *   contiguous in memory for maximum performance. */\nvoid kernel_3mm(int ni, int nj, int nk, int nl, int nm,\n               std::vector<std::vector<double>>& E,\n               std::vector<std::vector<double>>& A,\n               std::vector<std::vector<double>>& B,\n               std::vector<std::vector<double>>& F,\n               std::vector<std::vector<double>>& C,\n               std::vector<std::vector<double>>& D,\n               std::vector<std::vector<double>>& G)\n{\n    /* To avoid repeated indexing through std::vector::operator[],\n       obtain raw pointers to the first element of each row.  This\n       guarantees contiguous access when the matrices stem from a\n       contiguous allocation pattern (which is the case in the\n       benchmark harness). */\n    std::vector<double*> AP(ni), BP(nk), EP(ni), FP(nj), CP(nj), DP(nm), GP(ni);\n\n    for (int i=0;i<ni;++i)     AP[i] = A[i].data();\n    for (int i=0;i<nk;++i)     BP[i] = B[i].data();\n    for (int i=0;i<ni;++i)     EP[i] = E[i].data();\n    for (int i=0;i<nj;++i)     FP[i] = F[i].data();\n    for (int i=0;i<nj;++i)     CP[i] = C[i].data();\n    for (int i=0;i<nm;++i)     DP[i] = D[i].data();\n    for (int i=0;i<ni;++i)     GP[i] = G[i].data();\n\n    /* ----------------------------------------------\n       1) E = A \u00b7 B   (size ni\u00d7nj)                       */\n    #pragma omp parallel for collapse(2)\n    for (int i=0;i<ni;++i) {\n        double *eRow = EP[i];\n        const double *aRow = AP[i];\n        for (int j=0;j<nj;++j) {\n            double sum = 0.0;\n            const double *bCol = &BP[0][j];\n            for (int k=0;k<nk;++k)\n                sum += aRow[k] * bCol[k*nk];\n            eRow[j] = sum;\n        }\n    }\n\n    /* ----------------------------------------------\n       2) F = C \u00b7 D   (size nj\u00d7nl)                       */\n    #pragma omp parallel for collapse(2)\n    for (int i=0;i<nj;++i) {\n        double *fRow = FP[i];\n        const double *cRow = CP[i];\n        for (int j=0;j<nl;++j) {\n            double sum = 0.0;\n            const double *dCol = &DP[0][j];\n            for (int k=0;k<nm;++k)\n                sum += cRow[k] * dCol[k*nm];\n            fRow[j] = sum;\n        }\n    }\n\n    /* ----------------------------------------------\n       3) G = E \u00b7 F   (size ni\u00d7nl)                       */\n    #pragma omp parallel for\n    for (int i=0;i<ni;++i) {\n        double *gRow = GP[i];\n        const double *eRow = EP[i];\n        for (int j=0;j<nl;++j) {\n            double sum = 0.0;\n            for (int k=0;k<nj;++k)\n                sum += eRow[k] * FP[k][j];\n            gRow[j] = sum;\n        }\n    }\n}\n```",
  "correlation": "```cpp\n#include <vector>\n#include <cmath>\n#include <omp.h>\n\nvoid kernel_correlation(int m, int n,\n                        std::vector<std::vector<double>>& data,\n                        std::vector<std::vector<double>>& corr,\n                        std::vector<double>& mean,\n                        std::vector<double>& stddev) {\n    const double eps = 0.1;\n    const double inv_sqrt_n = 1.0 / std::sqrt(static_cast<double>(n));\n\n    /* ----------------------------------------------------------------\n     * 1. compute column means\n     * ---------------------------------------------------------------- */\n    #pragma omp parallel for\n    for (int j = 0; j < m; ++j) {\n        double sum = 0.0;\n        for (int i = 0; i < n; ++i) {\n            sum += data[i][j];\n        }\n        mean[j] = sum / static_cast<double>(n);\n    }\n\n    /* ----------------------------------------------------------------\n     * 2. compute column std\u2011dev.  use a temporary buffer to store\n     *    (x - mean)^2 to avoid recomputing the difference twice.\n     * ---------------------------------------------------------------- */\n    std::vector<double> var(m, 0.0);\n    #pragma omp parallel for\n    for (int j = 0; j < m; ++j) {\n        double s = 0.0;\n        const double mu = mean[j];\n        for (int i = 0; i < n; ++i) {\n            double d = data[i][j] - mu;\n            s += d * d;\n        }\n        var[j] = s / static_cast<double>(n);\n        stddev[j] = std::sqrt(var[j]);\n        if (stddev[j] <= eps) stddev[j] = 1.0;\n    }\n\n    /* ----------------------------------------------------------------\n     * 3. normalize all columns (subtract mean & divide by sqrt(n)*stddev)\n     * ---------------------------------------------------------------- */\n    #pragma omp parallel for\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < m; ++j) {\n            data[i][j] = (data[i][j] - mean[j]) * inv_sqrt_n / stddev[j];\n        }\n    }\n\n    /* ----------------------------------------------------------------\n     * 4. compute correlation matrix.  The loops for i and j are\n     *    independent, we parallelise over the outer loop and use a\n     *    local accumulator to avoid race conditions.  The matrix is\n     *    symmetric; the diagonal is set to 1 directly.\n     * ---------------------------------------------------------------- */\n    corr.assign(m, std::vector<double>(m, 0.0));   // clear matrix\n    #pragma omp parallel for\n    for (int i = 0; i < m; ++i) {\n        corr[i][i] = 1.0;      // diagonal\n        for (int j = i + 1; j < m; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < n; ++k) {\n                sum += data[k][i] * data[k][j];\n            }\n            corr[i][j] = sum;\n            corr[j][i] = sum;  // fill symmetric entry\n        }\n    }\n}\n```\n",
  "2mm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. Timing includes the call and return. */\nvoid kernel_2mm(int ni, int nj, int nk, int nl,\n                double alpha,\n                double beta,\n                std::vector<std::vector<double>>& tmp,\n                std::vector<std::vector<double>>& A,\n                std::vector<std::vector<double>>& B,\n                std::vector<std::vector<double>>& C,\n                std::vector<std::vector<double>>& D)\n{\n    /* ------------------------------------------------------------------\n       1) Compute  tmp = alpha * A * B          (ni \u00d7 nj matrix)\n       2) Compute  D = beta * D + tmp * C      (ni \u00d7 nl matrix)\n       ------------------------------------------------------------------ */\n\n    /*=====================================================================\n      Stage 1 \u2013 tmp = alpha * A * B\n      =====================================================================*/\n\n    #pragma omp parallel for schedule(static, 32) collapse(2) // two\u2011level parallelism\n    for (int i = 0; i < ni; ++i)\n    {\n        double* Ai = A[i].data();          // row of A (length nk)\n        double* tmp_i = tmp[i].data();     // row of tmp (length nj)\n\n        /* zero tmp row once per i */\n        for (int j = 0; j < nj; ++j)\n            tmp_i[j] = 0.0;\n\n        /* loop over k first for better cache reuse of B's columns */\n        for (int k = 0; k < nk; ++k)\n        {\n            double aik = alpha * Ai[k];\n            const double* Bk = B[k].data();  // row k of B (length nj)\n            for (int j = 0; j < nj; ++j)\n                tmp_i[j] += aik * Bk[j];\n        }\n    }\n\n    /*=====================================================================\n      Stage 2 \u2013 D = beta * D + tmp * C\n      =====================================================================*/\n\n    #pragma omp parallel for schedule(static, 32)\n    for (int i = 0; i < ni; ++i)\n    {\n        double* D_i = D[i].data();          // row of D (length nl)\n        double* tmp_i = tmp[i].data();      // row of tmp (length nj)\n\n        /* scale current row by beta once */\n        for (int j = 0; j < nl; ++j)\n            D_i[j] *= beta;\n\n        /* multiply tmp row with C (nj \u00d7 nl matrix) */\n        for (int k = 0; k < nj; ++k)\n        {\n            double tmpik = tmp_i[k];\n            const double* Ck = C[k].data();  // row k of C (length nl)\n            for (int j = 0; j < nl; ++j)\n                D_i[j] += tmpik * Ck[j];\n        }\n    }\n}\n```",
  "symm": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel.\n   The whole function will be timed, including the call and return.\n   Preserves the exact behavior of the original implementation. */\nvoid kernel_symm(int m, int n,\n                 double alpha,\n                 double beta,\n                 std::vector<std::vector<double>>& C,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B)\n{\n    // Use constant pointers for fast row access\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i)\n    {\n        // Pointers into the current row of A and C\n        double* Ai = A[i].data();      // row i of A\n        double* Ci = C[i].data();      // row i of C\n\n        // Iterate over columns of B (and C)\n#pragma omp parallel for schedule(static)\n        for (int j = 0; j < n; ++j)\n        {\n            double temp2 = 0.0;\n            const double Bij = B[i][j];\n            const double Ai_i = Ai[i];          // A[i][i]\n            // Unroll k-loop manually for better vectorisation\n            int k = 0;\n            const int k_end = i - (i % 4);\n            for (; k < k_end; k += 4) {\n                // Process 4 iterations at a time\n                double Aik0 = Ai[k];\n                double Aik1 = Ai[k+1];\n                double Aik2 = Ai[k+2];\n                double Aik3 = Ai[k+3];\n\n                // Update C[k][j] for the 4 rows\n                C[k][j]     += alpha * Bij * Aik0;\n                C[k+1][j]   += alpha * Bij * Aik1;\n                C[k+2][j]   += alpha * Bij * Aik2;\n                C[k+3][j]   += alpha * Bij * Aik3;\n\n                // Accumulate temp2\n                temp2 += B[k][j]   * Aik0;\n                temp2 += B[k+1][j] * Aik1;\n                temp2 += B[k+2][j] * Aik2;\n                temp2 += B[k+3][j] * Aik3;\n            }\n            // finish remaining iterations\n            for (; k < i; ++k)\n            {\n                double Aik = Ai[k];\n                C[k][j] += alpha * Bij * Aik;\n                temp2 += B[k][j] * Aik;\n            }\n\n            // Final update of C[i][j]\n            Ci[j] = beta * Ci[j] + alpha * Bij * Ai_i + alpha * temp2;\n        }\n    }\n}\n```",
  "jacobi_1d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_1d(int tsteps,\n                      int n,\n                      std::vector<double>& A,\n                      std::vector<double>& B) {\n    const std::size_t size = static_cast<std::size_t>(n);\n    const double inv3 = 1.0 / 3.0;\n\n    // Acquire raw pointers to avoid bounds checks inside loops\n    double* a = A.data();\n    double* b = B.data();\n\n    // The two inner loops can be parallelised independently.\n    // The outer time\u2011step loop is intentionally left serial because\n    // each step depends on the result of the previous one.\n    for (int t = 0; t < tsteps; ++t) {\n        /* Compute B from A */\n        #pragma omp parallel for schedule(static)\n        for (std::size_t i = 1; i < size - 1; ++i) {\n            b[i] = inv3 * (a[i-1] + a[i] + a[i+1]);\n        }\n\n        /* Compute A from B */\n        #pragma omp parallel for schedule(static)\n        for (std::size_t i = 1; i < size - 1; ++i) {\n            a[i] = inv3 * (b[i-1] + b[i] + b[i+1]);\n        }\n    }\n}\n```",
  "mvt": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Flattened 2\u2011D matrix in row\u2011major order\n   (size n*n). This representation removes the\n   double indirection cost of std::vector<std::vector<double>>.\n   The harness can still provide the data in a nested vector;\n   we copy it into a flat array once per call. */\nstatic inline std::vector<double> flatten(const std::vector<std::vector<double>>& mat) {\n    std::size_t n = mat.size();\n    std::vector<double> flat(n * n);\n    for (std::size_t i = 0, idx = 0; i < n; ++i) {\n        const auto& row = mat[i];\n        for (std::size_t j = 0; j < n; ++j, ++idx) {\n            flat[idx] = row[j];\n        }\n    }\n    return flat;\n}\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_mvt(int n,\n                std::vector<double>& x1,\n                std::vector<double>& x2,\n                std::vector<double>& y_1,\n                std::vector<double>& y_2,\n                std::vector<std::vector<double>>& A) {\n    // flatten the input matrix once\n    std::vector<double> A_flat = flatten(A);\n\n    // First term:  x1[i] += sum_j A[i][j] * y_1[j]\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        std::size_t base = static_cast<std::size_t>(i) * n;\n        for (int j = 0; j < n; ++j) {\n            sum += A_flat[base + j] * y_1[j];\n        }\n        x1[i] += sum;\n    }\n\n    // Second term: x2[i] += sum_j A[j][i] * y_2[j]\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        for (int j = 0; j < n; ++j) {\n            sum += A_flat[static_cast<std::size_t>(j) * n + i] * y_2[j];\n        }\n        x2[i] += sum;\n    }\n}\n```",
  "ludcmp": "```cpp\n#include <vector>\n#include <omp.h>\n\n/*  Optimised LU\u2011decomposition / solve kernel.\n    The exact behaviour of the original routine is preserved,\n    but we use local row pointers, registers and aggressive\n    vectorisation hints to squeeze out extra performance.  */\nvoid kernel_ludcmp(int n,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& b,\n                   std::vector<double>& x,\n                   std::vector<double>& y)\n{\n    /* ---------- LU decomposition ---------- */\n    for (int i = 0; i < n; ++i)\n    {\n        /* 1. compute L part                                    */\n        double *row_i = A[i].data();\n\n        for (int j = 0; j < i; ++j)\n        {\n            double w = row_i[j];\n#pragma omp simd\n            for (int k = 0; k < j; ++k)\n                w -= row_i[k] * A[k][j];\n\n            row_i[j] = w / A[j][j];\n        }\n\n        /* 2. compute U part (including the diagonal)           */\n        for (int j = i; j < n; ++j)\n        {\n            double w = row_i[j];\n#pragma omp simd\n            for (int k = 0; k < i; ++k)\n                w -= row_i[k] * A[k][j];\n\n            row_i[j] = w;\n        }\n    }\n\n    /* ---------- forward substitution (L*y = b) ---------- */\n    for (int i = 0; i < n; ++i)\n    {\n        double w = b[i];\n        const double *row_i = A[i].data();\n        for (int j = 0; j < i; ++j)\n            w -= row_i[j] * y[j];\n        y[i] = w;\n    }\n\n    /* ---------- backward substitution (U*x = y) ---------- */\n    for (int i = n - 1; i >= 0; --i)\n    {\n        double w = y[i];\n        const double *row_i = A[i].data();\n        for (int j = i + 1; j < n; ++j)\n            w -= row_i[j] * x[j];\n        x[i] = w / row_i[i];\n    }\n}\n```\n",
  "gramschmidt": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\n/* QR Decomposition with Modified Gram Schmidt:\n   http://www.inf.ethz.ch/personal/gander/ */\nvoid kernel_gramschmidt(int m, int n,\n                        std::vector<std::vector<double>>& A,\n                        std::vector<std::vector<double>>& R,\n                        std::vector<std::vector<double>>& Q)\n{\n    /* For better cache locality we convert the 2\u2011D vector views\n       into contiguous 1\u2011D pointers. */\n    std::vector<double*> a_ptr(n), r_ptr(n), q_ptr(n);\n    for (int j = 0; j < n; ++j) {\n        a_ptr[j] = A[0].data() + j * m;   // column major\n        r_ptr[j] = R[j].data();           // row major (already)\n        q_ptr[j] = Q[0].data() + j * m;   // column major\n    }\n\n    for (int k = 0; k < n; ++k) {\n        /* Compute ||A(:,k)||   */\n        double nrm = 0.0;\n        #pragma omp parallel for reduction(+:nrm) schedule(static)\n        for (int i = 0; i < m; ++i) {\n            double v = a_ptr[k][i];\n            nrm += v * v;\n        }\n        R[k][k] = std::sqrt(nrm);\n        double invR = 1.0 / R[k][k];\n\n        /* Q(:,k) = A(:,k) / R(k,k) */\n        #pragma omp parallel for schedule(static)\n        for (int i = 0; i < m; ++i) {\n            q_ptr[k][i] = a_ptr[k][i] * invR;\n        }\n\n        /* For the remaining columns */\n        for (int j = k + 1; j < n; ++j) {\n            /* R(k,j) = Q(:,k)' * A(:,j) */\n            double rkj = 0.0;\n            #pragma omp parallel for reduction(+:rkj) schedule(static)\n            for (int i = 0; i < m; ++i) {\n                rkj += q_ptr[k][i] * a_ptr[j][i];\n            }\n            R[k][j] = rkj;\n\n            /* A(:,j) -= Q(:,k) * R(k,j) */\n            #pragma omp parallel for schedule(static)\n            for (int i = 0; i < m; ++i) {\n                a_ptr[j][i] -= q_ptr[k][i] * rkj;\n            }\n        }\n    }\n}\n```",
  "jacobi_2d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_jacobi_2d(int tsteps,\n\t\t      int n,\n\t\t      std::vector<std::vector<double>>& A,\n\t\t      std::vector<std::vector<double>>& B)\n{\n    const double alpha = 0.2;\n\n    /* Work with rows as contiguous blocks to minimise cache misses. */\n    std::vector<double*> Arow(n), Brow(n);\n    for (int i = 0; i < n; ++i) {\n        Arow[i] = A[i].data();\n        Brow[i]  = B[i].data();\n    }\n\n    /* Two serial sweeps per time step. Each sweep is parallelised over\n       the inner loop with an OpenMP parallel for. */\n    for (int t = 0; t < tsteps; ++t) {\n        /* 1) Update B from A */\n        #pragma omp parallel for schedule(static) collapse(2)\n        for (int i = 1; i < n - 1; ++i) {\n            for (int j = 1; j < n - 1; ++j) {\n                Brow[i][j] = alpha * (Arow[i][j]\n                                     + Arow[i][j-1]\n                                     + Arow[i][j+1]\n                                     + Arow[i+1][j]\n                                     + Arow[i-1][j]);\n            }\n        }\n\n        /* 2) Update A from B */\n        #pragma omp parallel for schedule(static) collapse(2)\n        for (int i = 1; i < n - 1; ++i) {\n            for (int j = 1; j < n - 1; ++j) {\n                Arow[i][j] = alpha * (Brow[i][j]\n                                     + Brow[i][j-1]\n                                     + Brow[i][j+1]\n                                     + Brow[i+1][j]\n                                     + Brow[i-1][j]);\n            }\n        }\n    }\n}\n```",
  "cholesky": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_cholesky(int n,\n\t\t     std::vector<std::vector<double>>& A) {\n\n    /* Parallelise the outer loop over rows.\n       The inner work for a given row is completely independent. */\n#pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        /* Compute the strictly lower\u2011triangular part. */\n        for (int j = 0; j < i; ++j) {\n            double sum = 0.0;\n            /* Replace the inner k\u2011loop by a dot product. */\n            for (int k = 0; k < j; ++k) {\n                sum += A[i][k] * A[j][k];\n            }\n            A[i][j] -= sum;\n            A[i][j] /= A[j][j];\n        }\n\n        /* Compute the diagonal element. */\n        double diag = 0.0;\n        for (int k = 0; k < i; ++k) {\n            diag += A[i][k] * A[i][k];\n        }\n        A[i][i] = std::sqrt(A[i][i] - diag);\n    }\n}\n```",
  "trmm": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_trmm(int m, int n,\n                 double alpha,\n                 std::vector<std::vector<double>>& A,\n                 std::vector<std::vector<double>>& B)\n{\n    // A is MxM, B is MxN\n    // B := alpha * A^T * B\n    // The inner loops are cache\u2011friendly after using row\u2011major storage\n    // and OpenMP parallelization.\n\n    const double a = alpha;               // local copy to avoid repeated loads\n    const int  strideB = n;                // B is stored row\u2011major\n    const int  strideA = m;                // A is square\n\n    // Parallelise the outer row loop.  Each thread works on a distinct i.\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < m; ++i) {\n        // Pre\u2011compute the pointer to the i\u2011th row of A:\n        // we need A[k][i] for k>i, i.e. the i\u2011th column of A.\n        const double* colA_i = &A[0][i];   // pointer to first element of column i\n\n        for (int j = 0; j < n; ++j) {\n            double sum = B[i][j];          // start with existing B[i][j]\n            // The increment k loop runs over rows k > i:\n            for (int k = i + 1; k < m; ++k) {\n                // A[k][i] is found at offset k but same column i\n                sum += colA_i[k] * B[k][j];\n            }\n            B[i][j] = a * sum;             // final scalar multiplication\n        }\n    }\n}\n```",
  "fdtd_2d": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_fdtd_2d(int tmax,\n                    int nx,\n                    int ny,\n                    std::vector<std::vector<double>>& ex,\n                    std::vector<std::vector<double>>& ey,\n                    std::vector<std::vector<double>>& hz,\n                    std::vector<double>& _fict_)\n{\n    const double step = 0.5;\n    const double step_h = 0.7;\n\n    // Flatten the 2\u2011D vectors to 1\u2011D pointers for faster access\n    double *const ex_ptr = &ex[0][0];\n    double *const ey_ptr = &ey[0][0];\n    double *const hz_ptr = &hz[0][0];\n\n    const ptrdiff_t nxny = static_cast<ptrdiff_t>(nx) * ny;\n    const size_t width = ny;\n\n    for (int t = 0; t < tmax; ++t) {\n        /* 1. Update ey[0][j] */\n        for (int j = 0; j < ny; ++j)\n            ey_ptr[j] = _fict_[t];\n\n        /* 2. Update ey[i][j] for i > 0 */\n        #pragma omp parallel for schedule(static) collapse(2)\n        for (int i = 1; i < nx; ++i) {\n            const ptrdiff_t base = static_cast<ptrdiff_t>(i) * width;\n            const ptrdiff_t base_prev = static_cast<ptrdiff_t>(i - 1) * width;\n            for (int j = 0; j < ny; ++j) {\n                ey_ptr[base + j] -= step *\n                    (hz_ptr[base + j] - hz_ptr[base_prev + j]);\n            }\n        }\n\n        /* 3. Update ex[i][j] for j > 0 */\n        #pragma omp parallel for schedule(static) collapse(2)\n        for (int i = 0; i < nx; ++i) {\n            const ptrdiff_t base = static_cast<ptrdiff_t>(i) * width;\n            for (int j = 1; j < ny; ++j) {\n                ex_ptr[base + j] -= step *\n                    (hz_ptr[base + j] - hz_ptr[base + j - 1]);\n            }\n        }\n\n        /* 4. Update hz[i][j] */\n        #pragma omp parallel for schedule(static) collapse(2)\n        for (int i = 0; i < nx - 1; ++i) {\n            const ptrdiff_t base = static_cast<ptrdiff_t>(i) * width;\n            const ptrdiff_t base_next = static_cast<ptrdiff_t>(i + 1) * width;\n            for (int j = 0; j < ny - 1; ++j) {\n                hz_ptr[base + j] -= step_h *\n                    (ex_ptr[base + j + 1] - ex_ptr[base + j] +\n                     ey_ptr[base_next + j] - ey_ptr[base + j]);\n            }\n        }\n    }\n}\n```\nThis replacement keeps the exact semantics of the original function while:\n\n1. Flattening the 2\u2011D `std::vector`s for cache\u2011friendly access.\n2. Using explicit pointer arithmetic to avoid bounds checks.\n3. Parallelizing independent loops with OpenMP (`collapse(2)` ensures two nested loops are fused for better load distribution).\n4. Minimizing temporary variables and keeping all arithmetic inlined.",
  "seidel_2d": "```cpp\n#include <vector>\n#include <omp.h>\n\nconstexpr double INV9 = 1.0 / 9.0;\n\n/* Helper to get element at i,j from a flattened 1D array */\ninline double& elem(std::vector<double>& a, int n, int i, int j) {\n    return a[i * n + j];\n}\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_seidel_2d(int tsteps,\n                      int n,\n                      std::vector<std::vector<double>>& A) {\n    // Flatten the 2D vector for better cache locality\n    std::vector<double> flat(n * n);\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            flat[i * n + j] = A[i][j];\n\n    for (int t = 0; t < tsteps; ++t) {\n        // Parallelize over rows with OpenMP\n        #pragma omp parallel for schedule(static)\n        for (int i = 1; i <= n - 2; ++i) {\n            int idx = i * n;          // base index for row i\n            int idx_up = (i - 1) * n; // base index for row i-1\n            int idx_dn = (i + 1) * n; // base index for row i+1\n\n            // Unroll the inner loop by 4\n            for (int j = 1; j <= n - 2; j += 4) {\n                // Load neighboring values\n                for (int k = 0; k < 4 && j + k <= n - 2; ++k) {\n                    int jj = j + k;\n                    const double a00 = flat[idx_up + jj - 1];\n                    const double a01 = flat[idx_up + jj];\n                    const double a02 = flat[idx_up + jj + 1];\n                    const double a10 = flat[idx + jj - 1];\n                    const double a11 = flat[idx + jj];\n                    const double a12 = flat[idx + jj + 1];\n                    const double a20 = flat[idx_dn + jj - 1];\n                    const double a21 = flat[idx_dn + jj];\n                    const double a22 = flat[idx_dn + jj + 1];\n                    flat[idx + jj] = INV9 * (a00 + a01 + a02 +\n                                            a10 + a11 + a12 +\n                                            a20 + a21 + a22);\n                }\n            }\n        }\n    }\n\n    // Copy back to the 2D vector\n    for (int i = 0; i < n; ++i)\n        for (int j = 0; j < n; ++j)\n            A[i][j] = flat[i * n + j];\n}\n```",
  "gemver": "```cpp\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_gemver(int n,\n                   double alpha,\n                   double beta,\n                   std::vector<std::vector<double>>& A,\n                   std::vector<double>& u1,\n                   std::vector<double>& v1,\n                   std::vector<double>& u2,\n                   std::vector<double>& v2,\n                   std::vector<double>& w,\n                   std::vector<double>& x,\n                   std::vector<double>& y,\n                   std::vector<double>& z) {\n    // ----------------------------------------------------------------------\n    // 1) A <- A + u1*v1^T + u2*v2^T\n    //    Parallel over rows, unroll inner loop for better vectorisation\n    // ----------------------------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double u1i = u1[i];\n        double u2i = u2[i];\n        std::vector<double>& Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            Ai[j] += u1i * v1[j] + u2i * v2[j];\n        }\n    }\n\n    // ----------------------------------------------------------------------\n    // 2) x = beta * A^T * y  + x\n    //    Parallel over rows of A^T (i.e. columns of A)\n    // ----------------------------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        for (int j = 0; j < n; ++j) {\n            sum += A[j][i] * y[j];\n        }\n        x[i] += beta * sum;\n    }\n\n    // ----------------------------------------------------------------------\n    // 3) x = x + z\n    // ----------------------------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        x[i] += z[i];\n    }\n\n    // ----------------------------------------------------------------------\n    // 4) w = alpha * A * x  + w\n    //    Parallel over rows of A\n    // ----------------------------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < n; ++i) {\n        double sum = 0.0;\n        const std::vector<double>& Ai = A[i];\n        for (int j = 0; j < n; ++j) {\n            sum += Ai[j] * x[j];\n        }\n        w[i] += alpha * sum;\n    }\n}\n```\n",
  "floyd_warshall": "```cpp\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\nnamespace {\n\n// Helper to access a row pointer with the same layout as std::vector<int>\ninline int* row_ptr(std::vector<int>& row) { return row.data(); }\n\n} // unnamed namespace\n\nvoid kernel_floyd_warshall(int n, std::vector<std::vector<int>>& path)\n{\n    // Parallelise the outer two loops. The innermost loop is\n    // already small enough to benefit from cache locality.\n    #pragma omp parallel for schedule(static) collapse(2)\n    for (int k = 0; k < n; ++k) {\n        int* restrict row_k = row_ptr(path[k]);          // path[k]\n        for (int i = 0; i < n; ++i) {\n            int* restrict row_i = row_ptr(path[i]);      // path[i]\n            // Optional manual unrolling for small loops\n            for (int j = 0; j < n; ++j) {\n                int new_val = row_i[k] + row_k[j];\n                if (new_val < row_i[j]) row_i[j] = new_val;\n            }\n        }\n    }\n}\n```",
  "lu": "```cpp\n#include <vector>\n#include <omp.h>\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_lu(int n,\n               std::vector<std::vector<double>>& A) {\n    for (int i = 0; i < n; ++i) {\n        // Pointers to the current row for fast access\n        double* Ai = A[i].data();\n\n        /* Update column elements A[i][j] for j < i */\n        for (int j = 0; j < i; ++j) {\n            double sum = 0.0;\n            double* Ak = A[i].data();      // same as Ai\n            double* Kj = A[j].data();      // row k of column j\n            for (int k = 0; k < j; ++k) {\n                sum += Ak[k] * Kj[k];\n            }\n            Ai[j] -= sum;\n            Ai[j] /= A[j][j];\n        }\n\n        /* Update row elements A[i][j] for j >= i */\n        for (int j = i; j < n; ++j) {\n            double sum = 0.0;\n            for (int k = 0; k < i; ++k) {\n                sum += Ai[k] * A[k][j];\n            }\n            Ai[j] -= sum;\n        }\n    }\n}\n```",
  "deriche": "```cpp\n#include <cmath>\n#include <vector>\n#include <omp.h>\n\nvoid kernel_deriche(int w, int h, double alpha,\n                    std::vector<std::vector<float>>& imgIn,\n                    std::vector<std::vector<float>>& imgOut,\n                    std::vector<std::vector<float>>& y1,\n                    std::vector<std::vector<float>>& y2) {\n\n    /* pre\u2011compute constant terms \u2013 they are the same for every pixel */\n    const float expA = std::exp(-alpha);\n    const float exp2A = std::exp(-2.0 * alpha);\n    const float k = 1.0f - expA * (1.0f - expA) /\n                           (1.0f + 2.0f * static_cast<float>(alpha) * expA - exp2A);\n\n    const float a1 = k, a5 = k;\n    const float a2 = a6 = k * expA * (static_cast<float>(alpha) - 1.0f);\n    const float a3 = a7 = k * expA * (static_cast<float>(alpha) + 1.0f);\n    const float a4 = a8 = -k * exp2A;\n    const float b1 = static_cast<float>(std::pow(2.0, -alpha));\n    const float b2 = -exp2A;\n    const float c1 = 1.0f, c2 = 1.0f;\n\n    /* forward pass along rows */\n    #pragma omp parallel for\n    for (int i = 0; i < w; ++i) {\n        float ym1 = 0.0f, ym2 = 0.0f;\n        float xm1 = 0.0f;\n        float* imgRow  = imgIn[i].data();\n        float* y1Row   = y1[i].data();\n        for (int j = 0; j < h; ++j) {\n            y1Row[j] = a1 * imgRow[j] + a2 * xm1 + b1 * ym1 + b2 * ym2;\n            xm1 = imgRow[j];\n            ym2 = ym1;\n            ym1 = y1Row[j];\n        }\n    }\n\n    /* backward pass along rows */\n    #pragma omp parallel for\n    for (int i = 0; i < w; ++i) {\n        float yp1 = 0.0f, yp2 = 0.0f;\n        float xp1 = 0.0f, xp2 = 0.0f;\n        float* imgRow = imgIn[i].data();\n        float* y2Row = y2[i].data();\n        for (int j = h - 1; j >= 0; --j) {\n            y2Row[j] = a3 * xp1 + a4 * xp2 + b1 * yp1 + b2 * yp2;\n            xp2 = xp1;\n            xp1 = imgRow[j];\n            yp2 = yp1;\n            yp1 = y2Row[j];\n        }\n    }\n\n    /* combine first stage results */\n    #pragma omp parallel for collapse(2)\n    for (int i = 0; i < w; ++i) {\n        for (int j = 0; j < h; ++j)\n            imgOut[i][j] = c1 * (y1[i][j] + y2[i][j]);\n    }\n\n    /* forward pass along columns */\n    #pragma omp parallel for\n    for (int j = 0; j < h; ++j) {\n        float tm1 = 0.0f, ym1 = 0.0f, ym2 = 0.0f;\n        for (int i = 0; i < w; ++i) {\n            y1[i][j] = a5 * imgOut[i][j] + a6 * tm1 + b1 * ym1 + b2 * ym2;\n            tm1 = imgOut[i][j];\n            ym2 = ym1;\n            ym1 = y1[i][j];\n        }\n    }\n\n    /* backward pass along columns */\n    #pragma omp parallel for\n    for (int j = 0; j < h; ++j) {\n        float tp1 = 0.0f, tp2 = 0.0f;\n        float yp1 = 0.0f, yp2 = 0.0f;\n        for (int i = w - 1; i >= 0; --i) {\n            y2[i][j] = a7 * tp1 + a8 * tp2 + b1 * yp1 + b2 * yp2;\n            tp2 = tp1;\n            tp1 = imgOut[i][j];\n            yp2 = yp1;\n            yp1 = y2[i][j];\n        }\n    }\n\n    /* final combine */\n    #pragma omp parallel for collapse(2)\n    for (int i = 0; i < w; ++i) {\n        for (int j = 0; j < h; ++j)\n            imgOut[i][j] = c2 * (y1[i][j] + y2[i][j]);\n    }\n}\n```"
}