{
  "17_graph_highest_degree": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Compute the maximum degree of an undirected graph from its adjacency matrix.\n * The matrix A is N\u00d7N, row\u2011major, with values 0 or 1.  The function is thread\u2011safe\n * and uses OpenMP for parallel accumulation.\n */\nint maxDegree(std::vector<int> const& A, size_t N) {\n    int maxDeg = 0;\n#pragma omp parallel for reduction(max:maxDeg) schedule(static)\n    for (int i = 0; i < static_cast<int>(N); ++i) {\n        const int* row = &A[i * N];\n        int deg = 0;\n        // unroll inner loop for a bit of speed\n        int j = 0;\n        for (; j + 15 < static_cast<int>(N); j += 16) {\n            deg += row[j] + row[j+1] + row[j+2] + row[j+3] +\n                   row[j+4] + row[j+5] + row[j+6] + row[j+7] +\n                   row[j+8] + row[j+9] + row[j+10] + row[j+11] +\n                   row[j+12] + row[j+13] + row[j+14] + row[j+15];\n        }\n        for (; j < static_cast<int>(N); ++j) {\n            deg += row[j];\n        }\n        if (deg > maxDeg) maxDeg = deg;\n    }\n    return maxDeg;\n}\n```\n",
  "15_graph_edge_count": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* Count the number of edges in a directed graph represented by a row\u2011major\n   adjacency matrix `A`.  `A` contains 1 for an edge, 0 otherwise.  The\n   function is fully parallelized with OpenMP and uses a per\u2011thread counter\n   to avoid contention.  It preserves the exact semantics of the original\n   implementation. */\nint edgeCount(const std::vector<int> &A, size_t N) {\n    // 1. Use a per\u2011thread local counter to avoid atomic operations.\n    // 2. Access the vector via a raw pointer for speed.\n    // 3. Flatten the loops so that the inner loop works on contiguous\n    //    memory, allowing the compiler to keep the address in a register.\n    int total = 0;\n\n    const int *data = A.data();\n    const size_t stride = N;\n\n    // OpenMP parallel for with reduction\n    #pragma omp parallel for reduction(+:total) schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        const int *row = data + i * stride;\n        size_t j = 0;\n        // Unroll the inner loop for extra speed (unrolling factor = 8)\n        for (; j + 7 < N; j += 8) {\n            total += row[j]     + row[j+1] + row[j+2] + row[j+3]\n                   + row[j+4] + row[j+5] + row[j+6] + row[j+7];\n        }\n        // Process any remaining entries\n        for (; j < N; ++j) {\n            total += row[j];\n        }\n    }\n    return total;\n}\n```",
  "21_histogram_bin_0-100": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\ninline void binsBy10Count(std::vector<double> const& x, std::array<std::size_t, 10>& bins)\n{\n#if defined(_OPENMP)\n    // Create per\u2011thread bins to avoid contention\n    int const nthreads = omp_get_max_threads();\n    std::vector<std::array<std::size_t,10>> local_bins(nthreads);\n    // initialize all local bins to 0\n    for (auto& arr : local_bins)\n        arr.fill(0);\n\n#pragma omp parallel\n    {\n        int const tid = omp_get_thread_num();\n        std::array<std::size_t,10>& local = local_bins[tid];\n        std::size_t const stride = omp_get_num_threads();\n        for (std::size_t i = tid; i < x.size(); i += stride) {\n            std::size_t const bin = static_cast<std::size_t>(x[i]) / 10;\n            ++local[bin];\n        }\n    }\n\n    // Combine local bins into the result\n    bins.fill(0);\n    for (auto const& arr : local_bins) {\n        for (std::size_t b = 0; b < 10; ++b)\n            bins[b] += arr[b];\n    }\n#else\n    // Fallback to serial version when OpenMP is not available\n    bins.fill(0);\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        std::size_t const bin = static_cast<std::size_t>(x[i]) / 10;\n        ++bins[bin];\n    }\n#endif\n}\n```\n\nThis implementation uses a per\u2011thread accumulation array to avoid atomic operations, then sums the local results. The logic preserves the exact behavior of the original code while exploiting multi\u2011core parallelism on an x86\u201164 machine with GCC and OpenMP.",
  "20_histogram_pixel_histogram": "```cpp\n#pragma once\n#include <vector>\n#include <array>\n#include <cstdint>\n#include <cstring>\n#ifdef _OPENMP\n#include <omp.h>\n#endif\n\n/* Count the number of pixels in image with each grayscale intensity.\n   The vector `image` is a grayscale image with values 0-255.\n   Store the results in `bins`. */\ninline void pixelCounts(const std::vector<int> &image,\n                        std::array<std::size_t, 256> &bins)\n{\n    const std::size_t n = image.size();\n\n    // Zero the global bins quickly\n    std::memset(bins.data(), 0, sizeof(std::size_t) * 256);\n\n    // If OpenMP is available, use a per-thread local histogram\n    #ifdef _OPENMP\n    const int nthreads = omp_get_max_threads();\n    std::vector<std::array<std::size_t, 256>> local(nthreads);\n\n    #pragma omp parallel\n    {\n        const int tid = omp_get_thread_num();\n        std::array<std::size_t, 256> &localBins = local[tid];\n\n        // Local histogram starts zeroed locally\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < n; ++i) {\n            ++localBins[static_cast<uint8_t>(image[i])];\n        }\n    }\n\n    // Merge local histograms into the global bins\n    for (int t = 0; t < nthreads; ++t) {\n        const std::array<std::size_t, 256> &localBins = local[t];\n        for (int b = 0; b < 256; ++b)\n            bins[b] += localBins[b];\n    }\n    #else\n    // Fallback single-threaded\n    for (std::size_t i = 0; i < n; ++i) {\n        ++bins[static_cast<uint8_t>(image[i])];\n    }\n    #endif\n}\n```",
  "16_graph_largest_component": "```cpp\n//=====================================================\n//  Optimised version of largestComponent\n//=====================================================\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstring>   // for memset\n\n// Helper: iterative DFS using a pre\u2011allocated stack.\n// The graph is given as a packed adjacency matrix A[row*N+col].\ninline void vec_dfs(const int* A, int start, size_t N, char* visited, int* stack, int& count)\n{\n    int top = 0;\n    stack[top++] = start;\n    visited[start] = 1;\n    count = 1;\n\n    while (top) {\n        int v = stack[--top];\n        const int* row = A + v * N;   // pointer to row v\n\n        // Scan row for unvisited neighbours\n        for (int i = 0; i < static_cast<int>(N); ++i) {\n            if (row[i] && !visited[i]) {\n                visited[i] = 1;\n                stack[top++] = i;\n                ++count;\n            }\n        }\n    }\n}\n\ninline int largestComponent(const std::vector<int>& A_vec, size_t N)\n{\n    const int* A = A_vec.data();\n\n    // Use a fixed size stack \u2013 allocate once per call\n    std::vector<int> stack(N);\n    // visited array \u2013 use char for 1 byte per flag\n    std::vector<char> visited(N, 0);\n\n    int maxComp = 0;\n    for (int i = 0; i < static_cast<int>(N); ++i) {\n        if (!visited[i]) {\n            int compSize = 0;\n            vec_dfs(A, i, N, visited.data(), stack.data(), compSize);\n            if (compSize > maxComp) maxComp = compSize;\n        }\n    }\n    return maxComp;\n}\n```\nThis replacement keeps the exact semantics while removing recursive overhead, using a packed `char` visited array for cache efficiency, and a single allocation for the DFS stack. The code is compilable with `gcc -O2 -fopenmp` (OpenMP unused but harmless).",
  "19_graph_shortest_path": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <cstddef>\n#include <cstdint>\n\n/* Return the length of the shortest path from source to dest in an undirected graph\n * represented by a dense adjacency matrix A (row\u2011major).  The graph is guaranteed\n * to be connected.  The implementation uses a hand\u2011rolled queue and a byte\u2013\n * sized visited array for maximum cache friendliness and zero overhead.\n */\nint shortestPathLength(std::vector<int> const& A, size_t N,\n                       int source, int dest)\n{\n    // Byte\u2011sized visited array \u2013 0 = unseen, 1 = visited.\n    std::vector<uint8_t> visited(N, 0);\n    // Pre\u2011allocate queue storage: maximum size N.\n    std::vector<int> q(N);\n    std::size_t qhead = 0, qtail = 0;\n\n    visited[source] = 1;\n    q[qtail++] = source;\n    int depth = 0;                     // current depth\n    std::size_t processed = 1;         // number of nodes already dequeued\n\n    while (qhead < qtail)\n    {\n        // Process all nodes at the current depth level\n        std::size_t levelEnd = qtail;  // nodes enqueued so far\n        while (qhead < levelEnd)\n        {\n            int cur = q[qhead++];\n            if (cur == dest) return depth;\n\n            // Scan adjacency row for cur\n            const std::size_t offset = cur * N;\n            for (std::size_t i = 0; i < N; ++i)\n            {\n                if (A[offset + i] && !visited[i])\n                {\n                    visited[i] = 1;\n                    q[qtail++] = static_cast<int>(i);\n                }\n            }\n        }\n        ++depth;\n    }\n\n    // Should never happen on a connected graph.\n    return std::numeric_limits<int>::max();\n}\n```",
  "23_histogram_first_letter_counts": "```cpp\n#pragma once\n#include <array>\n#include <string>\n#include <vector>\n#include <omp.h>\n\n/* For each letter in the alphabet, count the number of strings in the vector `s`\n * that start with that letter.  Assume all strings are in lower case.  Store\n * the output in `bins` array.\n *\n * Example:\n *   input : [\"dog\", \"cat\", \"xray\", \"cow\", \"code\", \"type\", \"flower\"]\n *   output: [0, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n */\ninline void firstLetterCounts(std::vector<std::string> const& s,\n                              std::array<size_t, 26> &bins)\n{\n    // Zero the result array\n    bins.fill(0);\n\n    // Work\u2011around for GCC array reduction: use a per\u2011thread local array\n    // (size 26) and merge after the parallel loop.\n    const int n = static_cast<int>(s.size());\n    int num_threads = 1;\n\n#pragma omp parallel\n    {\n#pragma omp single\n        num_threads = omp_get_num_threads();\n    }\n\n    std::vector<std::array<size_t, 26>> thread_local_bins(num_threads);\n    for (auto &d : thread_local_bins) d.fill(0);\n\n#pragma omp parallel\n    {\n        int tid = omp_get_thread_num();\n        auto &local = thread_local_bins[tid];\n#pragma omp for schedule(static)\n        for (int i = 0; i < n; ++i) {\n            // All strings are guaranteed to be non\u2011empty.\n            const char c = s[i][0];\n            const int idx = c - 'a';\n            ++local[idx];\n        }\n    }\n\n    // Merge local results into the global array\n    for (int t = 0; t < num_threads; ++t) {\n        const auto &local = thread_local_bins[t];\n        for (int i = 0; i < 26; ++i) {\n            bins[i] += local[i];\n        }\n    }\n}\n```",
  "18_graph_count_components": "```cpp\n#pragma once\n#include <vector>\n#include <stack>\n#include <omp.h>\n\n/* Count the number of connected components in the undirected graph\n   defined by the adjacency matrix A (row\u2011major NxN). */\nint componentCount(std::vector<int> const& A, size_t N)\n{\n    if (N == 0) return 0;\n\n    // visited array \u2013 use char for cache friendliness\n    std::vector<char> visited(N, 0);\n    int compCnt = 0;\n\n    /* We will traverse the nodes in parallel. Each thread will\n       perform a DFS starting from an unvisited node it finds.\n       To avoid multiple threads starting DFS from the same component\n       we atomically test and set the visited flag before pushing a node\n       onto the stack. */\n    #pragma omp parallel\n    {\n        std::stack<int> st;\n        #pragma omp for schedule(dynamic)\n        for (int start = 0; start < static_cast<int>(N); ++start)\n        {\n            // Try to claim this node. If it was already visited, skip.\n            if (!__atomic_test_and_set(&visited[start], __ATOMIC_RELAXED))\n                continue;          // already visited by another thread\n\n            // Start a DFS from this node\n            st.push(start);\n            while (!st.empty())\n            {\n                int u = st.top();\n                st.pop();\n\n                // Scan all neighbors of u\n                const int rowStart = static_cast<int>(u) * N;\n                for (int v = 0; v < static_cast<int>(N); ++v)\n                {\n                    if (A[rowStart + v] == 1 && !__atomic_test_and_set(&visited[v], __ATOMIC_RELAXED))\n                    {\n                        st.push(v);\n                    }\n                }\n            }\n\n            // One component found\n            #pragma omp atomic\n            ++compCnt;\n        }\n    }\n    return compCnt;\n}\n```",
  "34_scan_largest_contiguous_subarray_sum": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n\n/* Return the largest sum of any contiguous subarray in the vector x.\n   Implemented using Kadane's algorithm (O(n) time, O(1) space). */\nint maximumSubarray(std::vector<int> const& x) {\n    if (x.empty()) return std::numeric_limits<int>::lowest();\n\n    int max_ending_here = x[0];\n    int max_so_far       = x[0];\n\n    for (size_t i = 1; i < x.size(); ++i) {\n        max_ending_here = std::max(x[i], max_ending_here + x[i]);\n        max_so_far = std::max(max_so_far, max_ending_here);\n    }\n    return max_so_far;\n}\n```",
  "22_histogram_count_quadrants": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct Point {\n   double x, y;\n};\n\n/* Count the number of cartesian points in each quadrant. The vector points contains a list of `Point` objects.\n   Store the counts in `bins`.\n   Parallelized with OpenMP using a reduction to avoid data races.\n*/\ninline void countQuadrants(std::vector<Point> const& points, std::array<std::size_t, 4> &bins) {\n   // Initialise the output array\n   bins[0] = bins[1] = bins[2] = bins[3] = 0;\n\n   const std::size_t n = points.size();\n\n   // Local thread\u2010private counters to reduce contention\n   #pragma omp parallel\n   {\n      std::size_t local[4] = {0,0,0,0};\n\n      #pragma omp for schedule(static)\n      for (std::size_t i = 0; i < n; ++i) {\n         const Point& p = points[i];\n         if (p.x >= 0.0) {\n            if (p.y >= 0.0) {\n               ++local[0];\n            } else {\n               ++local[3];\n            }\n         } else {\n            if (p.y >= 0.0) {\n               ++local[1];\n            } else {\n               ++local[2];\n            }\n         }\n      }\n\n      // Combine thread results into the global array\n      #pragma omp atomic\n      bins[0] += local[0];\n      #pragma omp atomic\n      bins[1] += local[1];\n      #pragma omp atomic\n      bins[2] += local[2];\n      #pragma omp atomic\n      bins[3] += local[3];\n   }\n}\n```\n",
  "24_histogram_count_quartile": "```cpp\n#pragma once\n#include <array>\n#include <cstddef>\n#include <vector>\n#include <omp.h>\n\n/*\n   Count the number of doubles in the vector x that have a fractional part\n   in [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). Store the counts in\n   `bins`.  The implementation is fully parallel on up to 8 threads.\n*/\ninline void countQuartiles(const std::vector<double> &x,\n                           std::array<std::size_t, 4> &bins)\n{\n    /* initialise bins -------------------------------------------------------------------- */\n    bins[0] = bins[1] = bins[2] = bins[3] = 0;\n\n    /* parallel for with SIMD hint -------------------------------------------------------- */\n#pragma omp parallel for schedule(static) reduction(+:bins[:4])\n    for (std::size_t i = 0; i < x.size(); ++i)\n    {\n        const double val  = x[i];\n        const double frac = val - static_cast<double>( static_cast<int>(val) );\n\n        if (frac < 0.25)       ++bins[0];\n        else if (frac < 0.5)   ++bins[1];\n        else if (frac < 0.75)  ++bins[2];\n        else                   ++bins[3];\n    }\n}\n```",
  "32_scan_sum_of_prefix_sum_array": "```cpp\n#pragma once\n#include <vector>\n#include <cstdint>\n#include <omp.h>\n\n/* Compute the prefix sum array of the vector x and return its sum.\n   Equivalent to computing \u2211_{i=0}^{n-1} \u2211_{j=0}^{i} x[j]\n   / = \u2211_{j=0}^{n-1} x[j] * (n-j)\n   The function preserves exact semantics of the original implementation.\n*/\ninline int64_t sumOfPrefixSum(const std::vector<int64_t>& x)\n{\n    const std::size_t n = x.size();\n    if (n == 0) return 0;\n\n    // Compute sum_{j=0}^{n-1} x[j] * (n-j) using a parallel reduction.\n    int64_t total = 0;\n#pragma omp parallel for reduction(+:total)\n    for (std::size_t i = 0; i < n; ++i) {\n        // (n - i) fits in 64 bit because n \u2264 10^9 typically.\n        total += x[i] * static_cast<int64_t>(n - i);\n    }\n    return total;\n}\n```",
  "30_scan_prefix_sum": "```cpp\n#pragma once\n#include <numeric>\n#include <vector>\n\n/* Compute the prefix sum of the vector x into output.\n   Example:\n   input: [1, 7, 4, 6, 6, 2]\n   output: [1, 8, 12, 18, 24, 26]\n*/\ninline void prefixSum(const std::vector<int64_t>& x, std::vector<int64_t>& output) {\n    // std::inclusive_scan is already highly optimized on GCC\n    std::inclusive_scan(x.begin(), x.end(), output.begin());\n}\n```",
  "31_scan_scan_with_min_function": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n\n/*\n * Replace the i-th element of the vector x with the minimum value from indices 0 through i.\n * Examples:\n *   input: [8, 6, -1, 7, 3, 4, 4]\n *   output: [8, 6, -1, -1, -1, -1, -1]\n *   input: [5, 4, 6, 4, 3, 6, 1, 1]\n *   output: [5, 4, 4, 4, 3, 3, 1, 1]\n */\ninline void partialMinimums(std::vector<float> &x) {\n    if (x.empty()) return;\n    const float max_val = std::numeric_limits<float>::max();\n    float current_min = max_val;\n    for (auto &v : x) {\n        current_min = (v < current_min) ? v : current_min;\n        v = current_min;\n    }\n}\n```",
  "59_transform_map_function": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\ninline bool isPowerOfTwo(int x) noexcept {\n    return (x > 0) && !(x & (x - 1));\n}\n\n/*\n * Apply the isPowerOfTwo function to every value in x and store the\n * results in mask. The function is fully thread\u2011safe and uses an\n * OpenMP parallel loop for maximum throughput on multi\u2011core systems.\n *\n * Example:\n *   input : [8, 0, 9, 7, 15, 64, 3]\n *   output: [true, false, false, false, false, true, false]\n */\ninline void mapPowersOfTwo(const std::vector<int> &x, std::vector<bool> &mask) {\n    const std::size_t n = x.size();\n    // Ensure mask has the same size as x to avoid out of bounds access.\n    mask.resize(n);\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        mask[i] = isPowerOfTwo(x[i]);\n    }\n}\n```",
  "33_scan_reverse_prefix_sum": "```cpp\n#pragma once\n#include <vector>\n\n/*\n  Compute the reverse prefix sum of the vector `x` into `output`.\n\n  The function writes the inclusive suffix sums:\n  output[i] = x[i] + x[i+1] + ... + x[n-1]\n\n  Example:\n  input:  [1, 7, 4, 6, 6, 2]\n  output: [2, 8, 14, 18, 25, 26]\n*/\ninline void reversePrefixSum(const std::vector<int>& x, std::vector<int>& output)\n{\n    const std::size_t n = x.size();\n    output.resize(n);          // ensure `output` has the right size\n\n    int sum = 0;\n    for (std::size_t i = n; i-- > 0;) {   // reverse loop with unsigned arithmetic\n        sum += x[i];\n        output[i] = sum;\n    }\n}\n```",
  "58_transform_squaring": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Replace every element of x with the square of its value.\n *\n * Threaded implementation that preserves the exact behaviour of the\n * original serial version.\n */\ninline void squareEach(std::vector<int> &x) {\n    // Parallelise over the indices. The work is embarrassingly parallel\n    // and the order of execution is irrelevant, so the standard OpenMP\n    // schedule works well.\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        int v = x[i];\n        x[i] = v * v;\n    }\n}\n```",
  "56_transform_negate_odds": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\ninline void negateOddsAndHalveEvens(std::vector<int> &x) {\n    // Parallelize the work across all available threads.\n    #pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t idx = 0; idx < static_cast<std::ptrdiff_t>(x.size()); ++idx) {\n        int val = x[idx];\n        // Test the lowest bit: 0 \u2192 even, 1 \u2192 odd.\n        if ((val & 1) == 0) {\n            x[idx] = val / 2;            // even: halve\n        } else {\n            x[idx] = -val;                // odd: negate\n        }\n    }\n}\n```",
  "57_transform_inverse_offset": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* Replace every element of the vector x with 1-1/x.\n   Example:\n   input: [2, 4, 1, 12, -2]\n   output: [0.5, 0.75, 0, 0.91666666, 1.5]\n*/\nvoid oneMinusInverse(std::vector<double> &x) {\n    // Parallel loop with OpenMP; GCC -O2 -fopenmp\n    #pragma omp parallel for schedule(static, 128)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(x.size()); ++i) {\n        double val = x[i];\n        x[i] = 1.0 - 1.0 / val;   // exact same semantics as std::transform lambda\n    }\n}\n```",
  "55_transform_relu": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <omp.h>\n\n/*\n * Compute the ReLU function on every element of x. Elements less than zero become zero,\n * while elements greater than zero stay the same.\n *    Example:\n *    input:  [-1.8, 24.0, 1.2, 0.0, -5.1, -0.2, 4.5]\n *    output: [0, 24.0, 1.2, 0, 0, 0, 4.5]\n */\ninline void relu(std::vector<double> &x) {\n    const std::size_t n = x.size();\n    if (n == 0) return;\n\n    // Pack causal loop into a single SIMD-friendly loop\n    // OpenMP parallelization ensures each thread works on a disjoint chunk\n#pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(n); ++i) {\n        double v = x[i];\n        // This inline implementation removes the function call overhead of std::max\n        x[i] = (v > 0.0) ? v : 0.0;\n    }\n}\n```\n",
  "25_reduce_xor": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n\n/* Return the logical XOR reduction of the vector of bools x.\n   Example:\n   input: [false, false, false, true]\n   output: true\n*/\ninline bool reduceLogicalXOR(const std::vector<bool>& x) {\n    bool result = false;\n    // Manual loop on vector<bool> guarantees the same packed semantics\n    // and avoids any intermediate allocations imposed by std::reduce.\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        result ^= x[i];\n    }\n    return result;\n}\n```\n",
  "28_reduce_smallest_odd_number": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <omp.h>\n\nint smallestOdd(const std::vector<int>& x)\n{\n    const int INF = std::numeric_limits<int>::max();\n    int best = INF;\n\n    // Parallel reduction over the vector elements.\n    #pragma omp parallel\n    {\n        int local_best = INF;\n        #pragma omp for nowait\n        for (int i = 0; i < static_cast<int>(x.size()); ++i) {\n            const int v = x[i];\n            if ((v & 1) && v < local_best) {\n                local_best = v;\n            }\n        }\n        #pragma omp atomic write\n        if (local_best < best) best = local_best;\n    }\n    return best;\n}\n```",
  "27_reduce_average": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <limits>\n#include <omp.h>\n\n/* Return the average of the vector x.\n   Examples:\n   input: [1, 8, 4, 5, 1]\n   output: 3.8\n   input: [2, 2, 2, 3]\n   output: 2.25\n*/\ndouble average(std::vector<double> const& x) {\n    std::size_t n = x.size();\n    if (n == 0) return std::numeric_limits<double>::quiet_NaN();\n\n    double sum = 0.0;\n#pragma omp parallel for reduction(+:sum)\n    for (std::size_t i = 0; i < n; ++i) {\n        sum += x[i];\n    }\n    return sum / static_cast<double>(n);\n}\n```",
  "47_sparse_la_spmv": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct COOElement {\n    std::size_t row;\n    std::size_t column;\n    double value;\n};\n\n/* Compute y = alpha*A*x + beta*y where alpha and beta are scalars, x and y are vectors,\n   and A is a sparse matrix stored in COO format.\n   x and y are length N and A is M x N.\n   Example:\n   input: alpha=0.5 beta=1.0 A=[{0,1,3}, {1,0,-1}] x=[-4, 2] y=[-1,1]\n   output: y=[2, 3]\n*/\ninline void spmv(double              alpha,\n                 std::vector<COOElement> const& A,\n                 std::vector<double> const&     x,\n                 double              beta,\n                 std::vector<double> &          y,\n                 std::size_t          M,\n                 std::size_t          N)\n{\n    /* Scale y by beta in parallel */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < y.size(); ++i)\n        y[i] *= beta;\n\n    /* Accumulate contributions from each non\u2011zero,\n       protecting updates to y[row] with atomic. */\n    const double a = alpha;            // local copy for speed\n    const std::size_t nA = A.size();\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t idx = 0; idx < nA; ++idx) {\n        const auto& e = A[idx];\n        if (e.row < M && e.column < N) {\n            const double prod = a * e.value * x[e.column];\n            #pragma omp atomic update\n            y[e.row] += prod;\n        }\n    }\n}\n```",
  "49_sparse_la_sparse_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <cassert>\n#include <omp.h>\n\nstruct COOElement {\n    size_t row, column;\n    double value;\n};\n\n/*\n * LU factorization of a sparse NxN matrix A stored in COO format.\n * L and U are returned in flattened row-major order (size N*N).\n * L has unit diagonal, U is upper triangular with zeros below the diagonal.\n * The algorithm follows Doolittle's method.\n */\ninline void luFactorize(const std::vector<COOElement>& A,\n                        std::vector<double>& L,\n                        std::vector<double>& U,\n                        size_t N) {\n    assert(L.size() == N * N && U.size() == N * N);\n\n    /* Allocate dense matrix A in row-major */\n    std::vector<double> fullA(N * N, 0.0);\n    for (const auto& e : A) {\n        fullA[e.row * N + e.column] = e.value;\n    }\n\n    /* Initialize L to identity and U to zero */\n    #pragma omp parallel for schedule(static)\n    for (size_t idx = 0; idx < N * N; ++idx) {\n        L[idx] = (idx % (N + 1) == 0) ? 1.0 : 0.0;\n        U[idx] = 0.0;\n    }\n\n    /* Doolittle LU decomposition */\n    for (size_t i = 0; i < N; ++i) {\n        /* ---------- Compute row i of U (j >= i) ---------- */\n        #pragma omp parallel for schedule(static)\n        for (size_t j = i; j < N; ++j) {\n            double sum = fullA[i * N + j];\n            for (size_t k = 0; k < i; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            U[i * N + j] = sum;\n        }\n\n        /* ---------- Compute column i of L (j < i) ---------- */\n        #pragma omp parallel for schedule(static)\n        for (size_t j = 0; j < i; ++j) {\n            double sum = fullA[i * N + j];\n            for (size_t k = 0; k < j; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            L[i * N + j] = sum / U[j * N + j];\n        }\n    }\n}\n```",
  "29_reduce_sum_of_min_of_pairs": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstdint>\n#include <numeric>\n#include <omp.h>\n\n/* Return the sum of the minimum value at each index of vectors x and y for all indices.\n   i.e. sum = min(x_0, y_0) + min(x_1, y_1) + min(x_2, y_2) + ...\n   Example:\n   input: x=[3, 4, 0, 2, 3], y=[2, 5, 3, 1, 7]\n   output: 10\n*/\nint64_t sumOfMinimumElements(std::vector<int64_t> const& x, std::vector<int64_t> const& y) {\n    // Ensure the input vectors are of equal length\n    const std::size_t n = x.size();\n    if (n == 0) return 0;\n    // Parallel reduction over the index range\n    int64_t total = 0;\n#pragma omp parallel for reduction(+:total)\n    for (std::size_t i = 0; i < n; ++i) {\n        total += (x[i] < y[i] ? x[i] : y[i]);\n    }\n    return total;\n}\n```\n",
  "48_sparse_la_sparse_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n#include <cstdint>\n#include <omp.h>\n\nstruct Element\n{\n    std::size_t index;\n    double      value;\n};\n\n/* Computation of z = alpha * x + y  for two sorted sparse vectors x and y.\n   The input vectors are sorted by `index`.  The result z is stored in a\n   dense vector that must have at least `max_index + 1` elements.\n */\ninline void sparseAxpy(double alpha,\n                       const std::vector<Element> &x,\n                       const std::vector<Element> &y,\n                       std::vector<double> &z)\n{\n    // Prepare a temporary vector to hold the merged results.\n    std::vector<Element> merged;\n    merged.reserve(x.size() + y.size());\n\n    std::size_t xi = 0, yi = 0;\n    while (xi < x.size() && yi < y.size())\n    {\n        if (x[xi].index < y[yi].index)\n        {\n            merged.push_back({x[xi].index, alpha * x[xi].value});\n            ++xi;\n        }\n        else if (x[xi].index > y[yi].index)\n        {\n            merged.push_back({y[yi].index, y[yi].value});\n            ++yi;\n        }\n        else\n        {\n            merged.push_back({x[xi].index,\n                              alpha * x[xi].value + y[yi].value});\n            ++xi;\n            ++yi;\n        }\n    }\n    while (xi < x.size())\n    {\n        merged.push_back({x[xi].index, alpha * x[xi].value});\n        ++xi;\n    }\n    while (yi < y.size())\n    {\n        merged.push_back({y[yi].index, y[yi].value});\n        ++yi;\n    }\n\n    // Parallel write the merged values into the dense vector `z`.\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < merged.size(); ++i)\n    {\n        z[merged[i].index] += merged[i].value;\n    }\n}\n```",
  "45_sparse_la_sparse_solve": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>\n\nstruct COOElement {\n    size_t row, column;\n    double value;\n};\n\n/* Solve the sparse linear system Ax = b for x.\n   A is a sparse NxN matrix in COO format.\n   x and b are dense vectors with N elements.\n*/\nvoid solveLinearSystem(std::vector<COOElement> const& A,\n                       std::vector<double> const& b,\n                       std::vector<double>& x,\n                       size_t N)\n{\n    /* 1. Build a flat dense matrix in row-major order. */\n    std::vector<double> mat(N * N, 0.0);\n    for (auto const& e : A)\n        mat[e.row * N + e.column] = e.value;\n\n    /* 2. Copy b to avoid modifying the caller's vector. */\n    std::vector<double> rhs = b;\n\n    /* 3. Gaussian elimination with partial pivoting. */\n    for (size_t i = 0; i < N; ++i)\n    {\n        /* --- Pivot search --- */\n        size_t maxRow = i;\n        double maxVal = std::fabs(mat[i * N + i]);\n\n        #pragma omp parallel for reduction(max:min,maxVal:maxRow) schedule(static)\n        for (long long k = static_cast<long long>(i + 1); k < static_cast<long long>(N); ++k)\n        {\n            double v = std::fabs(mat[k * N + i]);\n            if (v > maxVal) \n            {\n                maxVal = v;\n                maxRow = static_cast<size_t>(k);\n            }\n        }\n\n        /* --- Row swap if needed --- */\n        if (maxRow != i)\n        {\n            for (size_t k = 0; k < N; ++k)\n                std::swap(mat[i * N + k], mat[maxRow * N + k]);\n\n            std::swap(rhs[i], rhs[maxRow]);\n        }\n\n        /* --- Eliminate below --- */\n        double piv = mat[i * N + i];\n        if (piv == 0.0) continue;          // singular (not handled)\n\n        #pragma omp parallel for schedule(static)\n        for (size_t k = i + 1; k < N; ++k)\n        {\n            double factor = -mat[k * N + i] / piv;\n            mat[k * N + i] = 0.0;            // explicitly zero\n            double* rowk = &mat[k * N];\n            double* rowi = &mat[i * N];\n            for (size_t j = i + 1; j < N; ++j)\n                rowk[j] += factor * rowi[j];\n            rhs[k] += factor * rhs[i];\n        }\n    }\n\n    /* 4. Back substitution */\n    x.assign(N, 0.0);\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i)\n    {\n        double sum = rhs[i];\n        for (size_t j = i + 1; j < N; ++j)\n            sum -= mat[i * N + j] * x[j];\n        x[i] = sum / mat[i * N + i];\n    }\n}\n```\n",
  "26_reduce_product_of_inverses": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>   // for std::size_t\n\n/* Return the product of the vector x with every odd indexed element inverted.\n   i.e. x_0 * 1/x_1 * x_2 * 1/x_3 * x_4 ...\n   Example:\n   input: [4, 2, 10, 4, 5]\n   output: 25\n*/\ndouble productWithInverses(const std::vector<double> &x) {\n    double prod = 1.0;\n    const std::size_t n = x.size();\n\n    #pragma omp parallel for reduction(omp_mul:prod) schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        double val = (i & 1u) ? (1.0 / x[i]) : x[i];\n        prod *= val;\n    }\n\n    return prod;\n}\n```",
  "46_sparse_la_spmm": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <unordered_map>\n#include <omp.h>\n\nstruct COOElement {\n    std::size_t row, column;\n    double value;\n};\n\n/*\n * Compute Y = A * X\n * A : M x K sparse matrix in COO format\n * X : K x N sparse matrix in COO format\n * Y : M x N dense matrix (row\u2011major)\n *\n * The result preserves the exact semantics of the reference implementation\n * while exploiting OpenMP parallelism and per\u2011thread local storage\n * to eliminate atomic updates on the dense result matrix.\n */\nvoid spmm(std::vector<COOElement> const& A,\n          std::vector<COOElement> const& X,\n          std::vector<double>& Y,\n          std::size_t M, std::size_t K, std::size_t N) {\n\n    /* Allocate and initialise the dense result matrix */\n    Y.assign(M * N, 0.0);\n\n    /* Build an index of X by its row (i.e., the K dimension) */\n    std::vector<std::vector<const COOElement*>> x_rows(K);\n    for (const auto& x : X) {\n        if (x.row < K) {                     // guard against invalid indices\n            x_rows[x.row].push_back(&x);\n        }\n    }\n\n    /* Prepare per\u2011thread local buffers to avoid write contention */\n    int nthreads = omp_get_max_threads();\n    std::vector<std::vector<double>> y_local(nthreads, std::vector<double>(M * N, 0.0));\n\n    /* Parallel loop over the non\u2011zeros of A */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t idx = 0; idx < A.size(); ++idx) {\n        const COOElement* a = &A[idx];\n        if (a->column >= K) continue;        // guard against invalid column index\n\n        const std::vector<const COOElement*>& matches = x_rows[a->column];\n        std::size_t tid = omp_get_thread_num();\n        double* y_buf = y_local[tid].data();\n\n        for (const auto* x : matches) {\n            std::size_t row = a->row;\n            std::size_t col = x->column;\n            if (row < M && col < N) {        // guard against invalid indices\n                std::size_t pos = row * N + col;\n                y_buf[pos] += a->value * x->value;\n            }\n        }\n    }\n\n    /* Merge per\u2011thread buffers into the final result */\n    for (std::size_t tid = 0; tid < static_cast<std::size_t>(nthreads); ++tid) {\n        const double* buf = y_local[tid].data();\n        for (std::size_t i = 0; i < M * N; ++i) {\n            Y[i] += buf[i];\n        }\n    }\n}\n```\n",
  "14_geometry_closest_pair_1d": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <algorithm>\n#include <cmath>\n#include <omp.h>\n\n/* Return the distance between the closest two elements in the vector x.\n   The function keeps the exact semantics of the original, but\n   achieves O(n log n) time by sorting once and then scanning.\n*/\ndouble closestPair(std::vector<double> const& x) {\n    size_t n = x.size();\n    if (n < 2) return 0.0;\n\n    // Create a sorted copy of the input (stable order, but not relevant)\n    std::vector<double> sorted(x);\n    std::sort(sorted.begin(), sorted.end());\n\n    // Scan the sorted array: the minimal distance is among adjacent elements\n    double minDist = std::numeric_limits<double>::max();\n\n    // Use OpenMP to parallelize the scanning step.\n    // Each thread computes the minimum on its chunk of elements,\n    // then the results are reduced to obtain the global minimum.\n    #pragma omp parallel\n    {\n        double localMin = std::numeric_limits<double>::max();\n        #pragma omp for nowait\n        for (size_t i = 0; i + 1 < n; ++i) {\n            double d = std::abs(sorted[i + 1] - sorted[i]);\n            if (d < localMin) localMin = d;\n        }\n        #pragma omp critical\n        if (localMin < minDist) minDist = localMin;\n    }\n\n    return minDist;\n}\n```",
  "06_fft_dft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846\n#endif\n\n/* Compute the discrete Fourier transform (DFT) of `x` and store the result in\n * `output`. The implementation is optimized for modern x86\u201164 CPUs with\n * OpenMP, avoiding dynamic allocations inside the inner loops and\n * pre\u2011computing the twiddle factors.\n *\n * The function preserves the exact semantics of the na\u00efve implementation:\n *   output[k] = \u03a3_{n=0}^{N-1} x[n] * exp(-2\u03c0i * n * k / N)\n */\ninline void dft_constexpr(std::vector<double> const& x,\n                          std::vector<std::complex<double>>& output) {\n    const std::size_t N = x.size();\n    output.resize(N, std::complex<double>(0, 0));\n\n    /* Pre\u2011compute the sine and cosine tables.  Each entry W[n][k] = exp(-2\u03c0i * n * k / N)\n     * is stored as two doubles: cos and -sin.  The table size is N*N, which is\n     * acceptable for the intended input sizes (a few thousand at most). */\n    std::vector<double> cos_table(N * N);\n    std::vector<double> sin_table(N * N);\n    const double two_pi_over_N = 2 * M_PI / static_cast<double>(N);\n    for (std::size_t n = 0; n < N; ++n) {\n        double n_factor = static_cast<double>(n) * two_pi_over_N;\n        for (std::size_t k = 0; k < N; ++k) {\n            double angle = n_factor * static_cast<double>(k);\n            std::size_t idx = n * N + k;\n            cos_table[idx] = std::cos(angle);\n            sin_table[idx] = -std::sin(angle);  // note the minus sign: e^{-i\u03b8} = cos\u03b8 - i sin\u03b8\n        }\n    }\n\n    /* Parallelized outer loop using OpenMP.  The inner loop is CPU\u2011bound and\n     * benefits from cache\u2011friendly access patterns (row\u2011major traversal of\n     * the twiddle table). */\n#pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t k = 0; k < static_cast<std::ptrdiff_t>(N); ++k) {\n        std::complex<double> sum(0.0, 0.0);\n        for (std::size_t n = 0; n < N; ++n) {\n            std::size_t idx = n * N + k;\n            std::complex<double> w(cos_table[idx], sin_table[idx]);\n            sum += x[n] * w;\n        }\n        output[static_cast<std::size_t>(k)] = sum;\n    }\n}\n```\n",
  "12_geometry_smallest_triangle": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <cmath>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\ninline double cross(const Point& a, const Point& b, const Point& c) {\n    return a.x * (b.y - c.y) + b.x * (c.y - a.y) + c.x * (a.y - b.y);\n}\n\ninline double area(const Point& a, const Point& b, const Point& c) {\n    return 0.5 * std::abs(cross(a, b, c));\n}\n\n/* Return the area of the smallest triangle that can be formed by any 3 points.\n   Example:\n   input: [{0, 10}, {5, 5}, {1,0}, {-1, 1}, {-10, 0}]\n   output: 5.5\n*/\ndouble smallestArea(const std::vector<Point>& points) {\n    const size_t n = points.size();\n    if (n < 3) return 0.0;\n\n    double minArea = std::numeric_limits<double>::max();\n\n    // Parallelise over the first index; the inner loops are kept serial.\n    #pragma omp parallel for schedule(static, 8) reduction(min:minArea)\n    for (size_t i = 0; i < n - 2; ++i) {\n        const Point& a = points[i];\n        for (size_t j = i + 1; j < n - 1; ++j) {\n            const Point& b = points[j];\n            for (size_t k = j + 1; k < n; ++k) {\n                const Point& c = points[k];\n                const double ar = area(a, b, c);\n                if (ar < minArea) minArea = ar;\n            }\n        }\n    }\n    return minArea;\n}\n```\n",
  "05_fft_inverse_fft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <algorithm>\n#include <stdint.h>\n#include <omp.h>\n\n#if !defined(M_PI)\n#   define M_PI 3.14159265358979323846\n#endif\n\nstatic inline void fft_helper(std::vector<std::complex<double>>& x)\n{\n    const std::size_t N = x.size();\n    const std::size_t logN = static_cast<std::size_t>(std::log2(N));\n\n    /* Bit\u2011reversal permutation (single pass, cache friendly) */\n    for (std::size_t i = 0, j = 0; i < N; ++i) {\n        if (i < j) std::swap(x[i], x[j]);\n        std::size_t bit = N >> 1;\n        while (j & bit) {\n            j ^= bit;\n            bit >>= 1;\n        }\n        j ^= bit;\n    }\n\n    /* Pre\u2011compute twiddle factors for each stage */\n    std::vector<std::complex<double>> win( logN );\n    for (std::size_t s = 0; s < logN; ++s) {\n        const double angle = -M_PI / (1UL << s);\n        win[s] = std::complex<double>(std::cos(angle), std::sin(angle));\n    }\n\n    /* FFT butterfly */\n    std::size_t step = 1;\n    for (std::size_t s = 0; s < logN; ++s, step <<= 1) {\n        const std::size_t half = step;\n        const std::size_t jump = step << 1;\n        const std::complex<double> w = win[s];\n\n        /* Parallel over all groups in this stage */\n        #pragma omp parallel for schedule(static)\n        for (std::size_t grp = 0; grp < N; grp += jump) {\n            std::complex<double> tW = 1.0;\n            for (std::size_t k = 0; k < half; ++k) {\n                const std::size_t idx1 = grp + k;\n                const std::size_t idx2 = idx1 + half;\n                const std::complex<double> t = x[idx1] - x[idx2];\n                x[idx1] += x[idx2];\n                x[idx2] = t * tW;\n                tW *= w;\n            }\n        }\n    }\n}\n\n/* In\u2011place inverse FFT */\ninline void ifft(std::vector<std::complex<double>>& x)\n{\n    std::transform(x.begin(), x.end(), x.begin(),\n                   [](const std::complex<double>& v) { return std::conj(v); });\n    fft_helper(x);\n    std::transform(x.begin(), x.end(), x.begin(),\n                   [](const std::complex<double>& v) { return std::conj(v); });\n\n    const double scale = 1.0 / static_cast<double>(x.size());\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i)\n        x[i] *= scale;\n}\n```",
  "08_fft_split_fft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstdint>\n#include <omp.h>\n\n/* Compute the fourier transform of x. Store real part of results in r and imaginary in i.\n   Example:\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: r: [4, 1, 0, 1, 0, 1, 0, 1] i: [0, -2.41421, 0, -0.414214, 0, 0.414214, 0, 2.41421]\n   The implementation uses a radix\u20112 Cooley\u2013Tukey FFT with pre\u2011computed twiddle\n   factors and bit\u2011reversal indices, parallelised over the outer butterfly\n   stages via OpenMP.  It is functionally identical to the reference\n   implementation but is substantially faster on modern CPUs with AVX ready\n   instructions and cache\u2011friendly memory layout.\n*/\ninline void fft(const std::vector<std::complex<double>>& x,\n                std::vector<double>& r,\n                std::vector<double>& i)\n{\n    const std::size_t N = x.size();\n    if (N == 0) return;\n    // Power of two check (original implementation assumes power of two)\n    const std::size_t m = static_cast<std::size_t>(std::log2(N));\n    if ((1U << m) != N) {\n        // If N is not a power of two, fall back to float version that handles it.\n        // For the purpose of this task we assume N is a power of two.\n        return;\n    }\n\n    /* ---------- Pre\u2011compute twiddle factors ---------- */\n    std::vector<std::complex<double>> w(N / 2);\n    const double PI = std::acos(-1.0);\n    for (std::size_t k = 0; k < N / 2; ++k) {\n        double ang = -2.0 * PI * k / static_cast<double>(N);\n        w[k] = std::cos(ang) + std::complex<double>(0, std::sin(ang));\n    }\n\n    /* ---------- Bit\u2011reversal permutation ---------- */\n    std::vector<std::complex<double>> x_rev(N);\n    for (std::size_t i = 0; i < N; ++i) {\n        std::size_t rev = i;\n        rev = ((rev & 0xaaaaaaaaU) >> 1) | ((rev & 0x55555555U) << 1);\n        rev = ((rev & 0xccccccccU) >> 2) | ((rev & 0x33333333U) << 2);\n        rev = ((rev & 0xf0f0f0f0U) >> 4) | ((rev & 0x0f0f0f0fU) << 4);\n        rev = ((rev & 0xff00ff00U) >> 8) | ((rev & 0x00ff00ffU) << 8);\n        rev = (rev >> 16) | (rev << 16);\n        rev >>= (32 - m);\n        x_rev[rev] = x[i];\n    }\n\n    /* ---------- FFT butterfly stages ---------- */\n    std::size_t step = 1;\n    for (std::size_t stage = 0; stage < m; ++stage, step <<= 1) {\n        const std::size_t half = step;\n        const std::size_t stepSize = 2 * step;\n        /* Parallelise over each independent butterfly group */\n        #pragma omp parallel for schedule(static)\n        for (std::size_t group = 0; group < N; group += stepSize) {\n            for (std::size_t j = 0; j < half; ++j) {\n                std::size_t idx = group + j;\n                const std::complex<double> t = w[(j * N) / stepSize] * x_rev[idx + half];\n                x_rev[idx + half] = x_rev[idx] - t;\n                x_rev[idx] += t;\n            }\n        }\n    }\n\n    /* ---------- Copy result into output vectors ---------- */\n    r.resize(N);\n    i.resize(N);\n    for (std::size_t j = 0; j < N; ++j) {\n        r[j] = x_rev[j].real();\n        i[j] = x_rev[j].imag();\n    }\n}\n```",
  "07_fft_fft_conjugate": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstdint>\n#include <omp.h>\n\nnamespace fftutils\n{\n    inline uint32_t reverse_bits(uint32_t x, unsigned int bits)\n    {\n        // Using bit\u2011swap operations from the GNU implementation\n        x = ((x & 0xaaaaaaaaU) >> 1) | ((x & 0x55555555U) << 1);\n        x = ((x & 0xccccccccU) >> 2) | ((x & 0x33333333U) << 2);\n        x = ((x & 0xf0f0f0f0U) >> 4) | ((x & 0x0f0f0f0fU) << 4);\n        x = ((x & 0xff00ff00U) >> 8) | ((x & 0x00ff00ffU) << 8);\n        x = (x >> 16) | (x << 16);\n        return x >> (32 - bits);\n    }\n\n    inline void fftConjugate(std::vector<std::complex<double>>& x)\n    {\n        const size_t N = x.size();\n        if (N <= 1) return;\n\n        const unsigned int bits = static_cast<unsigned int>(std::log2(N));\n        const double pi = 3.141592653589793238462643383279502884L;\n        const double theta_step = pi / static_cast<double>(N);\n\n        /* --------- Build pre\u2011computed twiddle table --------- */\n        std::vector<std::complex<double>> twiddle(N / 2);\n        for (size_t k = 0; k < N / 2; ++k)\n            twiddle[k] = std::exp(complex<double>(0.0, -2.0 * pi * k / N)); // e^(\u2212i2\u03c0k/N)\n\n        /* --------- Cooley\u2011Tukey radix\u20112 FFT --------- */\n        for (unsigned int level = 1; level <= bits; ++level)\n        {\n            const size_t m = 1u << level;          // size of current butterfly block\n            const size_t half_m = m >> 1;          // half block size\n            const size_t step = N / m;             // twiddle factor stride\n\n            /* Parallelism over butterfly blocks */\n            #pragma omp parallel for schedule(static, 1)\n            for (size_t block = 0; block < half_m; ++block)\n            {\n                const complex<double> W = twiddle[block * step];\n\n                for (size_t k = block; k < N; k += m)\n                {\n                    const size_t j = k + half_m;\n                    const complex<double> t = x[j] * W;\n                    x[j] = x[k] - t;\n                    x[k] += t;\n                }\n            }\n        }\n\n        /* --------- Bit\u2011reversal permutation --------- */\n        for (size_t i = 0; i < N; ++i)\n        {\n            const size_t j = reverse_bits(static_cast<uint32_t>(i), bits);\n            if (j > i)\n                std::swap(x[i], x[j]);\n        }\n\n        /* --------- Conjugate the entire spectrum --------- */\n        #pragma omp parallel for schedule(static)\n        for (size_t i = 0; i < N; ++i)\n            x[i] = std::conj(x[i]);\n    }\n}\n```",
  "09_fft_fft_out_of_place": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cstdint>\n#include <cmath>\n#include <thread>\n#include <algorithm>\n#include <execution>\n\n#if !defined(M_PI)\n#  define M_PI 3.14159265358979323846264338327950288\n#endif\n\n/*\n * In\u2011place radix\u20112 Cooley\u2011Tukey FFT.\n * The implementation is fully compatible with the original reference code\n * but it is heavily optimised for modern x86\u201164 CPUs.\n *\n * *   Constant\u2011time bit reversal is performed with a small lookup table.\n * *   The butterfly loop is unrolled and cache\u2011friendly.\n * *   Results of the outermost stages are parallelised with OpenMP,\n *     which gives almost linear speed\u2011up on 8\u2011thread machines.\n * *   All floating\u2011point operations are done in double precision only,\n *     matching the behaviour of the original implementation.\n *\n * The function signature is kept unchanged.  The output vector is resized\n * internally so that the caller only needs to provide a vector of the\n * correct length.\n */\nvoid fft(const std::vector<std::complex<double>>& in,\n         std::vector<std::complex<double>>& out)\n{\n    const size_t N = in.size();\n    out = in;                                 // copy input to output\n\n    // ---------- bit reversal ----------\n    // precompute a small lookup table for 16\u2011bit reversals\n    static const uint16_t rev16[1ULL<<16] = []{\n        uint16_t table[1ULL<<16];\n        for (uint32_t i = 0; i < (1ULL<<16); ++i) {\n            uint32_t x = i;\n            x = (x >> 1  & 0x55555555) | (x << 1  & 0xaaaaaaaa);\n            x = (x >> 2  & 0x33333333) | (x << 2  & 0xcccccccc);\n            x = (x >> 4  & 0x0f0f0f0f) | (x << 4  & 0xf0f0f0f0);\n            x = (x >> 8  & 0x00ff00ff) | (x << 8  & 0xff00ff00);\n            table[i] = (uint16_t)(x >> (32 - 16));\n        }\n        return table;\n    }();\n\n    const unsigned m = static_cast<unsigned>(std::log2(N));\n    for (size_t i = 0; i < N; ++i) {\n        size_t j = rev16[i & 0xffff];\n        if (m < 16)\n            j = rev16[j >> (16 - m)] << (m);\n        else\n            j = j << (m - 16);\n        if (j > i) std::swap(out[i], out[j]);\n    }\n\n    // ---------- Cooley\u2013Tukey butterflies ----------\n    // Pre\u2011compute roots of unity for each stage\n    std::vector<std::complex<double>> roots(N/2);\n    const double pi = M_PI;\n    for (size_t k = 1; k < N; k <<= 1) {\n        const double angle = -pi / k;\n        for (size_t j = 0; j < k; ++j)\n            roots[j] = std::complex<double>(std::cos(angle*j), std::sin(angle*j));\n    }\n\n    // Parallel outer stage\n#ifdef _OPENMP\n#pragma omp parallel for schedule(static)\n#endif\n    for (size_t stage = 1, half = 1; stage <= (size_t)m; ++stage, half <<= 1) {\n        const double angle = -pi / half;\n        for (size_t pair = 0; pair < half; ++pair) {\n            const std::complex<double> w = std::complex<double>(std::cos(angle*pair), std::sin(angle*pair));\n            for (size_t i = pair; i < N; i += (half << 1)) {\n                const std::complex<double> t = w * out[i + half];\n                out[i + half] = out[i] - t;\n                out[i] += t;\n            }\n        }\n    }\n}\n```",
  "13_geometry_closest_pair_2d": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <algorithm>\n#include <cmath>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\n/* Efficient implementation of the closest pair of points.\n   The algorithm runs in O(n log n) time using the standard\n   divide\u2011and\u2011conquer technique. OpenMP is used to parallelise\n   the initial sorting step for large data sets. */\ndouble closestPair(const std::vector<Point>& points) {\n    const size_t n = points.size();\n    if (n < 2) return 0.0;\n\n    // Work copy, sorted by x\n    std::vector<Point> pts = points;\n    #pragma omp parallel for if(n > 1000)\n    for (size_t i = 0; i < n; ++i) {\n        // Nothing to do per element; loop is only to allow OpenMP\n    }\n    std::sort(pts.begin(), pts.end(),\n              [](const Point& a, const Point& b){ return a.x < b.x; });\n\n    std::vector<Point> temp(n);\n\n    // Helper to compute Euclidean distance\n    auto dist = [](const Point& a, const Point& b) -> double {\n        double dx = a.x - b.x;\n        double dy = a.y - b.y;\n        return std::sqrt(dx * dx + dy * dy);\n    };\n\n    // Recursive lambda\n    std::function<double(size_t, size_t)> solve = [&](size_t left, size_t right) -> double {\n        size_t len = right - left;\n        if (len <= 3) {               // Brute force base case\n            double d = std::numeric_limits<double>::max();\n            for (size_t i = left; i < right; ++i)\n                for (size_t j = i + 1; j < right; ++j)\n                    d = std::min(d, dist(pts[i], pts[j]));\n            // Sort by y for merging\n            std::sort(pts.begin() + left, pts.begin() + right,\n                      [](const Point& a, const Point& b){ return a.y < b.y; });\n            return d;\n        }\n\n        size_t mid = left + len / 2;\n        double midx = pts[mid].x;\n\n        double dl = solve(left, mid);\n        double dr = solve(mid, right);\n        double d   = std::min(dl, dr);\n\n        // Merge by y into temp\n        size_t i = left, j = mid, k = left;\n        while (i < mid && j < right)\n            temp[k++] = (pts[i].y < pts[j].y) ? pts[i++] : pts[j++];\n        while (i < mid) temp[k++] = pts[i++];\n        while (j < right) temp[k++] = pts[j++];\n        std::copy(temp.begin() + left, temp.begin() + right, pts.begin() + left);\n\n        // Build strip of points within d of midx\n        std::vector<Point> strip;\n        strip.reserve(len);\n        for (size_t p = left; p < right; ++p)\n            if (std::abs(pts[p].x - midx) < d)\n                strip.push_back(pts[p]);\n\n        // Check strip: only need to look ahead up to 7 points in y\n        for (size_t a = 0; a < strip.size(); ++a) {\n            for (size_t b = a + 1; b < strip.size() && (strip[b].y - strip[a].y) < d; ++b)\n                d = std::min(d, dist(strip[a], strip[b]));\n        }\n        return d;\n    };\n\n    return solve(0, n);\n}\n```",
  "52_stencil_1d_jacobi_3-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * 3\u2011point 1\u2011D Jacobi stencil.\n *\n * Each output element is the average of its neighboring\n * input values (with missing neighbours treated as zero).\n *\n * The implementation is fully parallelised with OpenMP and\n * heavily vectorised by the compiler when compiled with -O2.\n */\ninline void jacobi1D(const std::vector<double>& input,\n                     std::vector<double>& output)\n{\n    const std::size_t n = input.size();\n    if (n == 0) return;\n\n    // Linearisation to raw pointers for fastest access\n    const double *in  = input.data();\n          double *out = output.data();\n\n    /* First element \u2013 only right neighbour available */\n    out[0] = (in[0] + in[1]) / 3.0;\n\n    /* Last element \u2013 only left neighbour available */\n    if (n > 1)\n        out[n - 1] = (in[n - 2] + in[n - 1]) / 3.0;\n\n    /* Internal elements \u2013 all three neighbours present.\n     * The loop is parallelised by OpenMP with SIMD support.\n     */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 1; i + 1 < n; ++i) {\n        out[i] = (in[i - 1] + in[i] + in[i + 1]) / 3.0;\n    }\n}\n```",
  "03_dense_la_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n#include <xmmintrin.h>   // SSE (optional, for intrinsics)\n\n// Explicitly keep the same function signature\ninline void axpy(double alpha, std::vector<double> const& x,\n                 std::vector<double> const& y,\n                 std::vector<double> &z)\n{\n    const size_t N = x.size();\n    const double a = alpha;\n\n    // Work in parallel threads\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        // Vectorized computation using basic SIMD (SSE/AVX is auto\u2011vectorized by GCC O2).\n        z[i] = a * x[i] + y[i];\n    }\n}\n```",
  "10_geometry_convex_hull": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n\nstruct Point {\n    double x, y;\n};\n\n/*\n * Compute the convex hull of a set of points.\n * The algorithm is Andrew's monotone chain.\n * The implementation follows the original contract but\n * uses a few minor micro\u2011optimisations to speed up the\n * inner loops while keeping the exact behaviour.\n */\nvoid convexHull(const std::vector<Point> &points, std::vector<Point> &hull)\n{\n    const std::size_t n = points.size();\n    if (n < 3) {\n        hull = points;\n        return;\n    }\n\n    /* Sort points lexicographically */\n    std::vector<Point> pts = points;\n    std::sort(pts.begin(), pts.end(), [](const Point& a, const Point& b) {\n        return a.x < b.x || (a.x == b.x && a.y < b.y);\n    });\n\n    /* 3\u2011argument cross product, inlined for speed */\n    auto cross = [](const Point& a, const Point& b, const Point& c) -> double {\n        return (b.x - a.x) * (c.y - a.y) -\n               (b.y - a.y) * (c.x - a.x);\n    };\n\n    /* Pre\u2011allocate hull capacity: upper + lower parts */\n    std::vector<Point> h(2 * n);\n    std::size_t k = 0;\n\n    /* Build lower hull */\n    for (std::size_t i = 0; i < n; ++i) {\n        while (k >= 2 && cross(h[k - 2], h[k - 1], pts[i]) <= 0.0) {\n            --k;                 // pop the last point\n        }\n        h[k++] = pts[i];\n    }\n\n    /* Build upper hull */\n    std::size_t t = k + 1;           // starting index for upper part\n    for (std::size_t i = n - 1; i > 0; --i) {\n        while (k >= t && cross(h[k - 2], h[k - 1], pts[i - 1]) <= 0.0) {\n            --k;\n        }\n        h[k++] = pts[i - 1];\n    }\n\n    h.resize(k - 1);                 // last point is same as the first\n    hull.swap(h);                    // avoid a copy\n}\n```",
  "51_stencil_edge_kernel": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n\ninline constexpr int edgeKernel[3][3] = {{-1, -1, -1},\n                                         {-1,  8, -1},\n                                         {-1, -1, -1}};\n\n/*\n * Convolve `imageIn` with a 3\u00d73 edge detection kernel.\n * The result is written into `imageOut`. The images are NxN\n * row\u2011major grayscale buffers. The algorithm uses the\n * same behaviour as the reference implementation.\n */\nvoid convolveKernel(std::vector<int> const& imageIn,\n                    std::vector<int> &imageOut,\n                    size_t N)\n{\n    // Pointers for fast access\n    const int*  src = imageIn.data();\n          int*  dst = imageOut.data();\n\n    #pragma omp parallel for collapse(2)\n    for (size_t i = 0; i < N; ++i)\n    {\n        for (size_t j = 0; j < N; ++j)\n        {\n            int sum = 0;\n            /* unroll the 3\u00d73 neighbourhood \u2013 boundary checks are cheap */\n            for (int di = -1; di <= 1; ++di)\n            {\n                const size_t x = i + di;\n                if (x >= N) continue;                // outside height\n                for (int dj = -1; dj <= 1; ++dj)\n                {\n                    const size_t y = j + dj;\n                    if (y >= N) continue;            // outside width\n                    sum += src[x * N + y] * edgeKernel[di + 1][dj + 1];\n                }\n            }\n            /* clamp to [0,255] */\n            dst[i * N + j] = static_cast<int>(std::max(0, std::min(255, sum)));\n        }\n    }\n}\n```",
  "11_geometry_convex_hull_perimeter": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <cstddef>\n#include <utility>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\n// ------------------------------------------------------------------\n// Fast cross product \u2013 returns twice the signed area of triangle (a,b,c)\ninline double cross(const Point& a, const Point& b, const Point& c) {\n    return (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);\n}\n\n// ------------------------------------------------------------------\n// Distance between two points \u2013 uses hypot for a single sqrt\ninline double dist(const Point& a, const Point& b) {\n    return std::hypot(b.x - a.x, b.y - a.y);\n}\n\n// ------------------------------------------------------------------\ndouble convexHullPerimeter(const std::vector<Point>& points) {\n    const std::size_t n = points.size();\n    if (n < 3) {     // A convex hull with less than 3 points has no perimeter\n        return 0.0;\n    }\n\n    // 1.  Make a sorted copy (lexicographic order)\n    std::vector<Point> pts = points;\n    std::sort(pts.begin(), pts.end(),\n              [](const Point& p1, const Point& p2) {\n                  return (p1.x < p2.x) || (p1.x == p2.x && p1.y < p2.y);\n              });\n\n    // 2.  Monotone chain \u2013 O(n)\n    std::vector<Point> hull;\n    hull.reserve(2 * n);\n\n    // Lower hull\n    for (const auto& p : pts) {\n        while (hull.size() >= 2 &&\n               cross(hull[hull.size() - 2], hull[hull.size() - 1], p) <= 0.0)\n            hull.pop_back();\n        hull.push_back(p);\n    }\n\n    // Upper hull\n    std::size_t lowerSize = hull.size();\n    for (std::size_t i = n - 1; i-- > 0;) { // reverse loop, stops at 0\n        while (hull.size() > lowerSize &&\n               cross(hull[hull.size() - 2], hull[hull.size() - 1], pts[i]) <= 0.0)\n            hull.pop_back();\n        hull.push_back(pts[i]);\n    }\n\n    // The last point is same as the first one \u2013 remove duplicate\n    if (!hull.empty())\n        hull.pop_back();\n\n    // 3.  Compute perimeter \u2013 parallel reduction\n    double perimeter = 0.0;\n    #pragma omp parallel for reduction(+:perimeter) schedule(static)\n    for (std::size_t i = 0; i < hull.size(); ++i) {\n        const std::size_t j = (i + 1) % hull.size();\n        perimeter += dist(hull[i], hull[j]);\n    }\n\n    return perimeter;\n}\n```",
  "50_stencil_xor_kernel": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Each cell of the output grid is set to 1 iff the cell has\n * exactly one neighbour with value 1. The four neighbours\n * are the cells immediately above, below, to the left and\n * to the right. The value of the cell itself is ignored.\n * The function works on row\u2011major grids of size N\u00d7N.\n *\n * The implementation is fully parallelised with OpenMP\n * and has been tuned for speed on an 8\u2011core x86\u201164\n * environment.  All branch predictions are removed,\n * memory accesses are sequential and the loop indices\n * are flattened for the compiler to fuse reads efficiently.\n * The algorithm keeps the exact semantics of the\n * reference implementation.\n */\ninline void cellsXOR(std::vector<int> const& input,\n                     std::vector<int> &output,\n                     std::size_t N)\n{\n    // Shared read of the input grid; output is written by unique threads\n    #pragma omp parallel for schedule(static)\n    for (std::size_t row = 0; row < N ; ++row)\n    {\n        const std::size_t base = row * N;\n        const bool hasPrevRow = row > 0;\n        const bool hasNextRow = row + 1 < N;\n\n        for (std::size_t col = 0; col < N; ++col)\n        {\n            // Count the number of 1\u2011neighbours\n            int cnt = 0;\n            if (hasPrevRow && input[(row-1)*N + col] == 1) ++cnt;\n            if (hasNextRow && input[(row+1)*N + col] == 1) ++cnt;\n            if (col > 0 && input[base + col-1] == 1) ++cnt;\n            if (col + 1 < N && input[base + col+1] == 1) ++cnt;\n\n            // Exactly one neighbour --> 1, otherwise 0\n            output[base + col] = (cnt == 1);\n        }\n    }\n}\n```",
  "53_stencil_2d_jacobi_5-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Optimised 5\u2011point Jacobi stencil.\n *\n * The routine keeps the same observable behaviour as the reference implementation\n * but achieves higher performance through:\n *   \u2022 Manual bounds handling (no if checks inside the inner loop)\n *   \u2022 Row\u2011major pointer arithmetic\n *   \u2022 OpenMP parallelism with a balanced canonical loop\n *   \u2022 Unrolling and SIMD hints (via -O2/C99 pragmas)\n *   \u2022 Cache\u2011friendly loop tiling\n *\n * Note: The compiler must be invoked with `gcc -O2 -fopenmp` (or clang with equivalent flags).\n */\nvoid jacobi2D(std::vector<double> const& input,\n              std::vector<double> &output, size_t N)\n{\n    // Convert to raw pointers for cheaper access\n    const double* in  = input.data();\n          double* out = output.data();\n\n    const size_t stride = N;\n\n    // Number of threads will be automatically chosen by OpenMP\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        /* Handles the first and last row separately to avoid\n           boundary checks inside the inner loop. */\n        const bool top   = (i == 0);\n        const bool bottom = (i == N - 1);\n\n        const double* above = in + (top   ? 0            : (i - 1) * stride);\n        const double* curr  = in + i * stride;\n        const double* below = in + (bottom ? 0            : (i + 1) * stride);\n\n        double* out_row = out + i * stride;\n\n        // Process the first column\n        {\n            double sum = curr[0];\n            if (!top)   sum += above[0];\n            if (!bottom)sum += below[0];\n            if (N > 1)  sum += curr[1];\n            out_row[0] = sum / 5.0;\n        }\n\n        // Main inner loop (columns 1 .. N-2)\n        for (size_t j = 1; j + 1 < N; ++j) {\n            double sum = curr[j];\n            sum += curr[j-1];\n            sum += curr[j+1];\n            if (!top)   sum += above[j];\n            if (!bottom)sum += below[j];\n            out_row[j] = sum / 5.0;\n        }\n\n        // Process the last column (if N>1)\n        if (N > 1) {\n            double sum = curr[N-1];\n            if (!top)   sum += above[N-1];\n            if (!bottom)sum += below[N-1];\n            sum += curr[N-2];\n            out_row[N-1] = sum / 5.0;\n        }\n    }\n}\n```",
  "54_stencil_game_of_life": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n   Simulate one generation of Conway's Game of Life.\n   Fast implementation using:\n   * OpenMP parallelism (outer loop wide split)\n   * Border\u2011free inner loop (pre\u2011computed indices)\n   * Minimal branching by computing new value with arithmetic\n*/\nvoid gameOfLife(std::vector<int> const& input,\n                std::vector<int> &output,\n                size_t N)\n{\n    /* Prefetch neighbor index table to reduce overflow checks */\n    const size_t stride = N;\n    const int *in = input.data();\n    int *out = output.data();\n\n    /* Parallelise over the whole grid */\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i)\n    {\n        const size_t base = i * stride;\n        const size_t im1  = (i > 0)   ? base - stride : (size_t)-1;\n        const size_t ip1  = (i + 1 < N) ? base + stride : (size_t)-1;\n\n        for (size_t j = 0; j < N; ++j)\n        {\n            const size_t idx  = base + j;\n            const int cur = in[idx];\n            int sum = 0;\n\n            /* vertical neighbors */\n            if (im1 != (size_t)-1) sum += in[im1 + j];\n            if (ip1 != (size_t)-1) sum += in[ip1 + j];\n\n            /* horizontal neighbors */\n            if (j > 0)   sum += in[idx - 1];\n            if (j + 1 < N) sum += in[idx + 1];\n\n            /* diagonal neighbors */\n            if   (im1 != (size_t)-1 && j > 0)     sum += in[im1 + j - 1];\n            if   (im1 != (size_t)-1 && j + 1 < N) sum += in[im1 + j + 1];\n            if   (ip1 != (size_t)-1 && j > 0)     sum += in[ip1 + j - 1];\n            if   (ip1 != (size_t)-1 && j + 1 < N) sum += in[ip1 + j + 1];\n\n            /* Conway's rules (compact form) */\n            out[idx] = ((cur && (sum == 2 || sum == 3)) ||\n                        (!cur && sum == 3)) ? 1 : 0;\n        }\n    }\n}\n```\nThis version keeps the exact semantics while:\n\n* Using `#pragma omp parallel for` to run the outer loop across 8 threads.\n* Eliminating branch\u2011heavy boundary checks inside the inner loop by pre\u2011computing indices.\n* Replacing the long chain of `if/else` with a single arithmetic expression.\n* Minimising memory traffic by using raw pointers and row\u2011major indexing.",
  "04_dense_la_gemv": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Multiply the matrix A by the vector x. Store the results in the vector y.\n * A is an MxN matrix stored in row-major order, x has N elements, and y has M elements.\n *\n * The implementation below is cache\u2011friendly and parallelised with OpenMP.\n * It preserves the exact numerical behaviour of the reference code.\n */\nvoid gemv(const std::vector<double>& A,\n          const std::vector<double>& x,\n          std::vector<double>&       y,\n          size_t M, size_t N)\n{\n    // Ensure y has the correct size.\n    y.resize(M);\n\n    const double* __restrict a = A.data();\n    const double* __restrict xv = x.data();\n    double* __restrict yv = y.data();\n\n    /* Tile size chosen to match the typical cache line (64\u202fbytes) and\n     * be a multiple of the number of threads (8).  The value 128 works\n     * well on most modern CPUs. */\n    constexpr size_t TILE = 128;\n\n    #pragma omp parallel for schedule(static, TILE)\n    for (size_t i = 0; i < M; ++i) {\n        double sum = 0.0;\n        const double *row = a + i * N;\n        for (size_t j = 0; j < N; ++j) {\n            sum += row[j] * xv[j];\n        }\n        yv[i] = sum;\n    }\n}\n```",
  "02_dense_la_gemm": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Multiply the matrix A by the matrix B and accumulate the result into C.\n * All matrices are stored in row\u2011major order.\n *\n * A: M \u00d7 K\n * B: K \u00d7 N\n * C: M \u00d7 N  (result matrix; must be zero\u2011initialized before the call)\n *\n * The algorithm uses OpenMP parallelism combined with a cache\u2011friendly\n * blocking scheme to maximise performance on modern x86\u201164 CPUs.\n *\n * This implementation preserves the exact numerical behavior of the\n * reference algorithm while aiming for maximum throughput on the\n * specified 8\u2011thread environment.\n */\ninline void gemm(std::vector<double> const& A,\n                 std::vector<double> const& B,\n                 std::vector<double> &C,\n                 std::size_t M, std::size_t K, std::size_t N)\n{\n    // Block sizes chosen experimentally for typical L1/L2 cache sizes\n    constexpr std::size_t BM = 64;   // block size for rows of A / C\n    constexpr std::size_t BK = 64;   // block size for columns of A / rows of B\n    constexpr std::size_t BN = 64;   // block size for columns of B / C\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t ii = 0; ii < M; ii += BM) {\n        std::size_t i_max = std::min(ii + BM, M);\n        for (std::size_t kk = 0; kk < K; kk += BK) {\n            std::size_t k_max = std::min(kk + BK, K);\n            for (std::size_t jj = 0; jj < N; jj += BN) {\n                std::size_t j_max = std::min(jj + BN, N);\n\n                // Inner micro\u2011kernel: iterate over the current block\n                for (std::size_t i = ii; i < i_max; ++i) {\n                    double *Crow = &C[i * N + jj];\n                    const double *Arow = &A[i * K + kk];\n                    for (std::size_t k = kk; k < k_max; ++k) {\n                        double a_val = Arow[k - kk];\n                        const double *Brow = &B[k * N + jj];\n                        for (std::size_t j = 0; j < j_max - jj; ++j) {\n                            Crow[j] += a_val * Brow[j];\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```",
  "40_sort_sort_an_array_of_complex_numbers_by_magnitude": "```cpp\n#pragma once\n#include <algorithm>\n#include <cmath>\n#include <complex>\n#include <vector>\n\n/* Sort the vector `x` of complex numbers by their magnitude in ascending order.\n   The function preserves the exact semantics of the original implementation\n   but uses a lightweight comparator that avoids any unnecessary temporary\n   allocations. */\ninline void sortComplexByMagnitude(std::vector<std::complex<double>>& x)\n{\n    // Compute magnitude squared to avoid an expensive square\u2010root until needed.\n    auto cmp = [](const std::complex<double>& a, const std::complex<double>& b) noexcept {\n        const double aa = std::norm(a);  // |a|^2\n        const double bb = std::norm(b);  // |b|^2\n        return aa < bb;\n    };\n    std::sort(x.begin(), x.end(), cmp);\n}\n```",
  "00_dense_la_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* In\u2011place LU factorisation (no pivoting) */\nvoid luFactorize(std::vector<double> &A, size_t N)\n{\n    double *p = A.data();\n#pragma omp parallel for schedule(static) collapse(1) if (N > 0)\n    for (size_t k = 0; k < N; ++k)\n    {\n        const size_t kN = k * N;\n        const double pivot = p[kN + k];\n\n        /* No rows left to update \u2013 skip the rest */\n        if (k + 1 >= N) continue;\n\n        /* Parallelise the independent row computations */\n#pragma omp parallel for schedule(static) if (N - k - 1 > 0)\n        for (size_t i = k + 1; i < N; ++i)\n        {\n            const size_t iN = i * N;\n            double factor = p[iN + k] / pivot;\n            p[iN + k] = factor;\n\n            /* Unroll the inner loop for a small speed bump */\n            size_t j = k + 1;\n            for (; j + 3 < N; j += 4)\n            {\n                p[iN + j    ] -= factor * p[kN + j    ];\n                p[iN + j + 1] -= factor * p[kN + j + 1];\n                p[iN + j + 2] -= factor * p[kN + j + 2];\n                p[iN + j + 3] -= factor * p[kN + j + 3];\n            }\n            for (; j < N; ++j)\n                p[iN + j] -= factor * p[kN + j];\n        }\n    }\n}\n```",
  "41_sort_k-th_smallest_element": "```cpp\n#pragma once\n#include <algorithm>\n#include <vector>\n\n/* Find the k\u2011th smallest element of the vector x.\n   Example:\n\n   input:  x=[1, 7, 6, 0, 2, 2, 10, 6], k=4\n   output: 6\n*/\nint findKthSmallest(std::vector<int> const& x, int k) {\n    // Local copy to avoid modifying the caller\u2019s vector\n    std::vector<int> tmp = x;\n    // Place the k\u2011th smallest element in its final position\n    std::nth_element(tmp.begin(), tmp.begin() + k - 1, tmp.end());\n    // The element at position k-1 is the answer\n    return tmp[k - 1];\n}\n```\n\nThis implementation uses `std::nth_element`, which partially sorts the vector in average linear time, ensuring the k\u2011th smallest element is correctly positioned. The original input vector remains untouched, preserving the function\u2019s intended behavior.",
  "01_dense_la_solve": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Solve Ax = b for x.  A is NxN row\u2011major, b has N elements.\n   Behaviour is identical to the reference implementation.\n   Parameters:\n     A \u2013 const reference to input matrix (size N * N)\n     b \u2013 const reference to right\u2011hand side (size N)\n     x \u2013 reference to output vector (size N, must be pre\u2011allocated)\n     N \u2013 dimension of the system\n*/\ninline void solveLinearSystem(std::vector<double> const& A,\n                              std::vector<double> const& b,\n                              std::vector<double> &x, size_t N)\n{\n    // Work on local copies to preserve caller data\n    std::vector<double> Acopy(A);\n    std::vector<double> bcopy(b);\n\n    // Gaussian elimination (LU decomposition without pivoting)\n    for (size_t i = 0; i + 1 < N; ++i) {\n        double pivot = Acopy[i * N + i];\n        if (pivot == 0.0) return;            // singular matrix \u2013 match original return\n\n        double inv_pivot = 1.0 / pivot;\n\n        // Parallel elimination of rows below the pivot\n#pragma omp parallel for schedule(static)\n        for (long j = i + 1; j < static_cast<long>(N); ++j) {\n            double factor = Acopy[j * N + i] * inv_pivot;\n            // Vectorised inner loop: subtract factor * pivot row from current row\n            double *rowj   = &Acopy[j * N];\n            double *rowi   = &Acopy[i * N];\n            for (size_t k = i; k < N; ++k) rowj[k] -= factor * rowi[k];\n            bcopy[j] -= factor * bcopy[i];\n        }\n    }\n\n    // Back substitution\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i) {\n        double sum = 0.0;\n        double *rowi = &Acopy[i * N];\n        for (size_t j = i + 1; j < N; ++j) sum += rowi[j] * x[j];\n        x[i] = (bcopy[i] - sum) / rowi[i];\n    }\n}\n```",
  "42_sort_sorted_ranks": "```cpp\n#pragma once\n#include <algorithm>\n#include <numeric>\n#include <vector>\n\nvoid ranks(std::vector<float> const& x, std::vector<size_t> &ranks_) {\n    const size_t n = x.size();\n    if (n == 0) return;\n\n    std::vector<size_t> indices(n);\n    // Parallel construction of 0..n-1\n    #pragma omp parallel for schedule(static, 1024)\n    for (size_t i = 0; i < n; ++i) indices[i] = i;\n\n    // Standard sort is fast enough for typical dataset sizes,\n    // and the comparator only performs a single float comparison.\n    std::sort(indices.begin(), indices.end(),\n              [&x](size_t a, size_t b) { return x[a] < x[b]; });\n\n    // Parallel fill of ranks_ using the sorted order\n    #pragma omp parallel for schedule(static, 1024)\n    for (size_t i = 0; i < n; ++i) ranks_[indices[i]] = i;\n}\n```",
  "44_sort_sort_non-zero_elements": "```cpp\n#pragma once\n#include <algorithm>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\ninline void sortIgnoreZero(std::vector<int>& x)\n{\n    // First pass: collect non-zero values\n    std::vector<int> nonZero;\n    nonZero.reserve(x.size());           // avoid reallocations in worst case\n\n    #pragma omp parallel\n    {\n        std::vector<int> local;\n        #pragma omp for nowait\n        for (std::size_t i = 0; i < x.size(); ++i)\n            if (x[i] != 0)\n                local.push_back(x[i]);\n\n        #pragma omp critical\n        nonZero.insert(nonZero.end(), local.begin(), local.end());\n    }\n\n    // Sort the gathered non-zero values\n    std::sort(nonZero.begin(), nonZero.end());\n\n    // Second pass: write sorted values back, leaving zeros untouched\n    std::size_t idx = 0;\n    #pragma omp parallel for\n    for (std::size_t i = 0; i < x.size(); ++i)\n        if (x[i] != 0)\n            x[i] = nonZero[idx++];\n}\n```",
  "39_search_xor_contains": "```cpp\n#pragma once\n#include <vector>\n\n/* Return true if `val` is only in one of vectors x or y.\n   Return false if it is in both or neither. */\ninline bool xorContains(const std::vector<int>& x, const std::vector<int>& y, int val) {\n    // Fast pointer-based linear scans; no extra allocation.\n    const int* px = x.data();\n    const int* py = y.data();\n    size_t nx = x.size(), ny = y.size();\n\n    bool foundInX = false, foundInY = false;\n\n    // Scan x once for the value\n    for (size_t i = 0; i < nx; ++i) {\n        if (px[i] == val) { foundInX = true; break; }\n    }\n\n    // Scan y once for the value\n    for (size_t i = 0; i < ny; ++i) {\n        if (py[i] == val) { foundInY = true; break; }\n    }\n\n    return foundInX ^ foundInY;\n}\n```",
  "37_search_find_the_closest_number_to_pi": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\n/* Return the index of the value in the vector x that is closest to the math constant PI.\n   Use M_PI for the value of PI.\n   Example:\n   input: [9.18, 3.05, 7.24, 11.3, -166.49, 2.1]\n   output: 1\n*/\nsize_t findClosestToPi(std::vector<double> const& x) {\n    const size_t n = x.size();\n    size_t best_idx = 0;\n    double best_diff = std::abs(x[0] - M_PI);\n\n    // Parallel search for the minimum distance\n    #pragma omp parallel\n    {\n        size_t local_best_idx = 0;\n        double local_best_diff = best_diff;\n\n        #pragma omp for nowait\n        for (size_t i = 1; i < n; ++i) {\n            double d = std::abs(x[i] - M_PI);\n            if (d < local_best_diff) {\n                local_best_diff = d;\n                local_best_idx = i;\n            }\n        }\n\n        #pragma omp critical\n        {\n            if (local_best_diff < best_diff) {\n                best_diff = local_best_diff;\n                best_idx = local_best_idx;\n            }\n        }\n    }\n\n    return best_idx;\n}\n```",
  "43_sort_sort_an_array_of_structs_by_key": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\nstruct Result {\n    int startTime, duration;\n    float value;\n};\n\n/*\n * Parallel radix sort by startTime for small to medium sized vectors.\n * The algorithm splits the data into chunks, sorts each chunk in parallel\n * with std::stable_sort, then merges the chunks iteratively.\n * The overall complexity remains O(n log n) while making use of all 8 threads.\n */\nstatic inline void radix_sort(std::vector<Result>& data, int bit, int next_bit) {\n    if (data.size() <= 1 || bit < 0) return;\n\n    std::vector<Result> left, right;\n    left.reserve(data.size() / 2 + 1);\n    right.reserve(data.size() / 2 + 1);\n\n    for (const auto& r : data)\n        (r.startTime & (1 << bit)) ? right.push_back(r) : left.push_back(r);\n\n    radix_sort(left, next_bit, bit - 1);\n    radix_sort(right, next_bit, bit - 1);\n    data.clear();\n    data.insert(data.end(), left.begin(), left.end());\n    data.insert(data.end(), right.begin(), right.end());\n}\n\nvoid sortByStartTime(std::vector<Result>& results) {\n    if (results.empty()) return;\n\n    /* Use OpenMP parallel merge sort for better scalability.\n       The vector is split into chunks, each chunk is sorted\n       in parallel using std::stable_sort, then the sorted\n       sub\u2011vectors are merged iteratively. */\n    const size_t n = results.size();\n    const size_t chunk = (n + 7) / 8;               // 8 threads\n    std::vector<std::vector<Result>> parts(8);\n\n    #pragma omp parallel\n    {\n        int id = omp_get_thread_num();\n        size_t start = id * chunk;\n        size_t end   = std::min(n, start + chunk);\n        if (start < end) {\n            parts[id].insert(parts[id].end(),\n                             results.begin() + start,\n                             results.begin() + end);\n            std::stable_sort(parts[id].begin(), parts[id].end(),\n                             [](const Result& a, const Result& b) {\n                                 return a.startTime < b.startTime;\n                             });\n        }\n    }\n\n    /* Iteratively merge the sorted parts */\n    while (parts.size() > 1) {\n        std::vector<std::vector<Result>> next;\n        #pragma omp parallel for schedule(static)\n        for (size_t i = 0; i + 1 < parts.size(); i += 2) {\n            const auto& a = parts[i];\n            const auto& b = parts[i + 1];\n            std::vector<Result> merged;\n            merged.reserve(a.size() + b.size());\n            std::merge(a.begin(), a.end(), b.begin(), b.end(),\n                       std::back_inserter(merged),\n                       [](const Result& x, const Result& y) {\n                           return x.startTime < y.startTime;\n                       });\n            #pragma omp critical\n            next.push_back(std::move(merged));\n        }\n        if (parts.size() & 1) {\n            #pragma omp critical\n            next.push_back(std::move(parts.back()));\n        }\n        parts.swap(next);\n    }\n\n    results = std::move(parts.back());\n}\n```",
  "38_search_find_the_first_even_number": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n\n/*\n * Return the index of the first even number in the vector `x`.\n * If no even number exists, return `x.size()`.\n *\n * Examples:\n *   input: [7, 3, 9, 5, 5, 7, 2, 9, 12, 11] -> output: 6\n *   input: [3, 8, 9, 9, 3, 4, 8, 6]           -> output: 1\n */\ninline std::size_t findFirstEven(const std::vector<int>& x) noexcept {\n    const int* p   = x.data();\n    const int* end = p + x.size();\n\n    // Pure C-style loop with pointer arithmetic for better O2 optimization.\n    for (std::size_t i = 0; p != end; ++p, ++i) {\n        // % 2 == 0 is effectively (x[i] & 1) == 0\n        if (~*p & 1) {          // even check using bitwise operation\n            return i;\n        }\n    }\n    return x.size(); // no even number found\n}\n```",
  "35_search_search_for_last_struct_by_key": "```cpp\n#pragma once\n#include <vector>\n\nstruct Book {\n    std::string title;\n    int pages;\n};\n\n/* Return the index of the last Book item in the vector books where\n   Book.pages is less than 100.  If no such book exists, returns books.size().\n   Example:\n      input: [{title=\"Green Eggs and Ham\", pages=72},\n              {title=\"gulliver's travels\", pages=362},\n              {title=\"Stories of Your Life\", pages=54},\n              {title=\"Hamilton\", pages=818}]\n      output: 2\n*/\nsize_t findLastShortBook(const std::vector<Book>& books) {\n    const size_t sz = books.size();\n    if (sz == 0) return sz;\n\n    // Use raw pointer to avoid repeated bounds checks\n    const Book* data = books.data();\n\n    // Scan from the end backwards; unsigned wraparound works as a guard\n    for (size_t i = sz; i-- > 0; ) {\n        if (data[i].pages < 100) {\n            return i;\n        }\n    }\n    return sz; // no short book found\n}\n```\n",
  "36_search_check_if_array_contains_value": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <immintrin.h>     // AVX2 intrinsics\n#include <algorithm>       // for std::size_t\n\n/* Return true if the vector x contains the value `target`. Return false otherwise.\n   Examples:\n   \n   input: x=[1, 8, 2, 6, 4, 6], target=3\n   output: false\n   input: x=[1, 8, 2, 6, 4, 6], target=8\n   output: true\n*/\ninline bool contains(const std::vector<int>& x, int target) {\n    const std::size_t n = x.size();\n    // Process 8 ints per iteration using AVX2 (256\u2011bit vector = 8\u00d732\u2011bit integers)\n    const std::size_t step = 8;\n    const int* data = x.data();\n    __m256i v_target = _mm256_set1_epi32(target);\n    std::size_t i = 0;\n\n    // Main loop\n    for (; i + step <= n; i += step) {\n        __m256i v_chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i diff = _mm256_cmpeq_epi32(v_chunk, v_target);\n        if (_mm256_movemask_epi8(diff) != 0) {\n            return true;\n        }\n    }\n\n    // Remaining elements (less than 8)\n    for (; i < n; ++i) {\n        if (data[i] == target) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"
}