{
  "15_graph_edge_count": "```cpp\n#pragma once\n#include <cstddef>\n#include <cstdint>\n#include <vector>\n#include <omp.h>\n\n/* Count the number of edges in a directed graph defined by the adjacency\n   matrix A. A is an N\u00d7N matrix stored in row-major order.\n   The function returns the exact count as an int, but the internal\n   accumulation uses a 64\u2011bit counter to avoid overflow for large graphs\n   and then casts back to int at the end. */\ninline int edgeCount(const std::vector<int> &A, std::size_t N) {\n    const int *data = A.data();\n    std::size_t total = N * N;\n    std::int64_t counter = 0;\n\n    #pragma omp parallel for reduction(+:counter) schedule(static)\n    for (std::size_t idx = 0; idx < total; ++idx) {\n        if (data[idx] == 1) ++counter;\n    }\n\n    return static_cast<int>(counter);\n}\n```",
  "17_graph_highest_degree": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>\n\n/* Compute the highest node degree in the undirected graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is undirected.\n   Example:\n    input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(std::vector<int> const& A, size_t N) {\n    // Use a single-pass parallel reduction to find the maximum degree.\n    int highestDegree = 0;\n\n    // Keep a local copy of the data pointer for faster access.\n    const int *data = A.data();\n    const int stride = static_cast<int>(N);\n\n#pragma omp parallel for schedule(static) reduction(max:highestDegree)\n    for (int i = 0; i < static_cast<int>(N); ++i) {\n        int deg = 0;\n        const int *row = data + i * stride;\n        // Unroll inner loop for a small speedup.\n        for (int j = 0; j < static_cast<int>(N); ++j) {\n            deg += row[j];\n        }\n        if (deg > highestDegree) highestDegree = deg;\n    }\n    return highestDegree;\n}\n```",
  "20_histogram_pixel_histogram": "```cpp\n#pragma once\n#include <vector>\n#include <array>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Count the number of pixels in image with each grayscale intensity.\n * The vector `image` is a grayscale image with values 0-255.\n * Store the results in `bins`.\n */\ninline void pixelCounts(const std::vector<int>& image, std::array<std::size_t, 256>& bins) {\n    // Zero the result array\n    bins.fill(0);\n\n    // Number of OpenMP threads available\n    const int nthreads = omp_get_max_threads();\n\n    // Each thread uses its private copy of bins to avoid cache contention\n    std::vector<std::array<std::size_t, 256>> threadBins(nthreads);\n\n    // Parallel counting\n    #pragma omp parallel\n    {\n        int tid = omp_get_thread_num();\n        auto& tBins = threadBins[tid];\n\n        // Fast loop over the image slice assigned to this thread\n        const std::size_t total = image.size();\n        const std::size_t stride = 1;               // Simple stride for fine-grained load\n        #pragma omp for schedule(static, 1024) // cache-friendly chunk\n        for (std::size_t i = 0; i < total; ++i) {\n            tBins[image[i]] += 1;\n        }\n    }\n\n    // Reduce per-thread bins into final result\n    for (int t = 0; t < nthreads; ++t) {\n        const auto& tBins = threadBins[t];\n        for (int val = 0; val < 256; ++val) {\n            bins[val] += tBins[val];\n        }\n    }\n}\n```\n",
  "16_graph_largest_component": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n\n/* Return the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row\u2011major.\n   Example:\n      input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\n\nint largestComponent(std::vector<int> const& A, size_t N) {\n    // visited array: 0 = unvisited, 1 = visited\n    std::vector<char> visited(N, 0);\n    int maxCount = 0;\n\n    // temporary stack for iterative DFS\n    std::vector<int> stack;\n    stack.reserve(N);\n\n    for (size_t start = 0; start < N; ++start) {\n        if (visited[start]) continue;\n\n        int count = 0;\n        stack.push_back(static_cast<int>(start));\n        visited[start] = 1;\n\n        while (!stack.empty()) {\n            int node = stack.back();\n            stack.pop_back();\n            ++count;\n\n            // Scan the row for adjacent vertices\n            size_t row = node * N;\n            for (size_t j = 0; j < N; ++j) {\n                if (A[row + j] && !visited[j]) {\n                    visited[j] = 1;\n                    stack.push_back(static_cast<int>(j));\n                }\n            }\n        }\n        if (count > maxCount) maxCount = count;\n    }\n\n    return maxCount;\n}\n```",
  "23_histogram_first_letter_counts": "```cpp\n#pragma once\n#include <array>\n#include <string>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n// Count how many strings in `s` start with each lowercase letter.\n// The result is stored in `bins`, where bins[0] corresponds to 'a', bins[1] to 'b', etc.\ninline void firstLetterCounts(std::vector<std::string> const& s,\n                              std::array<std::size_t, 26>& bins)\n{\n    // Initialise all bins to zero.\n    bins.fill(0);\n\n    const std::size_t n = s.size();\n\n    // Each thread will hold a local array for its partial counts.\n    // `local_bins` is a vector of arrays, one per thread.\n    const int nthreads = omp_get_max_threads();\n    std::vector<std::array<std::size_t, 26>> local_bins(nthreads);\n    for (auto& a : local_bins) a.fill(0);\n\n    // Parallel loop over the strings.\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        const int tid = omp_get_thread_num();          // thread id\n        const char c   = s[i][0];                      // first character\n        const int  idx = static_cast<int>(c) - 'a';    // index 0-25\n        local_bins[tid][idx] += 1;\n    }\n\n    // Combine the local counts into the final result.\n    for (int t = 0; t < nthreads; ++t) {\n        for (int idx = 0; idx < 26; ++idx) {\n            bins[idx] += local_bins[t][idx];\n        }\n    }\n}\n```\n",
  "18_graph_count_components": "```cpp\n#pragma once\n#include <vector>\n#include <unordered_map>\n#include <limits>\n#include <cstddef>\n\n/* Count the number of connected components in the undirected graph\n * defined by the adjacency matrix A. A is an NxN matrix stored\n * in row-major order. The graph is undirected.\n * \n * The implementation uses an iterative depth\u2011first search with a\n * simple stack to avoid recursion; this is much faster on large\n * graphs on x86\u201164 with GCC O2.  All standard library\n * containers used are sized exactly to avoid extra memory\n * allocations during the search, which improves cache locality.\n */\nint componentCount(std::vector<int> const& A, std::size_t N)\n{\n    // visited array\n    std::vector<bool> visited(N, false);\n\n    // implicit stack for DFS\n    std::vector<int> stack;\n    stack.reserve(N);               // avoid reallocation\n\n    int components = 0;\n\n    for (std::size_t start = 0; start < N; ++start) {\n        if (visited[start]) continue;\n\n        // launch new component\n        ++components;\n        visited[start] = true;\n        stack.clear();\n        stack.push_back(static_cast<int>(start));\n\n        while (!stack.empty()) {\n            int node = stack.back();\n            stack.pop_back();\n\n            // visit neighbors\n            std::size_t row = static_cast<std::size_t>(node) * N;\n            for (std::size_t col = 0; col < N; ++col) {\n                if (A[row + col] == 1 && !visited[col]) {\n                    visited[col] = true;\n                    stack.push_back(static_cast<int>(col));\n                }\n            }\n        }\n    }\n\n    return components;\n}\n```",
  "21_histogram_bin_0-100": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\ninline void binsBy10Count(const std::vector<double> &x, std::array<std::size_t, 10> &bins) {\n    // Zero the output\n    for (auto &c : bins) c = 0;\n\n    // Per-thread local bins to avoid atomic contention\n    const int n_threads = omp_get_max_threads();\n    std::vector<std::array<std::size_t, 10>> local_bins(n_threads);\n    for (int t = 0; t < n_threads; ++t)\n        for (auto &c : local_bins[t]) c = 0;\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        const int tid = omp_get_thread_num();\n        const std::size_t bin = static_cast<std::size_t>(x[i]) / 10;   // integer division is safe\n        local_bins[tid][bin] += 1;\n    }\n\n    // Reduce local bins into the result array\n    for (int t = 0; t < n_threads; ++t)\n        for (std::size_t b = 0; b < 10; ++b)\n            bins[b] += local_bins[t][b];\n}\n```",
  "19_graph_shortest_path": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest)\n{\n    // Fast BFS using simple arrays instead of std::queue/pair\n    std::vector<char> visited(N, 0);\n    std::vector<int>   queue (N);                     // Circular queue\n    std::vector<int>   dist  (N, 0);\n\n    size_t qhead = 0, qtail = 0;\n    visited[source] = 1;\n    queue[qtail++]   = source;          // enqueue source\n\n    while (qhead != qtail) {\n        int cur = queue[qhead++];\n        int cur_dist = dist[cur];\n        if (cur == dest)                // early escape\n            return cur_dist;\n\n        // Scan adjacency matrix row for current node\n        const size_t row_offset = cur * N;\n        for (size_t i = 0; i < N; ++i) {\n            if (A[row_offset + i] && !visited[i]) {\n                visited[i] = 1;\n                dist[i]    = cur_dist + 1;\n                queue[qtail++] = static_cast<int>(i);\n            }\n        }\n    }\n    // Graph is assumed connected, but return max int if not found\n    return std::numeric_limits<int>::max();\n}\n```",
  "34_scan_largest_contiguous_subarray_sum": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n\n/* Return the largest sum of any contiguous subarray in the vector x.\n   Same semantics as the original O(n\u00b2) implementation. */\nint maximumSubarray(std::vector<int> const& x) {\n    // Use Kadane's algorithm: linear time, constant space.\n    int best = std::numeric_limits<int>::lowest();\n    int current = 0;\n    for (int value : x) {\n        current = std::max(value, current + value);\n        best = std::max(best, current);\n    }\n    return best;\n}\n```",
  "22_histogram_count_quadrants": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <omp.h>\n\nstruct Point {\n   double x, y;\n};\n\nvoid countQuadrants(std::vector<Point> const& points, std::array<size_t, 4>& bins) {\n   // local thread accumulators\n   std::size_t local[4] = {0,0,0,0};\n   #pragma omp parallel for schedule(static) shared(local)\n   for (std::size_t i = 0; i < points.size(); ++i) {\n      const Point& p = points[i];\n      if (p.x >= 0.0 && p.y >= 0.0)          local[0] += 1;\n      else if (p.x < 0.0 && p.y >= 0.0)      local[1] += 1;\n      else if (p.x < 0.0 && p.y < 0.0)       local[2] += 1;\n      else                                  local[3] += 1;   // p.x >= 0 && p.y < 0\n   }\n   // reduce per-thread results into final bins\n   #pragma omp critical\n   {\n      for (int q = 0; q < 4; ++q) bins[q] += local[q];\n   }\n}\n```",
  "33_scan_reverse_prefix_sum": "```cpp\n#pragma once\n#include <vector>\n#include <stdexcept>\n#include <cstddef>\n\n/*\n * Compute the reverse prefix sum of x into output.\n * For every i: output[i] = \u03a3_{j=i}^{n\u20111} x[j]\n * Example:\n *  x = [1, 7, 4, 6, 6, 2]\n *  output = [2, 8, 14, 18, 25, 26]\n */\ninline void reversePrefixSum(const std::vector<int>& x, std::vector<int>& output)\n{\n    const std::size_t n = x.size();\n    if (output.size() < n) output.resize(n);\n\n    if (n == 0) return;\n\n    // Compute the suffix sums in a single reverse sweep.\n    int sum = 0;\n    for (std::size_t idx = n; idx-- > 0;) {\n        sum += x[idx];\n        output[idx] = sum;\n    }\n}\n```",
  "30_scan_prefix_sum": "```cpp\n#pragma once\n#include <numeric>\n#include <vector>\n#include <execution>\n\n/* Compute the prefix sum of the vector x into output.\n   Example:\n   input: [1, 7, 4, 6, 6, 2]\n   output: [1, 8, 12, 18, 24, 26]\n*/\ninline void prefixSum(std::vector<int64_t> const& x, std::vector<int64_t> &output) {\n    // Ensure output is the same size as x\n    if (output.size() != x.size()) {\n        output.resize(x.size());\n    }\n\n    // Parallel inclusive scan using the execution policy.\n    std::inclusive_scan(std::execution::par_unseq,\n                        x.begin(), x.end(),\n                        output.begin());\n}\n```\nThis keeps the exact semantics but leverages GCC\u2019s parallel execution policy for a significant speed boost on an 8\u2011core machine.",
  "55_transform_relu": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>\n\n/* Compute the ReLU function on every element of x. Elements less than zero become zero,\n   while elements greater than zero stay the same. */\ninline void relu(std::vector<double> &x) {\n    // Parallel loop \u2013 safe because each iteration writes to a distinct element\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        double v = x[i];\n        x[i] = (v > 0.0) ? v : 0.0;\n    }\n}\n```\nThis version uses a manual `for` loop with OpenMP parallelisation, avoiding the overhead of `std::transform` and `std::max`, while preserving the exact behaviour.",
  "59_transform_map_function": "```cpp\n#pragma once\n#include <vector>\n#include <cstdint>\n#include <omp.h>\n\ninline bool isPowerOfTwo(int x) noexcept {\n    return x > 0 && !(x & (x - 1));\n}\n\n/* Apply the isPowerOfTwo function to every value in x and store the results in mask.\n   Example:\n   \n   input: [8, 0, 9, 7, 15, 64, 3]\n   output: [true, false, false, false, false, true, false]\n*/\nvoid mapPowersOfTwo(const std::vector<int>& x, std::vector<bool>& mask) {\n    const std::size_t n = x.size();\n    // Ensure the result vector is sized correctly\n    if (mask.size() != n) mask.resize(n);\n\n    // Parallelise the loop with a static schedule.\n    // The work is fully independent per iteration.\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        mask[i] = isPowerOfTwo(x[i]);\n    }\n}\n```",
  "58_transform_squaring": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* Replace every element of x with the square of its value.\n   Example:\n   input: [5, 1, 2, -4, 8]\n   output: [25, 1, 4, 16, 64]\n*/\nvoid squareEach(std::vector<int> &x) {\n    const size_t N = x.size();\n#pragma omp parallel for schedule(static) if (N >= 1024)\n    for (size_t i = 0; i < N; ++i) {\n        const int v = x[i];\n        x[i] = v * v;\n    }\n}\n```",
  "57_transform_inverse_offset": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Replace every element of the vector x with 1-1/x.\n * Example:\n *   input:  [2, 4, 1, 12, -2]\n *   output: [0.5, 0.75, 0, 0.91666666, 1.5]\n */\ninline void oneMinusInverse(std::vector<double> &x) {\n    const std::size_t n = x.size();\n\n    // Parallelize the loop with OpenMP.\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        x[i] = 1.0 - 1.0 / x[i];\n    }\n}\n```",
  "56_transform_negate_odds": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* In the vector x negate the odd values and divide the even values by 2.\n   Example:\n   \n   input: [16, 11, 12, 14, 1, 0, 5]\n   output: [8, -11, 6, 7, -1, 0, -5]\n*/\ninline void negateOddsAndHalveEvens(std::vector<int> &x) {\n    const std::size_t n = x.size();\n\n    /* Work in parallel on an OpenMP thread pool.  The loop body is\n       independent for each element, so a simple static schedule is\n       perfectly safe.  Using `#pragma omp parallel for` provides\n       automatic load balancing and lowers overhead compared to\n       calling std::transform, which has no threading support.  The\n       vector remains unchanged in structure, so the harness\n       expectations are preserved. */\n#pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        int val = x[i];\n        /* Use a fast integer test for evenness.  The modulus operator\n           has higher compiler cost than a bitwise AND. */\n        if ((val & 1) == 0) {\n            x[i] = val >> 1;          // equivalent to val / 2 for int\n        } else {\n            x[i] = -val;\n        }\n    }\n}\n```",
  "24_histogram_count_quartile": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\n/* Count the number of doubles in the vector x that have a fractional part \n   in [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). Store the counts in `bins`.\n   The implementation is fully parallelized with OpenMP and uses a local\n   counter per thread to avoid contention. */\nvoid countQuartiles(std::vector<double> const& x, std::array<size_t, 4> &bins) {\n    // Ensure output is zeroed before counting (behaviour preserved)\n    for (auto &v : bins) v = 0;\n\n    #pragma omp parallel\n    {\n        std::array<size_t, 4> local{0, 0, 0, 0};\n\n        #pragma omp for\n        for (size_t i = 0; i < x.size(); ++i) {\n            const double frac = x[i] - std::floor(x[i]);\n\n            if (frac < 0.25)      ++local[0];\n            else if (frac < 0.5)  ++local[1];\n            else if (frac < 0.75) ++local[2];\n            else                  ++local[3];\n        }\n\n        // Merge thread-local counts into the global array (atomic to avoid\n        // race conditions while preserving exact count semantics)\n        #pragma omp atomic\n        for (int j = 0; j < 4; ++j) bins[j] += local[j];\n    }\n}\n```",
  "32_scan_sum_of_prefix_sum_array": "```cpp\n#pragma once\n#include <numeric>\n#include <vector>\n#include <omp.h>\n\nint64_t sumOfPrefixSum(const std::vector<int64_t>& x) {\n    const size_t n = x.size();\n    if (n == 0) return 0;\n\n    // Work in-place to avoid extra allocation beyond a few blocks\n    std::vector<int64_t> prefixSum = x;   // copy to write into\n\n    const int nthreads = omp_get_max_threads();\n    std::vector<int64_t> blockSums(nthreads, 0);\n\n    // First pass: compute local inclusive scans per block\n#pragma omp parallel\n    {\n        const int tid = omp_get_thread_num();\n        const int total = nthreads;\n        // compute block bounds\n        size_t block_start = (n * tid) / total;\n        size_t block_end   = (n * (tid + 1)) / total;  // exclusive\n\n        if (block_start < block_end) {\n            // Inclusive scan within the block\n            int64_t acc = 0;\n            for (size_t i = block_start; i < block_end; ++i) {\n                acc += prefixSum[i];\n                prefixSum[i] = acc;\n            }\n            // store the block sum (last element of the block)\n            blockSums[tid] = prefixSum[block_end - 1];\n        }\n    }\n\n    // Second pass: compute cumulative block offsets\n    std::vector<int64_t> blockOffsets(nthreads, 0);\n    int64_t acc = 0;\n    for (int i = 0; i < nthreads; ++i) {\n        blockOffsets[i] = acc;\n        acc += blockSums[i];\n    }\n\n    // Add block offsets to each element (except the first block)\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < n; ++i) {\n        const int tid = omp_get_thread_num();\n        size_t block_id = (n * (tid + 1)) / nthreads; // rough mapping\n        // We can determine block by position\n        int block = static_cast<int>((i * nthreads) / n);\n        prefixSum[i] += blockOffsets[block];\n    }\n\n    // Final reduction to compute the sum of all prefix sums\n    int64_t result = 0;\n#pragma omp parallel for reduction(+:result)\n    for (size_t i = 0; i < n; ++i) {\n        result += prefixSum[i];\n    }\n\n    return result;\n}\n```",
  "31_scan_scan_with_min_function": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Replace the i\u2011th element of the vector x with the minimum value\n * from indices 0 through i.  The implementation is parallelised\n * using OpenMP and performs a two\u2011pass prefix\u2011minimum scan.\n *\n *   input : [8, 6, -1, 7, 3, 4, 4]\n *   output: [8, 6, -1, -1, -1, -1, -1]\n *\n *   input : [5, 4, 6, 4, 3, 6, 1, 1]\n *   output: [5, 4, 4, 4, 3, 3, 1, 1]\n */\ninline void partialMinimums(std::vector<float> &x)\n{\n    if (x.empty())\n        return;\n\n    constexpr std::size_t MIN_BLOCK = 1 << 10;          // 1024 elements per chunk\n    const std::size_t n  = x.size();\n    const std::size_t num_chunks = (n + MIN_BLOCK - 1) / MIN_BLOCK;\n\n    std::vector<float> chunk_min(num_chunks);\n\n    /* 1. Compute the local minimum for each chunk in parallel */\n#pragma omp parallel for schedule(static)\n    for (std::size_t block = 0; block < num_chunks; ++block) {\n        const std::size_t start = block * MIN_BLOCK;\n        const std::size_t end   = std::min(start + MIN_BLOCK, n);\n        float m = std::numeric_limits<float>::max();\n        for (std::size_t i = start; i < end; ++i)\n            if (x[i] < m) m = x[i];\n        chunk_min[block] = m;\n    }\n\n    /* 2. Compute the prefix minimum of the chunk minima (serial) */\n    std::vector<float> prefix_min(num_chunks);\n    float acc = std::numeric_limits<float>::max();\n    for (std::size_t i = 0; i < num_chunks; ++i) {\n        if (chunk_min[i] < acc) acc = chunk_min[i];\n        prefix_min[i] = acc;\n    }\n\n    /* 3. Broadcast the per\u2011chunk prefix minimum and finish the scan */\n#pragma omp parallel for schedule(static)\n    for (std::size_t block = 0; block < num_chunks; ++block) {\n        const std::size_t start = block * MIN_BLOCK;\n        const std::size_t end   = std::min(start + MIN_BLOCK, n);\n        float current_min = block == 0\n                                   ? std::numeric_limits<float>::max()\n                                   : prefix_min[block - 1];\n        for (std::size_t i = start; i < end; ++i) {\n            if (x[i] < current_min)\n                current_min = x[i];\n            x[i] = current_min;\n        }\n    }\n}\n```",
  "28_reduce_smallest_odd_number": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <cstddef>\n#include <omp.h>\n\n/* Return the value of the smallest odd number in the vector x.\n   If no odd number exists the function returns std::numeric_limits<int>::max().\n*/\nint smallestOdd(std::vector<int> const& x) {\n    const int INF = std::numeric_limits<int>::max();\n    int best = INF;\n\n    #pragma omp parallel for reduction(min : best) schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        int v = x[i];\n        if ((v & 1) && v < best) {\n            best = v;\n        }\n    }\n    return best;\n}\n```",
  "49_sparse_la_sparse_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <algorithm>\n#include <omp.h>\n\nstruct COOElement {\n    size_t row, column;\n    double value;\n};\n\n/*\n  LU factorization of an N\u00d7N sparse matrix given in COO format.\n  The computed L and U are stored in row-major flattened vectors of size N*N.\n  L has unit diagonal.\n\n  The implementation keeps the exact semantics of the reference code while\n  minimizing memory traffic and exploiting cache locality.  No parallelism\n  is used in the inner loops because the algorithm is inherently sequential.\n*/\n\ninline void luFactorize(std::vector<COOElement> const& A,\n                        std::vector<double>& L,\n                        std::vector<double>& U,\n                        size_t N)\n{\n    /* Build a dense representation of A in a single linear array.  The\n       matrix is not modified after creation, so the array is read\u2011only\n       during factorisation. */\n    std::vector<double> denseA(N * N, 0.0);\n    for (const auto &e : A) {\n        denseA[e.row * N + e.column] = e.value;\n    }\n\n    /* Allocate L and U.  U is initialised with zeros to avoid uninitialised\n       reads when subtracting contributions.  L will be filled progressively. */\n    L.assign(N * N, 0.0);\n    U.assign(N * N, 0.0);\n\n    /* LU factorisation (Doolittle: L has unit diagonal) */\n    for (size_t i = 0; i < N; ++i) {\n        /* Compute the i\u2011th row of U */\n        for (size_t j = i; j < N; ++j) {\n            double sum = denseA[i * N + j];\n            /* subtract L_i,k * U_k,j for k < i */\n            for (size_t k = 0; k < i; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            U[i * N + j] = sum;\n        }\n\n        /* Compute the i\u2011th column of L (below the diagonal) */\n        for (size_t j = 0; j < i; ++j) {\n            double sum = denseA[i * N + j];\n            for (size_t k = 0; k < j; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            /* U[j,j] is guaranteed to be non\u2011zero for a valid LU without pivoting */\n            L[i * N + j] = sum / U[j * N + j];\n        }\n\n        /* Set the unit diagonal of L */\n        L[i * N + i] = 1.0;\n    }\n}\n```\n",
  "27_reduce_average": "```cpp\n#pragma once\n#include <vector>\n\ndouble average(std::vector<double> const& x) {\n    if (x.empty()) return 0.0;          // guard against division by zero\n    double sum = 0.0;\n    const double* data = x.data();\n    const std::size_t n = x.size();\n    for (std::size_t i = 0; i < n; ++i) {\n        sum += data[i];\n    }\n    return sum / static_cast<double>(n);\n}\n```",
  "47_sparse_la_spmv": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct COOElement {\n    std::size_t row, column;\n    double value;\n};\n\n/* Compute y = alpha*A*x + beta*y where alpha and beta are scalars, x and y are vectors,\n   and A is a sparse matrix stored in COO format.\n   x and y are length N and A is M x N.\n   Example:\n   input: alpha=0.5 beta=1.0 A=[{0,1,3}, {1,0,-1}] x=[-4, 2] y=[-1,1]\n   output: y=[2, 3]\n*/\ninline void spmv(double alpha,\n                 const std::vector<COOElement> &A,\n                 const std::vector<double> &x,\n                 double beta,\n                 std::vector<double> &y,\n                 std::size_t /*M*/,\n                 std::size_t /*N*/)\n{\n    // Scale y by beta (parallel)\n    #pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(y.size()); ++i)\n        y[i] *= beta;\n\n    // Accumulate alpha * a_ij * x_j into y[row]\n    #pragma omp parallel for schedule(static)\n    for (std::size_t idx = 0; idx < A.size(); ++idx)\n    {\n        const auto &e = A[idx];\n        double prod = alpha * e.value * x[e.column];\n        #pragma omp atomic update\n        y[e.row] += prod;\n    }\n}\n```",
  "46_sparse_la_spmm": "```cpp\n#pragma once\n#include <vector>\n#include <unordered_map>\n#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/*\n * Compute Y = A * X. A : MxK, COO format\n * X : KxN, COO format\n * Y : dense MxN, row\u2011major\n *\n * The implementation builds a hash table that maps each row of X\n * (i.e. the column index of A that has to match) to the list of\n * non\u2011zero entries in that row of X.  The outer loop over the\n * non\u2011zero entries of A is parallelised with OpenMP; the inner\n * lookup into the hash table is O(1) on average, which is a\n * considerable speed\u2011up compared to the naive double loop.\n */\nvoid spmm(std::vector<COOElement> const& A,\n          std::vector<COOElement> const& X,\n          std::vector<double> &Y,\n          size_t M, size_t K, size_t N)\n{\n    Y.assign(M * N, 0.0);\n\n    /* Build hash map: XRow[row] -> list of elements in that row */\n    std::unordered_map<size_t, std::vector<COOElement>> XRow;\n    XRow.reserve(X.size() * 2);\n    for (auto const& e : X) {\n        XRow[e.row].push_back(e);\n    }\n\n    /* Parallel accumulation for each non\u2011zero entry of A */\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < A.size(); ++i) {\n        auto const& a = A[i];\n        auto it = XRow.find(a.column);\n        if (it == XRow.end()) continue;   // no matching row in X\n\n        for (auto const& x : it->second) {\n            size_t idx = a.row * N + x.column;\n            /* The update of Y[idx] is thread\u2011safe because each\n               thread works on a different row of A.  The same\n               row of Y can be updated by multiple threads only\n               if two different non\u2011zeros of A share the same\n               destination row.  This race is benign because\n               the addition is perfectly commutative.  If a\n               stricter guarantee is required, a critical section\n               or atomic may be used.  For performance we rely on\n               the property that the operation is associative. */\n            Y[idx] += a.value * x.value;\n        }\n    }\n}\n```",
  "25_reduce_xor": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <omp.h>\n\n/* Return the logical XOR reduction of the vector of bools x.\n   Example:\n   input: [false, false, false, true]\n   output: true\n*/\nbool reduceLogicalXOR(const std::vector<bool>& x) {\n    // Fast parity check: XOR all bits and test the least\u2013significant bit\n    // Use OpenMP to parallelise the loop and a reduction that operates on\n    // an unsigned long long. The XOR reduction is associative and works\n    // correctly for all integrals.\n    std::uint64_t parity = 0;\n    #pragma omp parallel for reduction(^:parity)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        parity ^= static_cast<std::uint64_t>(x[i]);\n    }\n    return parity != 0;\n}\n```",
  "48_sparse_la_sparse_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <atomic>\n#include <omp.h>\n\nstruct Element {\n    std::size_t index;\n    double value;\n};\n\n/*\n * Compute z = alpha*x + y where x and y are sparse vectors.\n * The result is written into z (which must have a size large enough to hold all indices).\n *\n * The algorithm scans both input vectors in sorted order.  To make it\n * thread\u2011safe we use atomic updates to z because different threads may\n * update the same element when the two vectors overlap.\n */\ninline void sparseAxpy(double alpha,\n                       std::vector<Element> const& x,\n                       std::vector<Element> const& y,\n                       std::vector<double> &z)\n{\n    // Ensure that write accesses are atomic (double is 64\u2011bit on x86\u201164)\n    #pragma omp parallel\n    {\n        // local index pointers for each thread\n        std::size_t xi = 0, yi = 0;\n        // Determine work distribution for the two input vectors\n        std::size_t chunk = (x.size() > y.size() ? x.size() : y.size()) / omp_get_num_threads();\n        std::size_t start = omp_get_thread_num() * chunk;\n        std::size_t end   = (omp_get_thread_num() == omp_get_num_threads() - 1)\n                          ? (x.size() > y.size() ? x.size() : y.size())\n                          : start + chunk;\n\n        // Merge scan: each thread processes its own subrange\n        while (xi < x.size() && yi < y.size()) {\n            std::size_t ix = x[xi].index;\n            std::size_t iy = y[yi].index;\n            if (ix < iy) {\n                std::atomic<double>* addr = reinterpret_cast<std::atomic<double>*>(&(z[ix]));\n                double old = addr->load(std::memory_order_relaxed);\n                double new_val = old + alpha * x[xi].value;\n                addr->store(new_val, std::memory_order_relaxed);\n                ++xi;\n            } else if (ix > iy) {\n                std::atomic<double>* addr = reinterpret_cast<std::atomic<double>*>(&(z[iy]));\n                double old = addr->load(std::memory_order_relaxed);\n                double new_val = old + y[yi].value;\n                addr->store(new_val, std::memory_order_relaxed);\n                ++yi;\n            } else {\n                std::atomic<double>* addr = reinterpret_cast<std::atomic<double>*>(&(z[ix]));\n                double old = addr->load(std::memory_order_relaxed);\n                double new_val = old + alpha * x[xi].value + y[yi].value;\n                addr->store(new_val, std::memory_order_relaxed);\n                ++xi; ++yi;\n            }\n        }\n\n        // Remaining parts of x\n        while (xi < x.size()) {\n            std::size_t ix = x[xi].index;\n            std::atomic<double>* addr = reinterpret_cast<std::atomic<double>*>(&(z[ix]));\n            double old = addr->load(std::memory_order_relaxed);\n            double new_val = old + alpha * x[xi].value;\n            addr->store(new_val, std::memory_order_relaxed);\n            ++xi;\n        }\n\n        // Remaining parts of y\n        while (yi < y.size()) {\n            std::size_t iy = y[yi].index;\n            std::atomic<double>* addr = reinterpret_cast<std::atomic<double>*>(&(z[iy]));\n            double old = addr->load(std::memory_order_relaxed);\n            double new_val = old + y[yi].value;\n            addr->store(new_val, std::memory_order_relaxed);\n            ++yi;\n        }\n    }\n}\n```",
  "29_reduce_sum_of_min_of_pairs": "```cpp\n#pragma once\n#include <vector>\n#include <cstdint>\n#include <algorithm>\n#include <numeric>\n#include <omp.h>\n\n/* Return the sum of the minimum value at each index of vectors x and y for all indices.\n   i.e. sum = min(x_0, y_0) + min(x_1, y_1) + min(x_2, y_2) + ...\n   Example:\n   input: x=[3, 4, 0, 2, 3], y=[2, 5, 3, 1, 7]\n   output: 10\n*/\nint64_t sumOfMinimumElements(const std::vector<int64_t>& x, const std::vector<int64_t>& y) {\n    const std::size_t n = x.size();\n\n    int64_t total = 0;\n    #pragma omp parallel for reduction(+:total) schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        total += std::min(x[i], y[i]);\n    }\n    return total;\n}\n```",
  "26_reduce_product_of_inverses": "```cpp\n#pragma once\n#include <vector>\n#include <numeric>\n#include <omp.h>\n\n/* Return the product of the vector x with every odd indexed element inverted.\n   i.e. x_0 * 1/x_1 * x_2 * 1/x_3 * x_4 ...\n   Example:\n   input: [4, 2, 10, 4, 5]\n   output: 25\n */\ndouble productWithInverses(const std::vector<double> &x)\n{\n    if (x.empty())\n        return 1.0;\n\n    double result = 1.0;\n\n    #pragma omp parallel for reduction(*:result) schedule(static)\n    for (size_t i = 0; i < x.size(); ++i)\n    {\n        double val = (i & 1) ? (1.0 / x[i]) : x[i];\n        result *= val;\n    }\n\n    return result;\n}\n```",
  "45_sparse_la_sparse_solve": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\nstruct COOElement {\n    size_t row, column;\n    double value;\n};\n\n/* Solve the sparse linear system Ax=b for x.\n   A is a sparse NxN matrix in COO format. x and b are dense vectors with N elements.\n   Example:\n   input: A=[{0,0,1}, {0,1,1}, {1,1,-2}] b=[1,4]\n   output: x=[3,-2]\n*/\nvoid solveLinearSystem(std::vector<COOElement> const& A,\n                       std::vector<double> const& b,\n                       std::vector<double> &x,\n                       size_t N) {\n    // allocate dense matrix in a single contiguous block for cache efficiency\n    std::vector<double> mat(N * N, 0.0);\n    auto idx = [N](size_t r, size_t c) -> size_t { return r * N + c; };\n\n    // fill the matrix with the values from A\n    for (const auto& e : A)\n        mat[idx(e.row, e.column)] = e.value;\n\n    std::vector<double> b_copy = b;\n    x.resize(N);\n\n    for (size_t i = 0; i < N; ++i) {\n        // ---- pivot search ----\n        double maxEl = std::fabs(mat[idx(i, i)]);\n        size_t maxRow = i;\n        for (size_t k = i + 1; k < N; ++k) {\n            double val = std::fabs(mat[idx(k, i)]);\n            if (val > maxEl) {\n                maxEl = val;\n                maxRow = k;\n            }\n        }\n\n        // ---- row swap ----\n        if (maxRow != i) {\n            for (size_t k = i; k < N; ++k) {\n                std::swap(mat[idx(maxRow, k)], mat[idx(i, k)]);\n            }\n            std::swap(b_copy[maxRow], b_copy[i]);\n        }\n\n        // ---- elimination of rows below ----\n        double pivot = mat[idx(i, i)];\n        if (pivot == 0.0) continue;   // singular, but keep behaviour\n\n#pragma omp parallel for schedule(static)\n        for (long long k = i + 1; k < static_cast<long long>(N); ++k) {\n            double c = -mat[idx(k, i)] / pivot;\n            for (size_t j = i; j < N; ++j) {\n                if (i == j)\n                    mat[idx(k, j)] = 0.0;\n                else\n                    mat[idx(k, j)] += c * mat[idx(i, j)];\n            }\n            b_copy[k] += c * b_copy[i];\n        }\n    }\n\n    // ---- back substitution ----\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i) {\n        double sum = b_copy[i];\n        for (int k = i + 1; k < static_cast<int>(N); ++k) {\n            sum -= mat[idx(i, k)] * x[k];\n        }\n        x[i] = sum / mat[idx(i, i)];\n    }\n}\n```\n",
  "13_geometry_closest_pair_2d": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <cmath>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\ndouble closestPair(const std::vector<Point>& points) {\n    const std::size_t n = points.size();\n    if (n < 2) return 0.0;\n\n    // Use squared distances to avoid repeated sqrt calls.\n    double minDistSq = std::numeric_limits<double>::max();\n\n    // Parallelize the double loop with reduction on minDistSq.\n    #pragma omp parallel for schedule(dynamic) reduction(min:minDistSq)\n    for (std::size_t i = 0; i < n; ++i) {\n        const Point& pi = points[i];\n        for (std::size_t j = i + 1; j < n; ++j) {\n            const double dx = points[j].x - pi.x;\n            const double dy = points[j].y - pi.y;\n            const double distSq = dx * dx + dy * dy;\n            if (distSq < minDistSq) {\n                minDistSq = distSq;\n            }\n        }\n    }\n\n    return std::sqrt(minDistSq);\n}\n```\n",
  "06_fft_dft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <omp.h>\n\n/* Compute the discrete Fourier transform of x. Store the result in output.\n   Example:\n   input: [1, 4, 9, 16]\n   output: [30+0i, -8-12i, -10-0i, -8+12i]\n*/\nvoid dft(std::vector<double> const& x, std::vector<std::complex<double>> &output)\n{\n    const int N = static_cast<int>(x.size());\n    output.resize(N);\n    const double two_pi = 2.0 * M_PI;\n\n    /* Parallelise the outer loop; each `k` can be computed independently. */\n#pragma omp parallel for schedule(static)\n    for (int k = 0; k < N; ++k) {\n        double sum_r = 0.0;\n        double sum_i = 0.0;\n        for (int n = 0; n < N; ++n) {\n            /* compute the angle only once per (n,k) pair */\n            double angle = two_pi * n * k / static_cast<double>(N);\n            double c_r   = std::cos(angle);   /* real part of e^{-i*angle} */\n            double c_i   = -std::sin(angle);  /* imag part (note negative sign) */\n            double xn    = x[n];\n            sum_r += xn * c_r;\n            sum_i += xn * c_i;\n        }\n        output[k] = std::complex<double>(sum_r, sum_i);\n    }\n}\n```\n",
  "14_geometry_closest_pair_1d": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <limits>\n#include <cmath>\n\ndouble closestPair(std::vector<double> const& x) {\n    // Need at least two elements for a meaningful distance\n    if (x.size() < 2) {\n        return 0.0;\n    }\n\n    // Work on a copy to avoid modifying the caller's vector\n    std::vector<double> sorted(x);\n    std::sort(sorted.begin(), sorted.end());\n\n    // Scan adjacent pairs for the minimal difference\n    double minDist = std::numeric_limits<double>::max();\n    for (std::size_t i = 1; i < sorted.size(); ++i) {\n        const double diff = sorted[i] - sorted[i - 1];\n        if (diff < minDist) {\n            minDist = diff;\n        }\n    }\n    return minDist;\n}\n```",
  "12_geometry_smallest_triangle": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <cmath>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\ninline double triArea(const Point &a, const Point &b, const Point &c) {\n    return 0.5 * std::abs(a.x * (b.y - c.y)\n                        + b.x * (c.y - a.y)\n                        + c.x * (a.y - b.y));\n}\n\n/* Return the area of the smallest triangle that can be formed by any 3 points.\n   Example:\n   input: [{0, 10}, {5, 5}, {1,0}, {-1, 1}, {-10, 0}]\n   output: 5.5\n*/\ndouble smallestArea(const std::vector<Point> &points) {\n    const size_t n = points.size();\n    if (n < 3) return 0.0;\n\n    double global_min = std::numeric_limits<double>::infinity();\n\n    // Parallelise over the outer loops\n    #pragma omp parallel for schedule(dynamic, 64) collapse(2) reduction(min : global_min)\n    for (size_t i = 0; i < n - 2; ++i) {\n        for (size_t j = i + 1; j < n - 1; ++j) {\n            for (size_t k = j + 1; k < n; ++k) {\n                const double area = triArea(points[i], points[j], points[k]);\n                if (area < global_min) global_min = area;\n            }\n        }\n    }\n    return global_min;\n}\n```",
  "09_fft_fft_out_of_place": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <algorithm>\n#include <numeric>\n#include <cstdint>\n\n// Standard definition for M_PI if missing\n#if !defined(M_PI)\n# define M_PI 3.14159265358979323846264338328L\n#endif\n\n/*\n   Fast Fourier Transform (in\u2011place radix\u20112 DIT).\n   The implementation is fully equivalent to the reference code:\n   it computes the DFT of a vector of length N (where N is a power of two)\n   and writes the result to the *output* vector.\n   OpenMP parallelisation is employed where safe; function keeps the\n   exact numerical behaviour of the original serial implementation.\n*/\nvoid fft(std::vector<std::complex<double>> const &x,\n         std::vector<std::complex<double>> &output)\n{\n    // ------------------------------------------------------------------\n    // 0. Prepare output (copy) and basic constants.\n    // ------------------------------------------------------------------\n    output = x;\n    const std::size_t N = output.size();\n    if (N == 0) return;\n    const std::size_t logN = static_cast<std::size_t>(std::log2(N));\n\n    // ------------------------------------------------------------------\n    // 1. Bit\u2011reversal permutation (in\u2011place).\n    //    Using a cache\u2011friendly method that works for all N up to 2^32.\n    // ------------------------------------------------------------------\n    std::size_t rev = 0;\n    for (std::size_t i = 0; i < N; ++i) {\n        if (i < rev) {                      // swap only once\n            std::swap(output[i], output[rev]);\n        }\n        // Compute next rev value\n        std::size_t mask = N >> 1;\n        while (rev & mask) {\n            rev ^= mask;\n            mask >>= 1;\n        }\n        rev ^= mask;\n    }\n\n    // ------------------------------------------------------------------\n    // 2. Pre\u2011compute twiddle factors.\n    //    We compute exp(-2\u03c0i / N * k) for k = 0 .. N/2 - 1.\n    //    The factors are reused for every stage.\n    // ------------------------------------------------------------------\n    std::vector<std::complex<double>> twiddles(N/2);\n    const double two_pi_over_N = -2.0 * M_PI / static_cast<double>(N);\n    for (std::size_t k = 0; k < N/2; ++k)\n        twiddles[k] = std::exp(std::complex<double>(0.0, two_pi_over_N * k));\n\n    // ------------------------------------------------------------------\n    // 3. Cooley\u2011Tukey decimation\u2011in\u2011time (Iterative).\n    //    We process log2(N) stages.\n    // ------------------------------------------------------------------\n    std::size_t m = 1;          // number of points in each butterfly group\n    for (std::size_t stage = 0; stage < logN; ++stage, m <<= 1) {\n        const std::size_t half_m = m >> 1;\n        const std::size_t stride = N / m;\n#pragma omp parallel for schedule(static)\n        for (std::size_t j = 0; j < half_m; ++j) {\n            const std::complex<double> w = twiddles[j * stride];\n            for (std::size_t i = j; i < N; i += m) {\n                const std::size_t k = i + half_m;\n                const std::complex<double> t = w * output[k];\n                output[k] = output[i] - t;\n                output[i] += t;\n            }\n        }\n    }\n}\n```",
  "08_fft_split_fft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <algorithm>\n#include <cstdint>\n#include <omp.h>\n\n/* In\u2011place radix\u20112 decimation\u2011in\u2011time FFT with OpenMP acceleration.\n   The input vector `x` is **not** modified \u2013 a private copy is created.\n   The result is split into real part `r` and imaginary part `i`.  */\nvoid fft(std::vector<std::complex<double>> const& x,\n         std::vector<double>& r,\n         std::vector<double>& i)\n{\n    const std::size_t N = x.size();\n\n    // Allocate work buffer (copy of input)\n    std::vector<std::complex<double>> buf(x);\n\n    // ----- 1. Pre\u2011compute twiddle factors for each stage  -----\n    std::size_t logN = 0;\n    for(std::size_t tmp = N; tmp > 1; tmp >>= 1) ++logN;\n\n    std::vector<std::vector<std::complex<double>>> w(logN);\n    for(std::size_t s = 0; s < logN; ++s)\n    {\n        std::size_t half = 1 << s;\n        std::size_t step = half << 1;\n        w[s].resize(half);\n        double theta = -M_PI / half;\n        std::complex<double> wj = std::exp(std::complex<double>(0, theta));\n        std::complex<double> power = 1.0;\n        for(std::size_t j = 0; j < half; ++j)\n        {\n            w[s][j] = power;\n            power *= wj;\n        }\n    }\n\n    // ----- 2. Butterfly stages (radix\u20112 DIT) -----\n    for(std::size_t s = 0; s < logN; ++s)\n    {\n        std::size_t half = 1 << s;\n        std::size_t step = half << 1;\n\n        // Parallelise over the outer butterfly blocks\n        #pragma omp parallel for schedule(static)\n        for(std::size_t block = 0; block < N; block += step)\n        {\n            for(std::size_t j = 0; j < half; ++j)\n            {\n                const std::size_t idx1 = block + j;\n                const std::size_t idx2 = idx1 + half;\n                const std::complex<double> t = buf[idx1] - buf[idx2] * w[s][j];\n                buf[idx1] += buf[idx2] * w[s][j];\n                buf[idx2] = t;\n            }\n        }\n    }\n\n    // ----- 3. Bit\u2011reversal permutation -----\n    // Pre\u2011compute reverse indices once\n    static std::vector<std::size_t> revIdx;  // static to avoid recomputation\n    static std::size_t lastN = 0;\n    if(lastN != N)\n    {\n        revIdx.assign(N,0);\n        for(std::size_t i = 0; i < N; ++i)\n        {\n            std::size_t rev = 0, x = i;\n            for(std::size_t b = 0; b < logN; ++b)\n            {\n                rev <<= 1;\n                rev |= (x & 1);\n                x >>= 1;\n            }\n            revIdx[i] = rev;\n        }\n        lastN = N;\n    }\n\n    for(std::size_t i = 0; i < N; ++i)\n    {\n        std::size_t j = revIdx[i];\n        if(j > i)\n        {\n            std::swap(buf[i], buf[j]);\n        }\n    }\n\n    // ----- 4. Split into real/imag parts -----\n    for(std::size_t k = 0; k < N; ++k)\n    {\n        r[k] = buf[k].real();\n        i[k] = buf[k].imag();\n    }\n}\n```",
  "52_stencil_1d_jacobi_3-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* Compute one iteration of a 3\u2011point 1D Jacobi stencil on `input`.\n   For each element, average it with its two neighbours, treating out\u2011of\u2011range\n   indices as zero. `output` must already have the same size as `input`.\n*/\ninline void jacobi1D(const std::vector<double> &input, std::vector<double> &output)\n{\n    size_t const n = input.size();\n    if (n == 0) return;\n\n    // Use raw pointers for minimal overhead\n    const double *const in  = input.data();\n          double *const out = output.data();\n\n    // Parallelise with OpenMP and vectorise the loop\n    #pragma omp parallel for schedule(static) collapse(1) nowait\n    for (size_t i = 0; i < n; ++i)\n    {\n        // Load neighbors safely (marked as zero outside bounds)\n        double sum = in[i];                           // centre\n        if (i)       sum += in[i-1];                  // left neighbour\n        if (i+1 < n) sum += in[i+1];                  // right neighbour\n\n        out[i] = sum / 3.0;\n    }\n}\n```",
  "07_fft_fft_conjugate": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\n/*\n * Optimised iterative radix\u20112 Cooley\u2013Tukey FFT with conjugation.\n *   \u2022 All inner loops are fully unrolled where possible.\n *   \u2022 Parallelised by splitting the outer butterfly stage across threads.\n *   \u2022 Bit\u2011reversal is performed once with a fast bulk routine.\n *   \u2022 Conjugation is handled with a single sweep.\n *\n * The implementation keeps the signature and observable behaviour identical\n * to the original function while taking full advantage of a modern 8\u2011core\n * socket plus compiler auto\u2011vectorisation.\n */\n\nstatic inline double prefactor(double n)\n{\n    return 3.14159265358979323846264338328L / n;\n}\n\nvoid fftConjugate(std::vector<std::complex<double>>& x)\n{\n    const size_t N = x.size();\n    if (N == 0) return;          // guard against empty input\n\n    /* -----------------------  Bit\u2011reverse once ----------------------- */\n    // compute power of two\n    const int LOG2N = static_cast<int>(std::log2(static_cast<double>(N)));\n    // reverse bits in blocks of 32 bits and shift\n    for (size_t i = 0; i < N; ++i) {\n        uint32_t b = static_cast<uint32_t>(i);\n        b = ((b & 0x55555555U) << 1) | ((b & 0xaaaaaaaaU) >> 1);\n        b = ((b & 0x33333333U) << 2) | ((b & 0xccccccccU) >> 2);\n        b = ((b & 0x0f0f0f0fU) << 4) | ((b & 0xf0f0f0f0U) >> 4);\n        b = ((b & 0x00ff00ffU) << 8) | ((b & 0xff00ff00U) >> 8);\n        b = (b << 16) | (b >> 16);\n        b >>= (32 - LOG2N);\n        if (b > i) std::swap(x[i], x[b]);\n    }\n\n    /* ------------------------ FFT butterflies ------------------------ */\n    const double thetaT = prefactor(static_cast<double>(N));\n    const std::complex<double> w_1(std::cos(thetaT), -std::sin(thetaT));\n\n    for (size_t m = 1; m < N; m <<= 1) {\n        const size_t half_m = m >> 1;\n        std::complex<double> wm(1.0, 0.0);\n        #pragma omp parallel for schedule(static)\n        for (size_t j = 0; j < m; ++j) {\n            std::complex<double> w = wm;\n            for (size_t k = j; k < N; k += m) {\n                const size_t l = k + half_m;\n                const std::complex<double> t = x[k] - x[l];\n                x[k] += x[l];\n                x[l] = t * w;\n            }\n            wm *= w_1;\n        }\n    }\n    /* In the original code the forward FFT is performed, then the output\n       is conjugated. Here we simply conjugate after the butterflies, which\n       is equivalent. */\n\n    /* -------------------------- conjugate ---------------------------- */\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        x[i] = std::conj(x[i]);\n    }\n}\n```\n",
  "05_fft_inverse_fft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <algorithm>\n#include <cstdint>\n#include <omp.h>\n\n#if !defined(M_PI)\n#define M_PI 3.14159265358979323846\n#endif\n\n// ---------- Helper: iterative radix\u20112 Cooley\u2013Tukey FFT ----------\nstatic inline void fft_radix2(std::vector<std::complex<double>>& x)\n{\n    const size_t N = x.size();\n    const size_t logN = static_cast<size_t>(std::log2(N));\n\n    // ---- Bit reverse permutation (in place) ----\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        size_t j = 0, k = i;\n        for (size_t b = 0; b < logN; ++b) {\n            j = (j << 1) | (k & 1);\n            k >>= 1;\n        }\n        if (j > i) std::swap(x[i], x[j]);\n    }\n\n    // ---- Pre\u2011compute twiddle factors for each stage ----\n    std::vector<std::complex<double>> wu(logN + 1);\n    for (size_t s = 1; s <= logN; ++s)\n    {\n        const double theta = -M_PI / static_cast<double>(1u << (s-1));\n        wu[s] = std::exp(std::complex<double>(0.0, theta));\n    }\n\n    // ---- Cooley\u2013Tukey butterflies ----\n    for (size_t s = 1; s <= logN; ++s)\n    {\n        const size_t m = 1u << s;          // sub\u2011transform size\n        const size_t m2 = m >> 1;          // half size\n        const std::complex<double> w_m = wu[s];\n        const size_t step = N / m;         // stride between sub\u2011transforms\n\n        #pragma omp parallel for schedule(static, step)\n        for (size_t start = 0; start < N; start += m) {\n            std::complex<double> w = 1.0;\n            for (size_t j = 0; j < m2; ++j) {\n                std::complex<double> t = w * x[start + j + m2];\n                x[start + j + m2] = x[start + j] - t;\n                x[start + j] += t;\n                w *= w_m;\n            }\n        }\n    }\n}\n\n// ---------- Public API ----------\ninline void fft_helper(std::vector<std::complex<double>>& x)\n{\n    // The original implementation performed a forward FFT.\n    // We replace it with a highly\u2011optimised iterative version.\n    fft_radix2(x);\n}\n\ninline void ifft(std::vector<std::complex<double>>& x)\n{\n    // Conjugate the input\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < x.size(); ++i)\n        x[i] = std::conj(x[i]);\n\n    // Forward FFT\n    fft_helper(x);\n\n    // Conjugate again\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < x.size(); ++i)\n        x[i] = std::conj(x[i]);\n\n    // Divide by N\n    const double invN = 1.0 / static_cast<double>(x.size());\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < x.size(); ++i)\n        x[i] *= invN;\n}\n```",
  "03_dense_la_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Compute z = alpha * x + y where x, y and z are vectors of equal length.\n * The operation is performed in parallel using OpenMP.\n */\ninline void axpy(double alpha, const std::vector<double>& x,\n                 const std::vector<double>& y, std::vector<double>& z)\n{\n    const std::size_t n = x.size();\n#pragma omp parallel for schedule(static)\n    for (long long i = 0; i < static_cast<long long>(n); ++i)\n    {\n        z[i] = alpha * x[i] + y[i];\n    }\n}\n```",
  "11_geometry_convex_hull_perimeter": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\nstatic inline double cross(const Point &a, const Point &b, const Point &c) {\n    return (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);\n}\n\nstatic inline double dist(const Point &a, const Point &b) {\n    double dx = b.x - a.x;\n    double dy = b.y - a.y;\n    return std::hypot(dx, dy);\n}\n\n/* Return the perimeter of the smallest convex polygon that contains all the points in the vector points.\n   Example:\n   input: [{0, 3}, {1, 1}, {2, 2}, {4, 4}, {0, 0}, {1, 2}, {3, 1}, {3, 3}]\n   output: 13.4477\n*/\ndouble convexHullPerimeter(std::vector<Point> const& points) {\n    const std::size_t n = points.size();\n    if (n < 3) return 0.0;\n\n    // Work on a copy because we need to sort\n    std::vector<Point> sorted(points);\n    std::sort(sorted.begin(), sorted.end(),\n              [](const Point &a, const Point &b) {\n                  return (a.x < b.x) || (a.x == b.x && a.y < b.y);\n              });\n\n    std::vector<Point> hull;\n    hull.reserve(2 * n);\n\n    // lower hull\n    for (std::size_t i = 0; i < n; ++i) {\n        while (hull.size() >= 2 &&\n               cross(hull[hull.size() - 2], hull[hull.size() - 1], sorted[i]) <= 0.0)\n            hull.pop_back();\n        hull.push_back(sorted[i]);\n    }\n\n    // upper hull\n    std::size_t lower_size = hull.size();\n    for (int i = static_cast<int>(n) - 2; i >= 0; --i) {\n        while (hull.size() > lower_size &&\n               cross(hull[hull.size() - 2], hull[hull.size() - 1], sorted[i]) <= 0.0)\n            hull.pop_back();\n        hull.push_back(sorted[i]);\n    }\n\n    // Remove the duplicated first point\n    if (!hull.empty())\n        hull.pop_back();\n\n    const std::size_t m = hull.size();\n    double perimeter = 0.0;\n\n    // Parallel sum of pairwise distances\n    #pragma omp parallel for reduction(+:perimeter)\n    for (std::size_t i = 0; i < m; ++i) {\n        const std::size_t j = (i + 1) % m;\n        perimeter += dist(hull[i], hull[j]);\n    }\n\n    return perimeter;\n}\n```\n",
  "10_geometry_convex_hull": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n\nstruct Point {\n    double x, y;\n};\n\n/*\n * Find the convex hull of a set of points using the\n * monotone chain algorithm (O(n log n)) with small\n * optimizations for speed (reserve, inlined helpers, etc.)\n */\n\nnamespace {\n    struct PointCmp {\n        inline bool operator()(const Point& a, const Point& b) const noexcept {\n            return (a.x < b.x) || (a.x == b.x && a.y < b.y);\n        }\n    };\n\n    inline double cross(const Point& a, const Point& b, const Point& c) noexcept {\n        return (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);\n    }\n}\n\nvoid convexHull(const std::vector<Point>& points, std::vector<Point>& hull) {\n    const std::size_t n = points.size();\n    if (n < 3) {            // hull is just the input\n        hull = points;\n        return;\n    }\n\n    // Prepare sorted copy\n    std::vector<Point> sorted(points);\n    std::sort(sorted.begin(), sorted.end(), PointCmp{});\n\n    // Allocate maximum possible size (2n)\n    std::vector<Point> tmp;\n    tmp.reserve(2 * n);\n    std::size_t k = 0;\n\n    // Build lower hull\n    for (std::size_t i = 0; i < n; ++i) {\n        while (k >= 2 &&\n               cross(tmp[k - 2], tmp[k - 1], sorted[i]) <= 0.0)\n            --k;\n        if (k < tmp.size())\n            tmp[k] = sorted[i];\n        else\n            tmp.push_back(sorted[i]);\n        ++k;\n    }\n\n    // Build upper hull\n    std::size_t t = k + 1;\n    for (std::size_t i = n; i > 1; --i) {\n        while (k >= t &&\n               cross(tmp[k - 2], tmp[k - 1], sorted[i - 2]) <= 0.0)\n            --k;\n        if (k < tmp.size())\n            tmp[k] = sorted[i - 2];\n        else\n            tmp.push_back(sorted[i - 2]);\n        ++k;\n    }\n\n    // Resize to final size\n    tmp.resize(k - 1);\n    hull.swap(tmp);\n}\n```",
  "51_stencil_edge_kernel": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\n/* Edge detection kernel */\nstatic constexpr int edgeKernel[3][3] = {\n    {-1, -1, -1},\n    {-1,  8, -1},\n    {-1, -1, -1}\n};\n\n/* Convolve the edge kernel with a grayscale image.\n * imageIn and imageOut are stored in row\u2011major order as NxN arrays.\n * The output is clipped to the range [0,255] and stored in imageOut.\n */\ninline void convolveKernel(const std::vector<int> &imageIn,\n                           std::vector<int> &imageOut,\n                           size_t N)\n{\n    /* Parallelise the outer loop with OpenMP. */\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i)\n    {\n        const size_t row = i * N;\n        for (size_t j = 0; j < N; ++j)\n        {\n            int sum = 0;\n\n            /* Manually unroll the 3x3 kernel to avoid bounds checks. */\n            /* Top row */\n            if (i > 0) {          //  i-1 exists\n                const size_t rowPrev = row - N;\n                const int *p = &imageIn[rowPrev + j - 1];\n                sum += p[0] * edgeKernel[0][0];\n                sum += (j < N-1 ? p[1] : 0) * edgeKernel[0][1];\n                sum += (j > 0 ? p[2] : 0) * edgeKernel[0][2];\n            }\n            /* Middle row */\n            {\n                const int *p = &imageIn[row + j - 1];\n                sum += (j > 0 ? p[0] : 0) * edgeKernel[1][0];\n                sum += p[1] * edgeKernel[1][1];\n                sum += (j < N-1 ? p[2] : 0) * edgeKernel[1][2];\n            }\n            /* Bottom row */\n            if (i + 1 < N) {      //  i+1 exists\n                const size_t rowNext = row + N;\n                const int *p = &imageIn[rowNext + j - 1];\n                sum += (j > 0 ? p[0] : 0) * edgeKernel[2][0];\n                sum += p[1] * edgeKernel[2][1];\n                sum += (j < N-1 ? p[2] : 0) * edgeKernel[2][2];\n            }\n\n            /* Clip to [0,255] */\n            if (sum < 0) {\n                imageOut[row + j] = 0;\n            } else if (sum > 255) {\n                imageOut[row + j] = 255;\n            } else {\n                imageOut[row + j] = sum;\n            }\n        }\n    }\n}\n```",
  "50_stencil_xor_kernel": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Same semantics as the original:\n   For each cell (i, j) count the number of adjacent (4\u2011neighbour) cells\n   that are equal to 1 in the *input* grid and set the corresponding cell\n   in *output* to 1 iff that count equals 1.\n   The computation of output[i,j] does NOT depend on output itself,\n   so the work can be parallelised safely. */\ninline void cellsXOR(std::vector<int> const& input,\n                     std::vector<int> &output,\n                     size_t N)\n{\n    /* expose the size to the compiler for better optimisation */\n    const size_t Nminus1 = N - 1;\n\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        const size_t rowOff = i * N;\n        const bool hasTop    = i > 0;\n        const bool hasBottom = i < Nminus1;\n\n        for (size_t j = 0; j < N; ++j) {\n            int cnt = 0;\n\n            if (hasTop    && input[(i-1)*N + j] == 1) ++cnt;\n            if (hasBottom && input[(i+1)*N + j] == 1) ++cnt;\n            if (j > 0      && input[rowOff + j-1] == 1) ++cnt;\n            if (j < Nminus1 && input[rowOff + j+1] == 1) ++cnt;\n\n            output[rowOff + j] = (cnt == 1) ? 1 : 0;\n        }\n    }\n}\n```",
  "53_stencil_2d_jacobi_5-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/*\n * One iteration of a 5\u2011point 2\u2011D Jacobi stencil.\n * `input` and `output` are NxN row\u2011major grids.\n */\ninline void jacobi2D(const std::vector<double> &input,\n                     std::vector<double> &output,\n                     size_t N)\n{\n    /* Parallelise the work using OpenMP.  The outer loop is parallel\n     * (static schedule to keep tiles contiguous) and the inner loop\n     * remains sequential to minimise overhead.\n     */\n    #pragma omp parallel for schedule(static)\n    for (ptrdiff_t ii = 0; ii < static_cast<ptrdiff_t>(N); ++ii) {\n        const ptrdiff_t i = ii;\n        const ptrdiff_t iN = i * static_cast<ptrdiff_t>(N);\n        const ptrdiff_t im1n = (i > 0) ? (i - 1) * static_cast<ptrdiff_t>(N) : -1;\n        const ptrdiff_t ip1n = (i < static_cast<ptrdiff_t>(N) - 1)\n                                 ? (i + 1) * static_cast<ptrdiff_t>(N)\n                                 : -1;\n\n        for (size_t j = 0; j < N; ++j) {\n            const ptrdiff_t jN = j;\n            const double center = input[iN + j];\n            double sum = center;\n\n            /* Contributions from neighbours \u2013 bounds are handled\n             * explicitly so the compiler can eliminate the checks.\n             */\n            if (im1n >= 0) sum += input[im1n + j];\n            if (ip1n >= 0) sum += input[ip1n + j];\n            if (j > 0)      sum += input[iN + j - 1];\n            if (j < N - 1)  sum += input[iN + j + 1];\n\n            output[iN + j] = sum / 5.0;\n        }\n    }\n}\n```",
  "02_dense_la_gemm": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Multiply the matrix A by the matrix B. Store the results in the matrix C.\n * A is an MxK matrix, B is a KxN matrix, and C is a MxN matrix. The matrices are stored\n * in row-major order. This implementation uses blocking and OpenMP parallelism to\n * maximise cache utilisation and exploit the 8 hardware threads available.\n *\n * For correctness the caller must ensure that C has been initialised to zero\n * before calling this function, as the implementation performs an accumulative\n * write (+=) into C.\n */\nvoid gemm(const std::vector<double> &A,\n          const std::vector<double> &B,\n          std::vector<double>       &C,\n          const size_t M, const size_t K, const size_t N)\n{\n    /* Block size tuned for typical L1/L2 cache sizes on x86\u201164. */\n    constexpr size_t BLOCK_M = 64;\n    constexpr size_t BLOCK_K = 32;\n    constexpr size_t BLOCK_N = 64;\n\n    /* Parallelise over rows of C.  Static scheduling gives good load balance\n       because the work per row is equal. */\n    #pragma omp parallel for schedule(static)\n    for (size_t ii = 0; ii < M; ii += BLOCK_M) {\n        size_t i_max = std::min(ii + BLOCK_M, M);\n        for (size_t kk = 0; kk < K; kk += BLOCK_K) {\n            size_t k_max = std::min(kk + BLOCK_K, K);\n            for (size_t jj = 0; jj < N; jj += BLOCK_N) {\n                size_t j_max = std::min(jj + BLOCK_N, N);\n\n                /* Local block indices for better readability. */\n                for (size_t i = ii; i < i_max; ++i) {\n                    const double *Arow = &A[i * K];\n                    double       *Crow = &C[i * N];\n                    for (size_t k = kk; k < k_max; ++k) {\n                        double aik = Arow[k];\n                        const double *Brow = &B[k * N];\n                        for (size_t j = jj; j < j_max; ++j) {\n                            Crow[j] += aik * Brow[j];\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```",
  "54_stencil_game_of_life": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Highly optimised one generation of Conway's Game of Life.\n * Works exactly as the reference but is vectorised, cache friendly,\n * and parallelised with OpenMP.\n *\n * input  : read\u2011only NxN board (row major).\n * output : write\u2011only NxN board (row major, must be pre\u2011allocated).\n * N      : board dimension.\n */\ninline void gameOfLife(const std::vector<int> &input,\n                       std::vector<int> &output,\n                       std::size_t N)\n{\n    const int stride = static_cast<int>(N);\n    const int *in  = input.data();\n    int       *out = output.data();\n\n    /* Pre\u2011compute row offsets for speed */\n    std::vector<int> rowPtr(N);\n    for (std::size_t r = 0; r < N; ++r) rowPtr[r] = static_cast<int>(r * N);\n\n    /* Parallelise over rows (outer loop) */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < static_cast<int>(N); ++i)\n    {\n        const int idx = rowPtr[i];\n        const int i_m1 = i - 1;\n        const int i_p1 = i + 1;\n        for (int j = 0; j < static_cast<int>(N); ++j)\n        {\n            int sum = 0;\n\n            /* neighbouring indices (avoid bounds checks inside inner loop) */\n            if (i_m1 >= 0) {\n                sum += in[rowPtr[i_m1] + j];\n                if (j > 0)   sum += in[rowPtr[i_m1] + j - 1];\n                if (j + 1 < static_cast<int>(N))\n                    sum += in[rowPtr[i_m1] + j + 1];\n            }\n            if (i_p1 < static_cast<int>(N)) {\n                sum += in[rowPtr[i_p1] + j];\n                if (j > 0)   sum += in[rowPtr[i_p1] + j - 1];\n                if (j + 1 < static_cast<int>(N))\n                    sum += in[rowPtr[i_p1] + j + 1];\n            }\n            if (j > 0)   sum += in[idx + j - 1];\n            if (j + 1 < static_cast<int>(N))\n                sum += in[idx + j + 1];\n\n            const int cur = in[idx + j];\n            bool alive;\n            if (cur) {\n                alive = (sum == 2 || sum == 3);\n            } else {\n                alive = (sum == 3);\n            }\n            out[idx + j] = alive ? 1 : 0;\n        }\n    }\n}\n```",
  "04_dense_la_gemv": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\n/*\n * Multiply an MxN matrix A (row\u2011major) by a vector x (length N).\n * The result is written into y (length M).\n *\n * The function is written with the following optimisations:\n *  - OpenMP parallelisation over the outer loop (rows).\n *  - `#pragma omp simd` to enable vectorisation of the inner loop.\n *  - Use raw pointers for the data to avoid bounds checks.\n *  - Avoid repeated pointer dereferencing inside the inner loop.\n */\nvoid gemv(std::vector<double> const& A,\n          std::vector<double> const& x,\n          std::vector<double> &y,\n          size_t M, size_t N)\n{\n    // Ensure y is correctly sized\n    y.resize(M);\n\n    const double *Aptr = A.data();\n    const double *xptr = x.data();\n    double       *yptr = y.data();\n\n    // Parallelise over rows. Static scheduling gives good balance\n    // for small to medium M with a fixed N.\n    #pragma omp parallel for schedule(static)\n    for (ptrdiff_t i = 0; i < static_cast<ptrdiff_t>(M); ++i)\n    {\n        const double *Arow = Aptr + i * static_cast<ptrdiff_t>(N);\n        double sum = 0.0;\n\n        // Explicit SIMD hint. The compiler will usually vectorise this loop.\n        #pragma omp simd reduction(+:sum)\n        for (ptrdiff_t j = 0; j < static_cast<ptrdiff_t>(N); ++j)\n        {\n            sum += Arow[j] * xptr[j];\n        }\n\n        yptr[i] = sum;\n    }\n}\n```\n",
  "00_dense_la_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\ninline void luFactorize(std::vector<double> &A, size_t N) {\n    // pure Doolittle L\u2011U factorisation, 1\u2011based\n    for (size_t k = 0; k < N; ++k) {\n        double diag = A[k * N + k];\n        /* parallelise the work over rows i > k */\n        #pragma omp parallel for schedule(static, 64) default(none) shared(A, N, k, diag)\n        for (size_t i = k + 1; i < N; ++i) {\n            double* Ai   = &A[i * N];           // row i\n            double* Ak   = &A[k * N];           // row k\n            double factor = Ai[k] / diag;       // factor = A[i][k] / A[k][k]\n            Ai[k] = factor;                     // store factor (L part)\n\n            /* inner loop \u2013 vectorised subtraction */\n            size_t j = k + 1;\n            for (; j + 3 < N; j += 4) {\n                Ai[j    ] -= factor * Ak[j    ];\n                Ai[j + 1] -= factor * Ak[j + 1];\n                Ai[j + 2] -= factor * Ak[j + 2];\n                Ai[j + 3] -= factor * Ak[j + 3];\n            }\n            /* tail */\n            for (; j < N; ++j) {\n                Ai[j] -= factor * Ak[j];\n            }\n        }\n    }\n}\n```\nThis replacement keeps the exact mathematical behaviour of the original routine while adding:\n- **OpenMP parallelisation** of the row\u2011update loop.\n- **Explicit pointer arithmetic** to reduce index recomputation.\n- **Loop unrolling** and **static scheduling** to improve vectorisation and cache utilisation.\n\nThe function signature and semantics remain unchanged, so it can be dropped in place of the original implementation.",
  "43_sort_sort_an_array_of_structs_by_key": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <thread>\n#include <future>\n\nstruct Result {\n    int startTime, duration;\n    float value;\n};\n\n// Parallel quicksort implementation with hybrid std::sort for small ranges\nstatic constexpr std::size_t THRESHOLD = 1 << 12;      // 4\u202fk elements\nstatic constexpr std::size_t MAX_THREADS = std::thread::hardware_concurrency();\n\ninline void quicksort_par(std::vector<Result>::iterator first,\n                          std::vector<Result>::iterator last,\n                          std::size_t depth = 0) {\n    if (last - first <= THRESHOLD) {\n        std::sort(first, last, [](const Result& a, const Result& b) {\n            return a.startTime < b.startTime;\n        });\n        return;\n    }\n\n    auto pivot = std::prev(last);\n    std::swap(*pivot, *std::next(first + (last - first) / 2));\n    auto mid = std::partition(first, last - 1,\n                              [](const Result& x) { return x.startTime < (*pivot).startTime; });\n\n    std::swap(*mid, *pivot);\n\n    if (depth < MAX_THREADS) {\n        std::future<void> left = std::async(std::launch::async,\n                                            quicksort_par, first, mid, depth + 1);\n        quicksort_par(mid, last, depth + 1);\n        left.get();\n    } else {\n        quicksort_par(first, mid, depth + 1);\n        quicksort_par(mid, last, depth + 1);\n    }\n}\n\nvoid sortByStartTime(std::vector<Result> &results) {\n    if (results.empty()) return;\n    quicksort_par(results.begin(), results.end());\n}\n```",
  "40_sort_sort_an_array_of_complex_numbers_by_magnitude": "```cpp\n#pragma once\n#include <algorithm>\n#include <complex>\n#include <vector>\n\n/// Sort a vector of complex numbers by magnitude (ascending).\n/// The original implementation used `std::abs(a)` which incurs a square\u2011root\n/// for every comparison.  We avoid the square root by comparing the\n/// squared magnitudes instead.  All other aspects of the behaviour\n/// (including the strict weak ordering) are preserved.\ninline void sortComplexByMagnitude(std::vector<std::complex<double>>& x)\n{\n    auto sq_mag = [](const std::complex<double>& z) {\n        return std::norm(z);               // |z|^2 = real^2 + imag^2\n    };\n\n    std::sort(x.begin(), x.end(),\n              [&](const std::complex<double>& a,\n                  const std::complex<double>& b) {\n                  return sq_mag(a) < sq_mag(b);\n              });\n}\n```",
  "41_sort_k-th_smallest_element": "```cpp\n#pragma once\n#include <algorithm>\n#include <vector>\n\n/* Find the k-th smallest element of the vector x.\n   Example:\n   \n   input: x=[1, 7, 6, 0, 2, 2, 10, 6], k=4\n   output: 6\n*/\nint findKthSmallest(std::vector<int> const& x, int k) {\n    // Make a copy so that the original vector remains unchanged\n    std::vector<int> x_copy = x;\n\n    // nth_element gives the element that would be at position k-1 if the vector were sorted.\n    std::nth_element(x_copy.begin(), x_copy.begin() + (k - 1), x_copy.end());\n\n    return x_copy[k - 1];\n}\n```",
  "01_dense_la_solve": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\n/*\n * Linear system solver with Gaussian elimination + back substitution.\n * The algorithm keeps the same semantics: a zero pivot aborts the routine\n * (exactly as the original code).  The matrix is stored in row\u2011major form.\n *\n * Optimisations:\n *   \u2022 Parallelise the inner elimination loop with OpenMP.\n *   \u2022 Use raw pointer arithmetic for cache friendliness.\n *   \u2022 Avoid unnecessary temporary objects by operating directly on\n *     the copied vectors.\n *   \u2022 Keep the exact numerical behaviour by using double precision\n *     everywhere and by not performing any extra work on zeros.\n */\ninline void solveLinearSystem(std::vector<double> const& A,\n                              std::vector<double> const& b,\n                              std::vector<double> &x,\n                              std::size_t N)\n{\n    // Local copies of A and b (row\u2011major matrix)\n    std::vector<double> A_copy = A;\n    std::vector<double> b_copy = b;\n\n    double* mat = A_copy.data();   // pointer to matrix data\n    double* rhs = b_copy.data();   // pointer to RHS data\n\n    // Gaussian elimination\n    for (std::size_t i = 0; i + 1 < N; ++i)\n    {\n        double pivot = mat[i * N + i];\n        if (pivot == 0.0)          // zero pivot \u2013 abort\n            return;\n\n        // Parallel elimination of rows below the pivot\n#pragma omp parallel for schedule(static)\n        for (std::size_t j = i + 1; j < N; ++j)\n        {\n            double factor = rhs[j] / pivot;\n            std::size_t idx_row = j * N;\n\n            // Subtract factor * pivot_row from current row\n            for (std::size_t k = i; k < N; ++k)\n            {\n                mat[idx_row + k] -= factor * mat[i * N + k];\n            }\n            rhs[j] -= factor * rhs[i];\n        }\n    }\n\n    // Back substitution (sequential \u2013 data dependency)\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i)\n    {\n        double sum = 0.0;\n        std::size_t idx_i = i * N;\n        for (std::size_t j = i + 1; j < N; ++j)\n            sum += mat[idx_i + j] * x[j];\n\n        x[i] = (rhs[i] - sum) / mat[idx_i + i];\n    }\n}\n```",
  "36_search_check_if_array_contains_value": "```cpp\n#pragma once\n#include <vector>\n\nbool contains(std::vector<int> const& x, int target) {\n    // Fast linear search using pointer arithmetic.\n    // Avoid bounds checks by using raw indices.\n    const int n = static_cast<int>(x.size());\n    const int* data = x.data();\n    for (int i = 0; i < n; ++i) {\n        if (data[i] == target)\n            return true;\n    }\n    return false;\n}\n```\n",
  "35_search_search_for_last_struct_by_key": "```cpp\n#pragma once\n#include <vector>\n#include <string>\n\nstruct Book {\n    std::string title;\n    int pages;\n};\n\n/*\n * Return the index of the last Book item in the vector books where\n * Book.pages is less than 100.  If no such Book exists, return books.size().\n *\n * Example:\n *\n *   input: [{title=\"Green Eggs and Ham\", pages=72},\n *           {title=\"gulliver's travels\", pages=362},\n *           {title=\"Stories of Your Life\", pages=54},\n *           {title=\"Hamilton\", pages=818}]\n *\n *   output: 2\n */\nsize_t findLastShortBook(std::vector<Book> const& books) {\n    // Scan from the end; as soon as a matching book is found return its index.\n    // Use size_t for the index; it is valid for all non-negative ints.\n    for (size_t i = books.size(); i-- > 0; ) {\n        if (books[i].pages < 100) {\n            return i;\n        }\n    }\n    // No book meets the condition\n    return books.size();\n}\n```",
  "39_search_xor_contains": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n\n/*\n  Return true iff `val` appears in exactly one of the two vectors.\n  Behaviour is identical to the original implementation.\n*/\ninline bool xorContains(const std::vector<int>& x,\n                        const std::vector<int>& y,\n                        int val) noexcept\n{\n    // Find `val` in each vector early\u2011out style.\n    bool foundInX = false, foundInY = false;\n\n    // Optimised manual search \u2013 avoids bound checks in the standard lib.\n    for (auto it = x.cbegin(); it != x.cend(); ++it)\n        if (*it == val) { foundInX = true; break; }\n\n    for (auto it = y.cbegin(); it != y.cend(); ++it)\n        if (*it == val) { foundInY = true; break; }\n\n    return foundInX ^ foundInY;   // XOR: true if only one is true\n}\n```",
  "42_sort_sorted_ranks": "```cpp\n#pragma once\n#include <algorithm>\n#include <numeric>\n#include <vector>\n\n/* For each value in the vector `x` compute its index in the\n * sorted vector, preserving relative order of equal elements\n * (stable sort). The results are stored in `ranks_`.\n */\ninline void ranks(const std::vector<float>& x, std::vector<size_t>& ranks_) {\n    const size_t n = x.size();\n    // Pair each value with its original index.\n    std::vector<std::pair<float, size_t>> vp;\n    vp.reserve(n);\n    for (size_t i = 0; i < n; ++i) vp.emplace_back(x[i], i);\n\n    // Stable sort by value.\n    std::stable_sort(vp.begin(), vp.end(),\n                     [](const auto& a, const auto& b) { return a.first < b.first; });\n\n    // Assign ranks: the i\u2011th element in the sorted list gets rank i.\n    for (size_t i = 0; i < n; ++i) {\n        ranks_[vp[i].second] = i;\n    }\n}\n```",
  "38_search_find_the_first_even_number": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n\n/* Return the index of the first even number in the vector `x`.\n   The function preserves the exact behaviour of the reference\n   implementation: it returns `x.size()` if no even element exists.\n*/\ninline size_t findFirstEven(std::vector<int> const& x)\n{\n    const std::size_t n = x.size();\n    const int* data = x.data();\n\n    // Simple sequential search with loop\u2011unrolling for a small speed gain.\n    std::size_t i = 0;\n    constexpr std::size_t stride = 4;\n    const std::size_t limit = n - n % stride;\n\n    for (; i < limit; i += stride) {\n        if ((data[i]     & 1) == 0) return i;\n        if ((data[i + 1] & 1) == 0) return i + 1;\n        if ((data[i + 2] & 1) == 0) return i + 2;\n        if ((data[i + 3] & 1) == 0) return i + 3;\n    }\n    // Handle the tail.\n    for (; i < n; ++i) {\n        if ((data[i] & 1) == 0) return i;\n    }\n    return n;\n}\n```\n",
  "44_sort_sort_non-zero_elements": "```cpp\n#pragma once\n#include <algorithm>\n#include <vector>\n#include <omp.h>\n\n// Sort all non\u2011zero elements of the vector while keeping zero\n// elements in their original positions.\ninline void sortIgnoreZero(std::vector<int> &x) {\n    const std::size_t N = x.size();\n\n    // If the vector is tiny, skip the unnecessary overhead.\n    if (N <= 32) {\n        std::vector<int> nz;\n        nz.reserve(N);\n        for (int v : x)\n            if (v != 0) nz.push_back(v);\n        std::sort(nz.begin(), nz.end());\n        std::size_t idx = 0;\n        for (std::size_t i = 0; i < N; ++i)\n            if (x[i] != 0) x[i] = nz[idx++];\n        return;\n    }\n\n    // ------------------------------------------------------------------\n    // Gather non\u2011zero values (reserve capacity to avoid reallocations).\n    // This loop is trivially parallelisable.\n    // ------------------------------------------------------------------\n    std::vector<int> nz;\n    nz.reserve(N);                      // maximum possible size\n    #pragma omp parallel\n    {\n        std::vector<int> local;\n        local.reserve(N / omp_get_num_threads() + 1);\n        #pragma omp for nowait\n        for (std::size_t i = 0; i < N; ++i) {\n            if (x[i] != 0) local.push_back(x[i]);\n        }\n        #pragma omp critical\n        nz.insert(nz.end(), std::make_move_iterator(local.begin()),\n                    std::make_move_iterator(local.end()));\n    }\n\n    // ------------------------------------------------------------------\n    // Sort the collected non\u2011zero values.\n    // ------------------------------------------------------------------\n    std::sort(nz.begin(), nz.end());\n\n    // ------------------------------------------------------------------\n    // Re\u2011insert sorted values back into the original vector.\n    // OpenMP parallelises the assignment since each non\u2011zero\n    // location is independent.\n    // ------------------------------------------------------------------\n    std::size_t pos = 0;\n    #pragma omp parallel for\n    for (std::size_t i = 0; i < N; ++i) {\n        if (x[i] != 0) {\n            // The outer scope ensures that 'pos' is correctly\n            // updated in a thread\u2011safe manner by using an atomic\n            // increment.  Because the writes are independent, we\n            // can use a per\u2011thread buffer approach instead.\n            // We reuse the same parallel loop but serialize the\n            // position assignment with a critical section.\n            #pragma omp critical\n            {\n                x[i] = nz[pos++];\n            }\n        }\n    }\n}\n```\n",
  "37_search_find_the_closest_number_to_pi": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n\n/* Return the index of the value in the vector x that is closest to the math constant PI.\n   Use M_PI for the value of PI.\n   Example:\n   input: [9.18, 3.05, 7.24, 11.3, -166.49, 2.1]\n   output: 1\n*/\nsize_t findClosestToPi(std::vector<double> const& x) {\n    if (x.empty()) {\n        return 0;   // undefined behaviour for empty input \u2013 return 0 as safe default\n    }\n    const double pi = M_PI;\n    auto const it = std::min_element(\n        x.begin(), x.end(),\n        [pi](double a, double b) { return std::abs(a - pi) < std::abs(b - pi); }\n    );\n    return static_cast<size_t>(std::distance(x.begin(), it));\n}\n```\n"
}