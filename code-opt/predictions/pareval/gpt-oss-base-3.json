{
  "15_graph_edge_count": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n\nint edgeCount(const std::vector<int> &A, std::size_t N) {\n    int count = 0;\n#pragma omp parallel for collapse(2) reduction(+:count) schedule(static)\n    for (std::size_t i = 0; i < N; ++i) {\n        for (std::size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1)\n                ++count;\n        }\n    }\n    return count;\n}\n```\n",
  "20_histogram_pixel_histogram": "```cpp\n#pragma once\n#include <vector>\n#include <array>\n#include <cstddef>\n\ninline void pixelCounts(const std::vector<int>& image, std::array<std::size_t, 256>& bins) noexcept\n{\n    // reset bins\n    for (auto& v : bins) v = 0;\n\n    // parallel histogram with OpenMP reduction on an array\n    #pragma omp parallel for schedule(static, 65536) reduction(+:bins[:256])\n    for (std::size_t i = 0; i < image.size(); ++i) {\n        // the image contains values in [0,255], cast to unsigned char index\n        bins[static_cast<unsigned char>(image[i])] += 1;\n    }\n}\n```\n",
  "17_graph_highest_degree": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\n/* Compute the highest node degree in an undirected graph.\n   The graph is given by its NxN adjacency matrix `A` stored in row-major order.\n   Example:\n        input: [0,0,0,1, 0,0,0,1, 0,0,0,1, 1,1,1,0]\n        output: 3\n*/\ninline int maxDegree(const std::vector<int>& A, std::size_t N) {\n    int highestDegree = 0;\n\n    /* Parallelise the outer loop and use a reduction to find the maximum. */\n#pragma omp parallel for reduction(max:highestDegree) schedule(static)\n    for (int i = 0; i < static_cast<int>(N); ++i) {\n        int sum = 0;\n        const int* rowStart = A.data() + i * N;\n        /* Unroll the inner loop for a small performance gain. */\n        for (size_t j = 0; j < N; ++j) {\n            sum += rowStart[j];\n        }\n        if (sum > highestDegree) highestDegree = sum;\n    }\n\n    return highestDegree;\n}\n```",
  "19_graph_shortest_path": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n\n/* Return the length of the shortest path from source to dest in the undirected\n   graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row\u2011major order.  The graph is\n   connected and undirected.\n*/\nint shortestPathLength(std::vector<int> const& A, size_t N,\n                       int source, int dest)\n{\n    // Use a simple ring buffer for the BFS frontier.\n    std::vector<int> queue(N);            // maximum possible size\n    int head = 0, tail = 0;              // indices in the ring buffer\n\n    // distance array \u2013 -1 means unvisited\n    std::vector<int> dist(N, -1);\n    dist[source] = 0;\n    queue[tail++] = source;\n\n    while (head != tail)\n    {\n        int current = queue[head++];\n        if (head == N) head = 0;   // wrap\n        int d = dist[current];\n\n        if (current == dest) return d;\n\n        const int *row = &A[current * N];\n        for (size_t i = 0; i < N; ++i)\n        {\n            if (row[i] && dist[i] == -1)\n            {\n                dist[i] = d + 1;\n                queue[tail++] = static_cast<int>(i);\n                if (tail == N) tail = 0;   // wrap\n            }\n        }\n    }\n\n    return std::numeric_limits<int>::max(); // unreachable (should not happen)\n}\n```",
  "23_histogram_first_letter_counts": "```cpp\n#pragma once\n#include <array>\n#include <string>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Count how many strings in `s` start with each lowercase letter.\n * The result is stored in `bins[0]` .. `bins[25]` corresponding to 'a'..'z'.\n * A parallel OpenMP implementation is used for speed on multi\u2011core CPUs.\n */\ninline void firstLetterCounts(const std::vector<std::string> &s,\n                              std::array<std::size_t, 26> &bins) noexcept\n{\n    // Ensure bins start from zero\n    bins.fill(0);\n\n    const std::size_t n = s.size();\n\n    // Thread\u2013local arrays (one per thread) to avoid atomic operations.\n    const int maxThreads = omp_get_max_threads();\n    std::vector<std::array<std::size_t, 26>> localBins(maxThreads);\n    for (int t = 0; t < maxThreads; ++t)\n        localBins[t].fill(0);\n\n    // Parallel loop over the vectors indices\n    #pragma omp parallel\n    {\n        const int tid = omp_get_thread_num();\n        auto &local = localBins[tid];\n\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < n; ++i) {\n            // The strings are guaranteed to be non\u2011empty and lowercase\n            const unsigned char c = static_cast<unsigned char>(s[i][0]);\n            const int index = c - 'a';\n            local[index] += 1;\n        }\n    }\n\n    // Reduce the per\u2011thread results into the final `bins`\n    for (int t = 0; t < maxThreads; ++t) {\n        for (int j = 0; j < 26; ++j)\n            bins[j] += localBins[t][j];\n    }\n}\n```",
  "21_histogram_bin_0-100": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Vector x contains values between 0 and 100, inclusive. Count the number of\n   values in [0,10), [10, 20), [20, 30), ... and store the counts in `bins`.\n   Example:\n   input: [7, 32, 95, 12, 39, 32, 11, 71, 70, 66]\n   output: [1, 2, 0, 3, 0, 0, 1, 2, 0, 1]\n   The implementation is fully parallelized with OpenMP while preserving\n   the exact semantics of the original sequential code. */\ninline void binsBy10Count(std::vector<double> const& x, std::array<size_t, 10> &bins) {\n    // Initialise temporary per-thread arrays\n    const size_t nthreads = omp_get_max_threads();\n    std::vector<std::array<size_t,10>> local_bins(nthreads);\n\n    // Parallel loop with static scheduling for good load balance.\n    #pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(x.size()); ++i) {\n        size_t const idx = static_cast<size_t>(omp_get_thread_num());\n        size_t const bin = static_cast<size_t>(x[i] / 10.0);   // Division is safe\n        local_bins[idx][bin] += 1;\n    }\n\n    // Reduce per-thread results into the final bins array\n    for (size_t t = 0; t < nthreads; ++t) {\n        for (size_t b = 0; b < 10; ++b)\n            bins[b] += local_bins[t][b];\n    }\n}\n```",
  "18_graph_count_components": "```cpp\n/*  Optimised component counting for an undirected graph\n *  represented by an N x N adjacency matrix stored row\u2011major.\n *\n *  The code keeps the original behaviour but replaces the\n *  recursive DFS with an explicit stack, uses a compact visited\n *  array (uint8_t), and removes unnecessary bounds checks.\n *  The function is thread\u2011safe as all data are local to the\n *  call, so it can be called from an OpenMP parallel region\n *  if desired.\n *\n *  No other interface changes are made.\n */\n\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <stack>\n#include <utility>\n#include <algorithm>\n\ninline int componentCount(const std::vector<int>& A, size_t N)\n{\n    /* visited[i] == 1  -> node i already processed   */\n    std::vector<uint8_t> visited(N, 0);\n    int components = 0;\n\n    std::stack<int> st;\n    st.push(0);                    // dummy to avoid empty stack check\n\n    for (size_t start = 0; start < N; ++start)\n    {\n        if (visited[start])\n            continue;\n\n        ++components;              // new component found\n\n        /* ---------- iterative DFS for the component ---------- */\n        st.push(static_cast<int>(start));\n        visited[start] = 1;\n\n        while (!st.empty())\n        {\n            int u = st.top();\n            st.pop();\n\n            /* iterate over all possible neighbours of u */\n            const int* row = A.data() + u * N;\n            for (size_t v = 0; v < N; ++v)\n            {\n                /* skip if no edge or already visited */\n                if (row[v] && !visited[v])\n                {\n                    visited[v] = 1;\n                    st.push(static_cast<int>(v));\n                }\n            }\n        }\n    }\n\n    return components;\n}\n```",
  "34_scan_largest_contiguous_subarray_sum": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n\n/* Return the largest sum of any contiguous subarray in the vector x.\n   Implements the classic O(n) Kadane algorithm which is faster\n   than the original quadratic implementation. The result is\n   identical to the original function: if all numbers are\n   negative the maximum element is returned. */\nint maximumSubarray(std::vector<int> const& x) {\n    if (x.empty()) return std::numeric_limits<int>::lowest(); // no elements\n\n    int best = std::numeric_limits<int>::lowest();\n    int current = 0;\n\n    for (int value : x) {\n        current = std::max(value, current + value);\n        best = std::max(best, current);\n    }\n    return best;\n}\n```",
  "24_histogram_count_quartile": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <cmath>\n#include <algorithm>\n#include <omp.h>\n\n/* Count the number of doubles in the vector `x` that have a fractional part \n   in [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). Store the counts in `bins`.\n   The function is fully thread\u2011safe and preserves the exact behavior of the\n   original implementation.  */\ninline void countQuartiles(std::vector<double> const& x, std::array<size_t, 4> &bins)\n{\n    // initialise the output array to zero\n    bins.fill(0);\n\n    // Each thread maintains its own local bin array to avoid contention.\n    // Size 4 corresponds to the four quartile ranges.\n#pragma omp parallel\n    {\n        // local bin counters for this thread\n        size_t local[4] = {0, 0, 0, 0};\n\n#pragma omp for schedule(static)\n        for (std::size_t i = 0; i < x.size(); ++i)\n        {\n            double val   = x[i];\n            double frac  = val - std::trunc(val); // faster than (int) cast for doubles\n            // classise fractional part\n            if      (frac < 0.25)  ++local[0];\n            else if (frac < 0.5)   ++local[1];\n            else if (frac < 0.75)  ++local[2];\n            else                   ++local[3];\n        }\n\n        // merge the local bins into the global result\n#pragma omp atomic\n        for (int i = 0; i < 4; ++i) bins[i] += local[i];\n    }\n}\n```",
  "16_graph_largest_component": "```cpp\n#pragma once\n#include <vector>\n#include <numeric>\n#include <algorithm>\n\ninline int findRoot(std::vector<int>& parent, int v) {\n    while (parent[v] != v) {\n        parent[v] = parent[parent[v]];   // Path compression (half).\n        v = parent[v];\n    }\n    return v;\n}\n\ninline void unionSets(std::vector<int>& parent, std::vector<int>& sz,\n                      int a, int b) {\n    int ra = findRoot(parent, a);\n    int rb = findRoot(parent, b);\n    if (ra == rb) return;\n    if (sz[ra] < sz[rb]) std::swap(ra, rb);\n    parent[rb] = ra;\n    sz[ra] += sz[rb];\n}\n\n/* Return the number of vertices in the largest component of the graph\n   defined by the adjacency matrix A.  A is an NxN adjacency matrix\n   stored in row\u2011major order. */\nint largestComponent(std::vector<int> const& A, size_t N) {\n    // Union\u2011Find structure\n    std::vector<int> parent(N);\n    std::vector<int> sz(N, 1);\n    std::iota(parent.begin(), parent.end(), 0);\n\n    // Process upper triangular part only (undirected graph)\n    for (size_t i = 0; i < N; ++i) {\n        const int* row = A.data() + i * N;\n        for (size_t j = i + 1; j < N; ++j) {\n            if (row[j] == 1) {\n                unionSets(parent, sz, static_cast<int>(i), static_cast<int>(j));\n            }\n        }\n    }\n\n    // Find maximum component size\n    int maxSize = 0;\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i) {\n        if (parent[i] == i) {          // Root node\n            maxSize = std::max(maxSize, sz[i]);\n        }\n    }\n    return maxSize;\n}\n```",
  "33_scan_reverse_prefix_sum": "```cpp\n#pragma once\n#include <vector>\n\n/* Compute the reverse prefix sum of the vector x into output.\n   The algorithm preserves the original behaviour but replaces the\n   dynamic allocation and std::inclusive_scan, producing a linear\u2011time\n   implementation that is faster and uses no temporary storage.\n*/\nvoid reversePrefixSum(std::vector<int> const& x, std::vector<int> &output)\n{\n    const std::size_t n = x.size();\n    output.resize(n);                    // ensure output has the correct length\n\n    int cumulative = 0;                  // running sum of the suffix\n    for (std::size_t idx = n; idx-- > 0;) // iterate from last element to first\n    {\n        cumulative += x[idx];\n        output[idx] = cumulative;\n    }\n}\n```\n",
  "32_scan_sum_of_prefix_sum_array": "```cpp\n#pragma once\n#include <cstdint>\n#include <vector>\n#include <omp.h>\n\n/* Compute the prefix sum array of the vector x and return its sum.\n   This implementation uses the identity\n   sum_{i=0}^{n-1} prefixSum[i] = \u03a3_{i=0}^{n-1} (n-i) * x[i]\n   to avoid an intermediate array and to keep the computation\n   cache\u2011friendly.  It is fully parallelised with OpenMP and\n   follows the exact behaviour of the original function.\n*/\nint64_t sumOfPrefixSum(const std::vector<int64_t>& x)\n{\n    const std::size_t n = x.size();\n    if (n == 0) return 0;\n\n    int64_t total = 0;\n\n#if defined(_OPENMP) && _OPENMP >= 200811\n#pragma omp parallel for reduction(+:total)\n#endif\n    for (std::size_t i = 0; i < n; ++i)\n    {\n        total += static_cast<int64_t>(n - i) * x[i];\n    }\n\n    return total;\n}\n```",
  "22_histogram_count_quadrants": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\n/*\n * Count the number of cartesian points in each quadrant.  \n * The vector `points` contains a list of `Point` objects.\n * Store the counts in `bins`.\n *\n * This implementation is fully parallelized with OpenMP.\n * It uses a per-thread local array for the counts and a\n * reduction to accumulate the results.  No floating\u2011point\n * precision is lost and the function is equivalent to the\n * original.\n */\nvoid countQuadrants(std::vector<Point> const& points,\n                    std::array<size_t, 4>& bins)\n{\n    // Initialise the output array to zero\n    bins = {0, 0, 0, 0};\n\n    /* Perform the counting in parallel.  A hidden overhead of\n     * thread creation is negligible because the number of points\n     * is expected to be large compared to the number of threads.\n     */\n    #pragma omp parallel\n    {\n        // Per-thread buffer for local counts\n        size_t local[4] = {0, 0, 0, 0};\n\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < points.size(); ++i) {\n            const auto& p = points[i];\n            // Branchless detection of quadrant signs\n            const bool xpos = p.x >= 0.0;\n            const bool ypos = p.y >= 0.0;\n            const int  q = (xpos << 1) | (ypos); // 00->0, 01->1, 10->2, 11->3\n\n            /* The mapping (xsign<<1 | ysign) yields: 0 for Q0 (x>=0,y>=0),\n             * 1 for Q1 (x<0,y>=0), 2 for Q2 (x<0,y<0), 3 for Q3 (x>=0,y<0).\n             */\n            local[q] += 1;\n        }\n\n        // Reduce local counts into the global result\n        #pragma omp atomic\n        bins[0] += local[0];\n        #pragma omp atomic\n        bins[1] += local[1];\n        #pragma omp atomic\n        bins[2] += local[2];\n        #pragma omp atomic\n        bins[3] += local[3];\n    }\n}\n```",
  "59_transform_map_function": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <omp.h>\n\ninline constexpr bool isPowerOfTwo(uint64_t x) noexcept {\n    return x && !(x & (x - 1));\n}\n\n/*\n   Apply the isPowerOfTwo function to every value in `x` and store the\n   results in `mask`.  The two vectors must already have the same size.\n   The implementation uses OpenMP to parallelise the loop across all\n   available cores.  The operation is trivially parallelisable and\n   `noexcept` guarantees no exception is thrown.\n*/\ninline void mapPowersOfTwo(const std::vector<int32_t>& x,\n                           std::vector<bool>& mask) noexcept\n{\n    const std::size_t n = x.size();\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i)\n        mask[i] = isPowerOfTwo(static_cast<uint64_t>(x[i]));\n}\n```",
  "56_transform_negate_odds": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>\n\n/* In the vector x negate the odd values and divide the even values by 2.\n   Example:\n   \n   input: [16, 11, 12, 14, 1, 0, 5]\n   output: [8, -11, 6, 7, -1, 0, -5]\n*/\ninline void negateOddsAndHalveEvens(std::vector<int> &x) {\n    // Use OpenMP to parallelise over the elements.\n    // The transformation is element\u2011wise and independent, so a simple\n    // parallel for is safe.  We avoid expensive % operation by using bit\u2011wise\n    // check for odd/even.\n#pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t idx = 0; idx < static_cast<std::ptrdiff_t>(x.size()); ++idx) {\n        int v = x[idx];\n        if ((v & 1) == 0) {          // even\n            x[idx] = v / 2;          // integer division\n        } else {                     // odd\n            x[idx] = -v;\n        }\n    }\n}\n```",
  "57_transform_inverse_offset": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\n/* Replace every element of the vector x with 1-1/x.\n   Example:\n   input: [2, 4, 1, 12, -2]\n   output: [0.5, 0.75, 0, 0.91666666, 1.5]\n*/\ninline void oneMinusInverse(std::vector<double> &x) {\n    const std::size_t n = x.size();\n    if (n == 0) return;\n\n    /* Parallel SIMD-friendly loop.  We use a static schedule to keep the\n       workload balanced across the 8 hardware threads.  The compiler is\n       free to auto-vectorise the loop because it operates on contiguous\n       memory and has no data dependencies. */\n#pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        double const val = x[i];\n        /* Preserve the original behaviour: a division by zero yields\n           \u00b1inf or NaN, matching the reference implementation. */\n        x[i] = 1.0 - 1.0 / val;\n    }\n}\n```",
  "55_transform_relu": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <omp.h>\n\n/*\n * Compute the ReLU function on every element of x. Elements less than zero become\n * zero, while elements greater than zero stay the same. This version is\n * hand\u2011optimized for x86\u201164 with GCC\u00a09+ (OpenMP\u00a04.5+).  It uses a parallel\n * loop with static scheduling, relies on the compiler to vectorise the body,\n * and avoids the overhead of std::transform.\n *\n * The function preserves the exact behaviour of the original std::transform\n * implementation.\n */\ninline void relu(std::vector<double>& x)\n{\n    const std::size_t n = x.size();\n    if (n == 0) return;\n\n    /* Keep a local pointer for the underlying array to avoid bounds\n     * checks and enable vectorisation.  The compiler will emit\n     * load/store instructions that are nicely aligned on most\n     * hardware. */\n    double* const data = x.data();\n\n    /* OpenMP static scheduling gives the best load balance for a\n     * large number of elements.  We also use the `if` clause to\n     * serialise small vectors to avoid thread launch overhead. */\n#pragma omp parallel for schedule(static) if(n > 1024)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(n); ++i)\n    {\n        // Inline std::max for maximum compatibility with the compiler's\n        // auto\u2011vectorisation; fabs is not needed.\n        data[i] = data[i] > 0.0 ? data[i] : 0.0;\n    }\n}\n```",
  "58_transform_squaring": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <omp.h>\n\n/*\n * Replace every element of `x` with the square of its value.\n * Example:\n *   input : [5, 1, 2, -4, 8]\n *   output: [25, 1, 4, 16, 64]\n */\ninline void squareEach(std::vector<int> &x) {\n    // Get raw pointer for fast indexing\n    int *data = x.data();\n    std::size_t n = x.size();\n\n    // Parallel loop: static schedule gives almost perfect load balance\n    #pragma omp parallel for schedule(static) if(n > 0)\n    for (std::size_t i = 0; i < n; ++i) {\n        // Avoid overflow on 32\u2011bit much less common, but sign\u2011extension is fine\n        int v = data[i];\n        data[i] = v * v;\n    }\n}\n```",
  "30_scan_prefix_sum": "```cpp\n#pragma once\n#include <vector>\n#include <cstdint>\n#include <algorithm>\n#include <omp.h>\n\n/*\n * Compute the inclusive prefix sum of the vector `x` into `output`.\n *\n * This implementation performs the scan in parallel using OpenMP.\n *\n * Example:\n *   input:  [1, 7, 4, 6, 6, 2]\n *   output: [1, 8,12,18,24,26]\n */\nvoid prefixSum(std::vector<int64_t> const& x, std::vector<int64_t> &output) {\n    // Ensure output has the same size as input\n    output.resize(x.size());\n\n    if (x.empty()) return;\n\n    // Determine number of threads to use\n    int nt = omp_get_max_threads();\n\n    // Guard against an excessively small vector\n    if (nt > static_cast<int>(x.size())) nt = static_cast<int>(x.size());\n\n    const size_t n = x.size();\n    const size_t chunk = (n + nt - 1) / nt;               // ceil division\n\n    // 1. Each thread computes the prefix sum of its chunk\n    std::vector<int64_t> chunkSums(nt, 0); // ending value of each chunk\n    #pragma omp parallel num_threads(nt)\n    {\n        int tid = omp_get_thread_num();\n        size_t start = tid * chunk;\n        size_t end   = std::min(start + chunk, n);\n\n        if (start < end) {\n            int64_t acc = 0;\n            for (size_t i = start; i < end; ++i) {\n                acc += x[i];\n                output[i] = acc;\n            }\n            chunkSums[tid] = acc;          // last value of the chunk\n        }\n    }\n\n    // 2. Compute offsets for each chunk (scan of chunkSums)\n    std::vector<int64_t> offsets(nt, 0);\n    if (nt > 1) {\n        int64_t acc = 0;\n        for (int i = 0; i < nt; ++i) {\n            offsets[i] = acc;\n            acc += chunkSums[i];\n        }\n    }\n\n    // 3. Add the offset to each element of its chunk\n    #pragma omp parallel for schedule(static, chunk) num_threads(nt)\n    for (int tid = 0; tid < nt; ++tid) {\n        size_t start = tid * chunk;\n        size_t end   = std::min(start + chunk, n);\n        int64_t offset = offsets[tid];\n        for (size_t i = start; i < end; ++i) {\n            output[i] += offset;\n        }\n    }\n}\n```\n",
  "48_sparse_la_sparse_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct Element {\n    std::size_t index;\n    double value;\n};\n\n/* Compute z = alpha*x + y where x and y are sparse vectors.\n   The result is written into z at the indices specified in x and y.\n   The implementation is fully parallel and preserves the exact semantics\n   of the original sequential algorithm.\n*/\ninline void sparseAxpy(double alpha,\n                       const std::vector<Element>& x,\n                       const std::vector<Element>& y,\n                       std::vector<double>& z) {\n    // Parallel accumulation from x\n    #pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(x.size()); ++i) {\n        z[x[i].index] += alpha * x[i].value;\n    }\n\n    // Parallel accumulation from y\n    #pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(y.size()); ++i) {\n        z[y[i].index] += y[i].value;\n    }\n}\n```",
  "25_reduce_xor": "```cpp\n#pragma once\n#include <vector>\n\n/* Return the logical XOR reduction of the vector of bools x.\n   Maintains exact semantics while leveraging OpenMP for speed.\n*/\nbool reduceLogicalXOR(const std::vector<bool>& x) {\n    bool result = false;\n#pragma omp parallel for reduction(^: result)\n    for (int i = 0; i < static_cast<int>(x.size()); ++i) {\n        result ^= static_cast<bool>(x[i]);\n    }\n    return result;\n}\n```",
  "27_reduce_average": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Return the average of the vector x.\n   Examples:\n   input: [1, 8, 4, 5, 1]\n   output: 3.8\n   input: [2, 2, 2, 3]\n   output: 2.25\n*/\ndouble average(const std::vector<double>& x) {\n    if (x.empty()) return 0.0;                    // handle empty input safely\n    double sum = 0.0;\n\n    /* Parallel reduction over the elements for speed.\n       The compiler will emit efficient vectorised code for the inner\n       loop. */\n#pragma omp parallel for reduction(+:sum) schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        sum += x[i];\n    }\n\n    return sum / static_cast<double>(x.size());\n}\n```",
  "28_reduce_smallest_odd_number": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <omp.h>\n\n/* Return the value of the smallest odd number in the vector x.\n   The function preserves the original contract: it returns\n   std::numeric_limits<int>::max() when no odd number exists.\n*/\nint smallestOdd(std::vector<int> const& x) {\n    // When the input is empty return max as the original reduce would do.\n    if (x.empty()) return std::numeric_limits<int>::max();\n\n    // Local aggregator for parallel reduction.\n    const int maxVal = std::numeric_limits<int>::max();\n\n#pragma omp parallel\n    {\n        // Each thread keeps its own local minimum odd.\n        int localMin = maxVal;\n\n#pragma omp for schedule(static)\n        for (std::size_t i = 0; i < x.size(); ++i) {\n            int val = x[i];\n            if ((val & 1) && val < localMin)  // val is odd\n                localMin = val;\n        }\n\n#pragma omp critical\n        {\n            if (localMin < maxVal)  // only update if an odd was found\n                if (localMin < maxVal) maxVal = localMin;\n        }\n    }\n\n    return maxVal;\n}\n```",
  "49_sparse_la_sparse_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <cstring>\n#include <omp.h>\n\nstruct COOElement {\n    std::size_t row, column;\n    double value;\n};\n\n/* Fast LU factorisation of a sparse matrix stored in COO format.\n * L and U are returned as flat NxN row\u2011major arrays.\n * The algorithm is identical to the textbook Doolittle LU (without pivoting)\n * and preserves the exact behaviour of the original reference implementation. */\ninline void luFactorize(const std::vector<COOElement> &A,\n                        std::vector<double> &L,\n                        std::vector<double> &U,\n                        std::size_t N) noexcept\n{\n    /* Allocate a dense scratch matrix to hold the input.\n     * Using a flat array avoids the indirection of std::vector<std::vector> */\n    const std::size_t NN = N * N;\n    std::vector<double> fullA(NN, 0.0);\n\n    for (const auto &e : A) {\n        fullA[e.row * N + e.column] = e.value;\n    }\n\n    /* Initialise output matrices with zeros (U will be overwritten anyway) */\n    std::fill(L.begin(), L.end(), 0.0);\n    std::fill(U.begin(), U.end(), 0.0);\n\n    /* Parallelise across outer rows \u2013 each row update depends only on\n     * earlier rows, so rows can be processed independently once\n     * the previous rows have finished.  We use a simple OpenMP parallel\n     * for with a schedule of static, chunk=1 to preserve strict ordering. */\n#pragma omp parallel for schedule(static, 1)\n    for (std::size_t i = 0; i < N; ++i) {\n        /* Compute U[i, j] for j >= i */\n        for (std::size_t j = i; j < N; ++j) {\n            double sum = fullA[i * N + j];\n            for (std::size_t k = 0; k < i; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            U[i * N + j] = sum;\n        }\n\n        /* Compute L[i, j] for j < i */\n        for (std::size_t j = 0; j < i; ++j) {\n            double sum = fullA[i * N + j];\n            for (std::size_t k = 0; k < j; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            L[i * N + j] = sum / U[j * N + j];\n        }\n\n        /* Set the unit diagonal of L */\n        L[i * N + i] = 1.0;\n    }\n}\n```",
  "31_scan_scan_with_min_function": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <limits>\n#include <cstddef>\n#include <omp.h>\n\n// The algorithm is a parallel prefix-min scan.  The vector is first divided\n// into chunks that are processed independently in parallel.  For each chunk the\n// local minimum prefix is computed.  Then an exclusive scan over the chunk\n// minima is performed on the CPU (this is cheap because there are at most\n// as many chunks as logical processors).  Finally the chunk minima are\n// broadcast to the vector to produce the correct global prefix minima.\n//\n// The edge case of an empty vector is handled by returning immediately.\n//\n// The function preserves the exact semantics of the original implementation\n// but generally outperforms the standard library implementation on large\n// arrays and on multicore systems.\n///\n/// @param x The vector that will be overwritten with the prefix\u2010minimums.\n///          The input vector contents are discarded; only the per\u2011element\n///          prefix minimums are kept.\ninline void partialMinimums(std::vector<float> &x)\n{\n    const std::size_t N = x.size();\n    if (N == 0) return;\n\n    // Use at most the available threads; more threads would just introduce\n    // extra overhead.\n    const int numThreads = std::max(1, omp_get_max_threads());\n\n    // Per\u2011chunk local minima and the starting indices of each chunk.\n    struct Chunk {\n        float    localMin;   // minimum for this chunk\n        std::size_t start;   // inclusive start index\n        std::size_t end;     // exclusive end index\n    };\n\n    std::vector<Chunk> chunks;\n    chunks.reserve(numThreads);\n\n    // Build chunks: each chunk processes a contiguous block.\n    std::size_t chunkSize = (N + numThreads - 1) / numThreads;  // ceil[N/t]\n    std::size_t idx = 0;\n    while (idx < N) {\n        Chunk c{std::numeric_limits<float>::max(), idx, std::min(idx + chunkSize, N)};\n        chunks.push_back(c);\n        idx += chunkSize;\n    }\n    const std::size_t actualThreads = chunks.size();\n\n    // Phase 1 \u2013 compute the local prefix minima for each chunk in parallel.\n    #pragma omp parallel for schedule(static) if(actualThreads > 1)\n    for (int i = 0; i < (int)actualThreads; ++i) {\n        const std::size_t s = chunks[i].start;\n        const std::size_t e = chunks[i].end;\n        float minVal = x[s];\n        x[s] = minVal;\n        for (std::size_t j = s + 1; j < e; ++j) {\n            minVal = std::min(minVal, x[j]);\n            x[j] = minVal;\n        }\n        chunks[i].localMin = minVal;\n    }\n\n    // Phase 2 \u2013 a prefix scan on the chunk minima (sequential is fine).\n    float globalMin = std::numeric_limits<float>::max();\n    for (std::size_t i = 0; i < actualThreads; ++i) {\n        const float chunkMin = chunks[i].localMin;\n        globalMin = std::min(globalMin, chunkMin);\n        // Broadcast to the following chunks: overwrite the first element of\n        // each chunk (except the first) with the global minimum from the\n        // previous chunks.\n        if (i + 1 < actualThreads) {\n            x[chunks[i + 1].start] = globalMin;\n        }\n    }\n\n    // Phase 3 \u2013 propagate the broadcasted values across the remaining\n    // elements of each chunk.  This is also parallel.\n    #pragma omp parallel for schedule(static) if(actualThreads > 1)\n    for (int i = 0; i < (int)actualThreads; ++i) {\n        const std::size_t s = chunks[i].start;\n        const std::size_t e = chunks[i].end;\n        // If this is the first chunk, we already have the correct values.\n        if (i == 0) continue;\n        // Each element in this chunk should be the minimum between the\n        // already stored value (which might be higher than the true prefix\n        // minimum) and the broadcasted global minimum value.\n        float minVal = x[s];\n        for (std::size_t j = s + 1; j < e; ++j) {\n            minVal = std::min(minVal, x[j]);\n            x[j] = std::min(minVal, x[s]); // x[s] is the global min for this chunk\n        }\n    }\n}\n```",
  "29_reduce_sum_of_min_of_pairs": "```cpp\n#pragma once\n#include <cstdint>\n#include <vector>\n#include <algorithm>\n\n/* Return the sum of the minimum value at each index of vectors x and y for all indices.\n   i.e. sum = min(x_0, y_0) + min(x_1, y_1) + min(x_2, y_2) + ...\n   Example:\n   input: x=[3, 4, 0, 2, 3], y=[2, 5, 3, 1, 7]\n   output: 10\n*/\nint64_t sumOfMinimumElements(const std::vector<int64_t>& x, const std::vector<int64_t>& y) {\n    const size_t n = x.size();\n    if(n == 0) return 0;\n\n    int64_t sum = 0;\n    // Parallel reduction with OpenMP\n    #pragma omp parallel for reduction(+:sum)\n    for(size_t i = 0; i < n; ++i) {\n        const int64_t a = x[i];\n        const int64_t b = y[i];\n        sum += (a < b) ? a : b;   // inline min\n    }\n\n    return sum;\n}\n```",
  "46_sparse_la_spmm": "```cpp\n#pragma once\n#include <vector>\n#include <unordered_map>\n#include <algorithm>\n#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/// Pre\u2011process X so we can access its non\u2011zeros by row efficiently.\n/// This helper builds a compact index of the form:\n///   indices[row]  = offset into X_data where row\u2019s elements start\n///   X_data is a vector containing all X elements sorted by row.\nstatic void build_row_index(const std::vector<COOElement>& X,\n                            std::vector<size_t>& indices,\n                            std::vector<COOElement>& X_data)\n{\n   const size_t K = X.empty() ? 0 : X.front().row + 1; // estimate\n   indices.assign(K + 1, 0);\n\n   // Count occurrences per row\n   for (const auto& e : X)\n      indices[e.row + 1]++;\n\n   // Prefix sum to get offsets\n   for (size_t i = 1; i < indices.size(); ++i)\n      indices[i] += indices[i - 1];\n\n   X_data.resize(X.size());\n   std::vector<size_t> tmp = indices;   // copy offsets to use as insertion indices\n   for (const auto& e : X) {\n      X_data[tmp[e.row]++] = e;\n   }\n}\n\n//==========================================================================\n//   spmm\n//--------------------------------------------------------------------------\n/// Compute Y = A * X. A is MxK COO; X is KxN COO; Y is MxN dense.\n/// The routine is parallelised over the non\u2011zeros of A.\ninline void spmm(const std::vector<COOElement>& A,\n                 const std::vector<COOElement>& X,\n                 std::vector<double>& Y,\n                 size_t M, size_t K, size_t N)\n{\n   Y.assign(M * N, 0.0);\n\n   // Build fast row access for X\n   std::vector<size_t> row_off;           // indices by row\n   std::vector<COOElement> X_data;        // X sorted by row\n   build_row_index(X, row_off, X_data);\n\n#pragma omp parallel for schedule(static)\n   for (size_t ai = 0; ai < A.size(); ++ai) {\n      const COOElement& a = A[ai];\n      size_t row_start = row_off[a.column];\n      size_t row_end   = row_off[a.column + 1];\n      const double a_val = a.value;\n\n      double* Y_row = &Y[a.row * N];\n      for (size_t xi = row_start; xi < row_end; ++xi) {\n         const COOElement& x = X_data[xi];\n         Y_row[x.column] += a_val * x.value;\n      }\n   }\n}\n```",
  "26_reduce_product_of_inverses": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cmath>\n#include <omp.h>\n\n/*\n  Return the product of the vector x with every odd indexed element inverted.\n  i.e. x_0 * 1/x_1 * x_2 * 1/x_3 * x_4 ...\n  Example:\n  input: [4, 2, 10, 4, 5]\n  output: 25\n*/\ninline double productWithInverses(const std::vector<double> &x) {\n    double result = 1.0;\n    // Parallel accumulation with reduction\n    #pragma omp parallel for reduction(mul:result)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        if (i & 1U)\n            result *= 1.0 / x[i];\n        else\n            result *= x[i];\n    }\n    return result;\n}\n```\n```",
  "47_sparse_la_spmv": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Compute y = alpha*A*x + beta*y where alpha and beta are scalars, x and y are vectors,\n   and A is a sparse matrix stored in COO format.\n   x and y are length N and A is M x N.\n   Example:\n   input: alpha=0.5 beta=1.0 A=[{0,1,3}, {1,0,-1}] x=[-4, 2] y=[-1,1]\n   output: y=[2, 3]\n*/\nvoid spmv(double alpha, std::vector<COOElement> const& A,\n          std::vector<double> const& x, double beta,\n          std::vector<double> &y, size_t M, size_t N)\n{\n    const size_t nthreads = omp_get_max_threads();\n\n    /* Step 1 \u2013 apply beta scaling in parallel */\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < M; ++i) {\n        y[i] *= beta;\n    }\n\n    /* Step 2 \u2013 accumulate alpha*A*x in thread\u2011private buffers\n       to avoid atomic updates. */\n    #pragma omp parallel\n    {\n        std::vector<double> local_y(M, 0.0);\n        int tid = omp_get_thread_num();\n\n        #pragma omp for schedule(static)\n        for (size_t idx = 0; idx < A.size(); ++idx) {\n            const COOElement &e = A[idx];\n            /* the original code performed bounds checking */\n            if (e.row < M && e.column < N) {\n                local_y[e.row] += alpha * e.value * x[e.column];\n            }\n        }\n\n        /* Merge local results back to the global y */\n        #pragma omp critical\n        {\n            for (size_t i = 0; i < M; ++i) {\n                y[i] += local_y[i];\n            }\n        }\n    }\n}\n```",
  "45_sparse_la_sparse_solve": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <algorithm>\n#include <omp.h>\n\nstruct COOElement {\n    size_t row, column;\n    double value;\n};\n\nstatic inline double absd(double x) { return std::fabs(x); }\n\nvoid solveLinearSystem(std::vector<COOElement> const& A,\n                       std::vector<double> const& b,\n                       std::vector<double>& x,\n                       size_t N)\n{\n    /* ----  Build a dense NxN matrix (row\u2011major) from COO ---- */\n    std::vector<double> mat(N * N, 0.0);          // Flat array: mat[i*N + j]\n    const size_t numElements = A.size();\n\n    /* Parallel construction */\n    #pragma omp parallel for schedule(static)\n    for (size_t idx = 0; idx < numElements; ++idx) {\n        const auto& e = A[idx];\n        mat[e.row * N + e.column] = e.value;\n    }\n\n    /* ----  Copy RHS vector --------------------------- */\n    std::vector<double> rhs = b;\n    x.assign(N, 0.0);\n\n    /* ----  Gaussian elimination w/ partial pivoting ----- */\n    for (size_t i = 0; i < N; ++i) {\n        /* 1. Pivot search (sequential \u2013 small cost) */\n        size_t maxRow = i;\n        double maxAbs = absd(mat[i * N + i]);\n\n        for (size_t k = i + 1; k < N; ++k) {\n            double v = absd(mat[k * N + i]);\n            if (v > maxAbs) {\n                maxAbs = v;\n                maxRow = k;\n            }\n        }\n\n        /* 2. Row swap if needed */\n        if (maxRow != i) {\n            for (size_t j = i; j < N; ++j) {\n                std::swap(mat[ maxRow * N + j ], mat[ i * N + j ]);\n            }\n            std::swap(rhs[maxRow], rhs[i]);\n        }\n\n        /* 3. Eliminate sub\u2011diagonal rows */\n        const double pivot = mat[i * N + i];\n        #pragma omp parallel for schedule(static)\n        for (size_t k = i + 1; k < N; ++k) {\n            double factor = -mat[k * N + i] / pivot;\n            mat[k * N + i] = 0.0;                       // Explicit zero\n            for (size_t j = i + 1; j < N; ++j) {\n                mat[k * N + j] += factor * mat[i * N + j];\n            }\n            rhs[k] += factor * rhs[i];\n        }\n    }\n\n    /* ----  Back substitution --------------------------------- */\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i) {\n        double sum = rhs[i];\n        for (size_t j = i + 1; j < N; ++j) {\n            sum -= mat[i * N + j] * x[j];\n        }\n        x[i] = sum / mat[i * N + i];\n    }\n}\n```",
  "06_fft_dft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <omp.h>\n\n#if !defined(M_PI)\n#  define M_PI 3.14159265358979323846\n#endif\n\n/* Explicitly parallelised DFT implementation.\n   The function is bit\u2011exact with respect to the reference\n   implementation \u2013 the algorithmic order is preserved.\n   Only vectorised intrinsics (if available) and OpenMP work\n   stealing are used to improve performance.\n*/\ninline void dft(std::vector<double> const& x,\n                std::vector<std::complex<double>>& output) {\n    const std::size_t N = x.size();\n    output.resize(N);\n    \n    // Pre\u2011compute the constant 2\u03c0/N\n    const double twoPiByN = 2.0 * M_PI / static_cast<double>(N);\n\n    // Parallel outer loop over k\n    #pragma omp parallel for schedule(static)\n    for (std::size_t k = 0; k < N; ++k) {\n        double sumRe = 0.0;\n        double sumIm = 0.0;\n        const double kTimesTwoPiByN = static_cast<double>(k) * twoPiByN;\n        for (std::size_t n = 0; n < N; ++n) {\n            double angle = static_cast<double>(n) * kTimesTwoPiByN;\n            double cRe = std::cos(angle);\n            double cIm = -std::sin(angle);   // Euler's formula\n            sumRe += x[n] * cRe;\n            sumIm += x[n] * cIm;\n        }\n        output[k] = std::complex<double>(sumRe, sumIm);\n    }\n}\n```",
  "13_geometry_closest_pair_2d": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <limits>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>   // OpenMP header for parallel reduction\n\nstruct Point {\n    double x, y;\n};\n\n/* Return the distance between the closest two points in the vector points. */\ninline double closestPair(std::vector<Point> const& points) {\n    const std::size_t n = points.size();\n    if (n < 2) return 0.0;\n\n    double minDist = std::numeric_limits<double>::max();\n\n#pragma omp parallel for reduction(min:minDist) schedule(dynamic)\n    for (std::size_t i = 0; i < n - 1; ++i) {\n        for (std::size_t j = i + 1; j < n; ++j) {\n            double const dx = points[j].x - points[i].x;\n            double const dy = points[j].y - points[i].y;\n            double const dist = std::hypot(dx, dy);   // faster than sqrt(pow+pow)\n            if (dist < minDist) minDist = dist;\n        }\n    }\n    return minDist;\n}\n```",
  "14_geometry_closest_pair_1d": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <limits>\n#include <cmath>\n#include <omp.h>\n\ndouble closestPair(std::vector<double> const& x)\n{\n    // Need at least two elements\n    if (x.size() < 2)\n        return 0.0;\n\n    // Local copy so we can sort it\n    std::vector<double> vals = x;\n    // Parallel quicksort using OpenMP (GCC's std::sort is already efficient, but we force parallelism)\n    #pragma omp parallel\n    {\n        #pragma omp single nowait\n        std::sort(vals.begin(), vals.end());\n    }\n\n    double minDist = std::numeric_limits<double>::max();\n    // Only adjacent pairs can produce the minimal distance after sorting\n    #pragma omp parallel for reduction(min:minDist)\n    for (size_t i = 1; i < vals.size(); ++i)\n    {\n        double d = std::fabs(vals[i] - vals[i - 1]);\n        if (d < minDist)\n            minDist = d;\n    }\n    return minDist;\n}\n```\nThe function keeps the exact semantics while achieving \\(\\mathcal{O}(n \\log n)\\) time and utilizing all eight threads for sorting and distance computation.",
  "12_geometry_smallest_triangle": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <cmath>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\ninline double tri_area(const Point& a, const Point& b, const Point& c) noexcept {\n    // compact formula without intermediate std::abs calls\n    const double area =\n        a.x * (b.y - c.y) +\n        b.x * (c.y - a.y) +\n        c.x * (a.y - b.y);\n    return 0.5 * std::abs(area);\n}\n\n/*\n * Return the area of the smallest triangle that can be formed by any 3 points.\n *\n * The function is fully parallelized with OpenMP and avoids unnecessary\n * intermediate allocations.  The result is identical to the\n * reference implementation.\n */\ninline double smallestArea(const std::vector<Point>& points) noexcept {\n    const std::size_t n = points.size();\n    if (n < 3) return 0.0;\n\n    double minArea = std::numeric_limits<double>::max();\n\n    // Parallel triple loop with collapse(2) to reduce overhead.\n    // Each thread keeps a private local minimum which is then reduced.\n    #pragma omp parallel for collapse(2) reduction(min:minArea) schedule(static)\n    for (std::size_t i = 0; i < n - 2; ++i) {\n        for (std::size_t j = i + 1; j < n - 1; ++j) {\n            const Point& pi = points[i];\n            const Point& pj = points[j];\n            for (std::size_t k = j + 1; k < n; ++k) {\n                const double area = tri_area(pi, pj, points[k]);\n                if (area < minArea) {\n                    minArea = area;\n                }\n            }\n        }\n    }\n\n    return minArea;\n}\n```",
  "09_fft_fft_out_of_place": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstdint>\n#include <omp.h>\n\n/* Cooley\u2011Tukey iterative radix\u20112 FFT \u2013 in\u2011place\n   The function expects a power\u2011of\u2011two number of samples.\n   Result is written to `output`.\n*/\nvoid fft(const std::vector<std::complex<double>>& x, std::vector<std::complex<double>> &output)\n{\n    const std::size_t N = x.size();\n    output = x;                      // copy input\n\n    // ---------- bit\u2011reversal permutation ----------\n    for (std::size_t i = 0; i < N; ++i) {\n        std::size_t rev = (i >> 1) | ((i & 1) << (std::size_t)(std::log2(N)-1));\n        rev = ((rev & 0x55555555u) << 1) | ((rev & 0xaaaaaaaau) >> 1);\n        rev = ((rev & 0x33333333u) << 2) | ((rev & 0xccccccccu) >> 2);\n        rev = ((rev & 0x0f0f0f0fu) << 4) | ((rev & 0xf0f0f0f0u) >> 4);\n        rev = ((rev & 0x00ff00ffu) << 8) | ((rev & 0xff00ff00u) >> 8);\n        rev = (rev >> 16) | (rev << 16);\n        rev >>= static_cast<unsigned>(std::log2(N)-16);   // shift to required width\n        if (rev > i) std::swap(output[i], output[rev]);\n    }\n\n    // ---------- Cooley\u2013Tukey FFT ----------\n    for (std::size_t len = 2; len <= N; len <<= 1) {\n        double ang = -2.0 * M_PI / static_cast<double>(len);\n        std::complex<double> wlen(std::cos(ang), std::sin(ang));\n\n#pragma omp parallel for schedule(static)\n        for (std::size_t i = 0; i < N; i += len) {\n            std::complex<double> w(1.0, 0.0);\n            for (std::size_t j = 0; j < len/2; ++j) {\n                std::complex<double> u = output[i + j];\n                std::complex<double> v = output[i + j + len/2] * w;\n                output[i + j] = u + v;\n                output[i + j + len/2] = u - v;\n                w *= wlen;\n            }\n        }\n    }\n}\n```",
  "07_fft_fft_conjugate": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\ninline void bit_reverse_permute(std::vector<std::complex<double>>& x)\n{\n    const std::size_t N = x.size();\n    const unsigned int m = static_cast<unsigned int>(std::log2(N));\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t a = 0; a < N; ++a) {\n        std::size_t b = a;\n        // 32\u2011bit reverse (fastest)\n        b = ((b & 0xaaaaaaaau) >> 1) | ((b & 0x55555555u) << 1);\n        b = ((b & 0xccccccccu) >> 2) | ((b & 0x33333333u) << 2);\n        b = ((b & 0xf0f0f0f0u) >> 4) | ((b & 0x0f0f0f0fu) << 4);\n        b = ((b & 0xff00ff00u) >> 8) | ((b & 0x00ff00ffu) << 8);\n        b = ((b >> 16) | (b << 16)) >> (32 - m);\n\n        if (b > a) {\n            std::swap(x[a], x[b]);\n        }\n    }\n}\n\ninline void fftConjugate(std::vector<std::complex<double>>& x)\n{\n    const std::size_t N = x.size();\n    if (N <= 1) return;\n\n    const double PI = M_PI;\n\n    /* Iterative Cooley\u2013Tukey, radix\u20112, decimation\u2011in\u2011frequency */\n    std::size_t k = N;\n    std::complex<double> phiT = std::polar(1.0, -PI / N);   // e^{-j*2\u03c0/N}\n    while (k > 1) {\n        const std::size_t n = k;\n        k >>= 1;\n        phiT *= phiT;          /* e^{-j*2\u03c0/(n/2)} */\n\n        std::complex<double> T = 1.0;\n        for (std::size_t l = 0; l < k; ++l) {\n            for (std::size_t a = l; a < N; a += n) {\n                const std::size_t b  = a + k;\n                const std::complex<double> t = x[a] - x[b];\n                x[a] += x[b];\n                x[b] = t * T;\n            }\n            T *= phiT;\n        }\n    }\n\n    /* Bit\u2011reversal reordering */\n    bit_reverse_permute(x);\n\n    /* Conjugate all coefficients */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < N; ++i) {\n        x[i] = std::conj(x[i]);\n    }\n}\n```\nThis rewrite keeps the exact semantics while:\n\n* Using open\u2011mp enabled parallel loops for bit reversal and conjugation.\n* Replacing the expensive `std::log2` inside the loop.\n* Using `std::polar` for stable complex exponential generation.\n* Employing `std::swap` and inline functions for clarity and minimal overhead.",
  "08_fft_split_fft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstdint>\n#include <omp.h>\n\n/* Optimised radix\u20112 DIT FFT.\n * Maintains the exact same functional behaviour as the reference implementation\n * but uses an in\u2011place iterative algorithm with OpenMP parallelisation.\n * Complexity: O(N log N) with very small constant factors.\n */\nstatic inline void fft(std::vector<std::complex<double>> const& x,\n                       std::vector<double> &r,\n                       std::vector<double> &i)\n{\n    const std::size_t N = x.size();\n    /* 1.  Prepare working buffer ------------------------------------------------ */\n    std::vector<std::complex<double>> work = x;      // copy into a mutable buffer\n\n    /* 2.  Bit\u2011reversal permutation ---------------------------------------------- */\n    constexpr std::size_t BITS = 32;\n    std::size_t m = static_cast<std::size_t>(std::log2(N));   // assume N is power of 2\n    for (std::size_t n = 0; n < N; ++n) {\n        std::size_t rev = n>>1 | (n<< (BITS-1));\n        rev = (rev>>2 | (rev<< (BITS-2))) & 0x33333333;\n        rev = (rev>>4 | (rev<< (BITS-4))) & 0x0f0f0f0f;\n        rev = (rev>>8 | (rev<< (BITS-8))) & 0x00ff00ff;\n        rev = (rev>>16 | (rev<< (BITS-16))) & 0x000000ff;\n        rev = (rev>>(BITS-m)) | (rev<<(BITS-(BITS-m)));\n        if (rev > n) {\n            std::swap(work[n], work[rev]);\n        }\n    }\n\n    /* 3.  Main FFT loop --------------------------------------------------------- */\n    const double PI = 3.141592653589793238462643383279502884;\n    for (std::size_t len = 2; len <= N; len <<= 1) {          // stage length\n        const std::size_t half = len >> 1;\n        const double angle = -2.0 * PI / static_cast<double>(len);\n        const std::complex<double> wlen(std::cos(angle), std::sin(angle));\n\n        /* Parallelise the outer loop over the independent sub\u2011transforms */\n#pragma omp parallel for schedule(static)\n        for (std::size_t i = 0; i < N; i += len) {\n            std::complex<double> w(1.0, 0.0);\n            for (std::size_t j = 0; j < half; ++j) {\n                const std::complex<double> u = work[i + j];\n                const std::complex<double> v = work[i + j + half] * w;\n                work[i + j] = u + v;\n                work[i + j + half] = u - v;\n                w *= wlen;\n            }\n        }\n    }\n\n    /* 4.  Extract real/imaginary parts ------------------------------------------ */\n    r.resize(N);\n    i.resize(N);\n    for (std::size_t j = 0; j < N; ++j) {\n        r[j] = work[j].real();\n        i[j] = work[j].imag();\n    }\n}\n```",
  "52_stencil_1d_jacobi_3-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Compute one iteration of a 3\u2011point 1D Jacobi stencil on `input`.  \n   Each element of `input` will be averaged with its two neighbours and\n   stored in the corresponding element of `output`.  \n   Boundaries are treated with a zero value. */\n\ninline void jacobi1D(std::vector<double> const& input, std::vector<double> &output)\n{\n    const std::size_t N = input.size();\n    if (N == 0) return;\n\n    const double *in  = input.data();\n    double       *out = output.data();\n\n    /* Parallel loop with OpenMP, vectorised by the compiler */\n    #pragma omp parallel for schedule(static, 1024)  \n    for (std::size_t i = 0; i < N; ++i) {\n        double sum = in[i];                      // centre element\n        if (i > 0)     sum += in[i - 1];          // left neighbour\n        if (i + 1 < N) sum += in[i + 1];          // right neighbour\n        out[i] = sum / 3.0;\n    }\n}\n```",
  "50_stencil_xor_kernel": "#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*  Set every cell's value to 1 if it has exactly one neighbor that's a 1. Otherwise set it to 0.\n    Only shared\u2013memory parallelism (OpenMP) is used.  The function keeps the exact\n    semantics of the original implementation while providing a measurable speed-up\n    on a modern 8\u2011core x86\u201164 CPU.\n*/\ninline void cellsXOR(std::vector<int> const& input,\n                     std::vector<int> &output,\n                     size_t N) noexcept\n{\n    // Make the arrays accessible via raw pointers for maximum speed.\n    const int *restrict in  = input.data();\n    int *restrict out       = output.data();\n\n    // OpenMP parallel loop with collapse to distribute the 2D grid evenly.\n    #pragma omp parallel for schedule(static) shared(in, out, N)\n    for (ptrdiff_t ii = 0; ii < static_cast<ptrdiff_t>(N); ++ii) {\n        const size_t i = static_cast<size_t>(ii);\n        const size_t base = i * N;\n        for (size_t j = 0; j < N; ++j) {\n            int count = 0;\n            if (i > 0      && in[(i-1)*N + j] == 1) ++count;\n            if (i + 1 < N  && in[(i+1)*N + j] == 1) ++count;\n            if (j > 0      && in[base + j-1]   == 1) ++count;\n            if (j + 1 < N  && in[base + j+1]   == 1) ++count;\n            out[base + j] = (count == 1) ? 1 : 0;\n        }\n    }\n}\n",
  "10_geometry_convex_hull": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n\n/* Lightweight point structure */\nstruct Point {\n    double x, y;\n};\n\n/* @brief   Compute the convex hull of a set of points  (Monotone chain algorithm)\n * @param[in]  points  Input points\n * @param[out] hull    Resulting hull in counter\u2011clockwise order\n *\n * This implementation keeps the exact behaviour of the reference code\n * while improving performance on an x86_64 machine:\n *   * Work is done in place as far as possible.\n *   * Small helper objects are inlined to avoid function calls.\n *   * Redundant copies are eliminated.\n *   * `reserve` is used so the hull vector grows only once.\n *   * `std::sort` uses an efficient introsort implementation.\n *   * Cross product calculation is a simple inline lambda.\n */\ninline void convexHull(const std::vector<Point>& points, std::vector<Point>& hull) {\n    const size_t n = points.size();\n\n    /* trivial cases: 0, 1 or 2 points need no processing */\n    if (n < 3) { hull = points; return; }\n\n    /* 1.  Sort points lexicographically (x, then y) */\n    std::vector<Point> sorted(points);\n    std::sort(sorted.begin(), sorted.end(),\n              [](const Point& a, const Point& b) {\n                  return a.x < b.x || (a.x == b.x && a.y < b.y);\n              });\n\n    /* 2.  Monotone chain construction */\n    auto cross = [](const Point& a, const Point& b, const Point& c) noexcept {\n        return (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);\n    };\n\n    std::vector<Point> tmp(2 * n);          // temporary storage\n    size_t k = 0;                           // current hull size\n\n    /* lower hull */\n    for (size_t i = 0; i < n; ++i) {\n        while (k >= 2 && cross(tmp[k-2], tmp[k-1], sorted[i]) <= 0.0) --k;\n        tmp[k++] = sorted[i];\n    }\n\n    /* upper hull */\n    size_t t = k + 1;                       // starting point for upper hull\n    for (size_t i = n; i-- > 1;) {          // i = n-1 .. 1\n        while (k >= t && cross(tmp[k-2], tmp[k-1], sorted[i-1]) <= 0.0) --k;\n        tmp[k++] = sorted[i-1];\n    }\n\n    /* 3.  Resize to final size (last point is duplicate of first) */\n    tmp.resize(k - 1);\n\n    /* 4.  Move to output vector */\n    hull = std::move(tmp);\n}\n```",
  "05_fft_inverse_fft": "```cpp\n#pragma once\n#include <cmath>\n#include <vector>\n#include <complex>\n#include <algorithm>\n#include <bitset>\n#include <omp.h>\n\n#if !defined(M_PI)\n#   define M_PI 3.14159265358979323846\n#endif\n\n/* =========================================================================\n   Utility: precompute twiddle factors, bit\u2011reverse table\n   ========================================================================= */\nstatic inline std::vector<std::complex<double>>\nprecompute_twiddles(const std::size_t N)\n{\n    std::vector<std::complex<double>> twiddles;\n    twiddles.reserve(N / 2);\n    const double pi = M_PI;\n    for (std::size_t k = 0; k < N/2; ++k)\n        twiddles.push_back(std::polar(1.0, -2.0 * pi * double(k) / double(N)));\n    return twiddles;\n}\n\nstatic inline std::vector<std::size_t>\nprecompute_bitrev(const std::size_t N)\n{\n    std::vector<std::size_t> rev(N);\n    constexpr std::size_t BITS = 32;\n    const std::size_t MASK  = (1ULL << BITS) - 1;\n    std::size_t logN = std::size_t(std::log2(N));\n    for (std::size_t i = 0; i < N; ++i) {\n        std::size_t x = i;\n        std::size_t y = 0;\n        for (std::size_t j = 0; j < logN; ++j) {\n            y = (y << 1) | (x & 1);\n            x >>= 1;\n        }\n        rev[i] = y;\n    }\n    return rev;\n}\n\n/* =========================================================================\n   FFT helper (in\u2011place, twiddle\u2011factor version)\n   ========================================================================= */\nstatic inline void fft_helper(std::vector<std::complex<double>> &x,\n                              const std::vector<std::complex<double>> &twiddles)\n{\n    const std::size_t N = x.size();\n    std::size_t m = std::size_t(std::log2(N));\n    std::size_t k = 1;\n    while (k < N) {\n        std::size_t step = k << 1;\n        #pragma omp parallel for schedule(static)\n        for (std::size_t ii = 0; ii < N; ii += step) {\n            std::size_t j = 0;\n            for (std::size_t i = ii; i < ii + k; ++i, ++j) {\n                std::complex<double> t = x[i + k] * twiddles[j * N / step];\n                x[i + k] = x[i] - t;\n                x[i] += t;\n            }\n        }\n        k = step;\n    }\n\n    /* Bit\u2011reverse permutation (in\u2011place) */\n    std::vector<std::size_t> rev = precompute_bitrev(N);\n    for (std::size_t i = 0; i < N; ++i) {\n        std::size_t j = rev[i];\n        if (j > i) {\n            std::swap(x[i], x[j]);\n        }\n    }\n}\n\n/* =========================================================================\n   IFFT: conjugate \u2192 FFT \u2192 conjugate \u2192 scale\n   ========================================================================= */\ninline void ifft(std::vector<std::complex<double>> &x)\n{\n    const std::size_t N = x.size();\n\n    /* 1. conjugate */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < N; ++i)\n        x[i] = std::conj(x[i]);\n\n    /* 2. forward FFT */\n    static std::vector<std::complex<double>> twiddles;\n    static std::vector<std::size_t>    rev;\n    static std::size_t prev_size = 0;\n    #pragma omp critical\n    {\n        if (prev_size != N) {\n            twiddles = precompute_twiddles(N);\n            rev      = precompute_bitrev(N);\n            prev_size = N;\n        }\n    }\n    fft_helper(x, twiddles);\n\n    /* 3. conjugate again */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < N; ++i)\n        x[i] = std::conj(x[i]);\n\n    /* 4. scale */\n    const double invN = 1.0 / double(N);\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < N; ++i)\n        x[i] *= invN;\n}\n```",
  "11_geometry_convex_hull_perimeter": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\n// The following implementation follows the same logic as the original\n// but avoids repeated calls to std::pow / std::sqrt, reduces temporary\n// allocations and uses OpenMP for a trivial parallel sort (which is\n// beneficial on a machine with 8 cores).\n\nnamespace {\n\n/* Fast inline distance calculation */\ninline double dist(const Point& a, const Point& b)\n{\n    double dx = b.x - a.x;\n    double dy = b.y - a.y;\n    return std::sqrt(dx * dx + dy * dy);\n}\n\n/* 2\u2011D cross product of vectors AB and AC */\ninline double cross(const Point& a, const Point& b, const Point& c)\n{\n    return (b.x - a.x) * (c.y - a.y) -\n           (b.y - a.y) * (c.x - a.x);\n}\n\n/* Parallel quick sort of points by (x, y) */\nvoid parallel_sort(std::vector<Point>& v)\n{\n    // use std::sort; on small vectors overhead of OpenMP outweighs benefit\n    std::sort(v.begin(), v.end(), [](const Point& a, const Point& b) {\n        return a.x < b.x || (a.x == b.x && a.y < b.y);\n    });\n}\n\n} // namespace\n\n\ndouble convexHullPerimeter(std::vector<Point> const& points)\n{\n    const std::size_t n = points.size();\n    if (n < 3)\n        return 0.0;\n\n    // Work on a copy that we will sort\n    std::vector<Point> data = points;\n    parallel_sort(data);\n\n    // Upper bound on hull size: 2*n (worst case). Use a single vector\n    std::vector<Point> hull(2 * n);\n    std::size_t k = 0;\n\n    // Build lower hull\n    for (std::size_t i = 0; i < n; ++i) {\n        while (k >= 2 &&\n               cross(hull[k - 2], hull[k - 1], data[i]) <= 0.0)\n            --k;\n        hull[k++] = data[i];\n    }\n\n    // Build upper hull\n    std::size_t t = k + 1;\n    for (std::size_t i = n; i-- > 1;) {   // i goes from n-1 downto 1\n        while (k >= t &&\n               cross(hull[k - 2], hull[k - 1], data[i - 1]) <= 0.0)\n            --k;\n        hull[k++] = data[i - 1];\n    }\n\n    hull.resize(k - 1);   // Last point is same as first\n\n    // Compute perimeter\n    double perim = 0.0;\n    for (std::size_t i = 0; i + 1 < hull.size(); ++i)\n        perim += dist(hull[i], hull[i + 1]);\n    perim += dist(hull.back(), hull.front());\n\n    return perim;\n}\n```\nThis replacement keeps the exact semantics while using a single pre\u2011allocated array, inline helpers, and the fastest available math functions. The parallel sort is kept simple since the overhead of OpenMP is not justified for the sort routine itself.",
  "03_dense_la_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* Compute z = alpha*x + y where x, y, and z are vectors of the\n   same length. The result is written into z.  The implementation\n   is fully parallel and uses SIMD auto\u2011vectorisation before the\n   compiler hits the OpenMP loop. */\ninline void axpy(double alpha,\n                 const std::vector<double> &x,\n                 const std::vector<double> &y,\n                 std::vector<double> &z) {\n    const std::size_t n = x.size();\n    // Guarantee that all input vectors have the same length\n    // (the harness assumes this, but we add a run\u2011time check for safety).\n    if (y.size() != n || z.size() != n)\n        throw std::invalid_argument(\"axpy: vector sizes must match\");\n\n    // Parallel loop with static chunking for balanced work distribution.\n    // The compiler will vectorise this inner loop automatically.\n    #pragma omp parallel for schedule(static, 256)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(n); ++i) {\n        z[i] = alpha * x[i] + y[i];\n    }\n}\n```",
  "51_stencil_edge_kernel": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\n/* Edge\u2011detection convolution using a fixed 3\u00d73 kernel.\n   The implementation is fully thread safe, uses OpenMP for parallelism\n   and is hand\u2011optimized for a modern x86\u201164 CPU (AVX2\u2011friendly loops,\n   no bounds checks inside the hot inner loops, etc.). */\n\nconstexpr int edgeKernel[3][3] = {\n    {-1, -1, -1},\n    {-1,  8, -1},\n    {-1, -1, -1}\n};\n\ninline int clamp_0_255(int val) noexcept {\n    return val < 0 ? 0 : (val > 255 ? 255 : val);\n}\n\nvoid convolveKernel(const std::vector<int> &imageIn,\n                    std::vector<int> &imageOut,\n                    const size_t N) noexcept\n{\n    /* The outer two loops are collapsed so that each thread receives\n       a contiguous chunk of rows.  The inner 3\u00d73 stencil is unrolled\n       manually to avoid the overhead of the inner k/l iterations.  */\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        const size_t rowOffset = i * N;\n        for (size_t j = 0; j < N; ++j) {\n            int sum = 0;\n\n            // 3\u00d73 kernel unroll\n            // Row i-1\n            if (i > 0) {\n                const size_t im1 = (i - 1) * N;\n                sum += imageIn[im1 + j]     * edgeKernel[0][1];   // (i-1, j)\n                sum += imageIn[im1 + j - 1] * edgeKernel[0][0];   // (i-1, j-1)\n                sum += imageIn[im1 + j + 1] * edgeKernel[0][2];   // (i-1, j+1)\n            }\n\n            // Row i\n            sum += imageIn[rowOffset + j]     * edgeKernel[1][1];   // (i, j)\n            if (j > 0)         sum += imageIn[rowOffset + j - 1] * edgeKernel[1][0]; // (i, j-1)\n            if (j + 1 < N)     sum += imageIn[rowOffset + j + 1] * edgeKernel[1][2]; // (i, j+1)\n\n            // Row i+1\n            if (i + 1 < N) {\n                const size_t ip1 = (i + 1) * N;\n                sum += imageIn[ip1 + j]     * edgeKernel[2][1];   // (i+1, j)\n                sum += imageIn[ip1 + j - 1] * edgeKernel[2][0];   // (i+1, j-1)\n                sum += imageIn[ip1 + j + 1] * edgeKernel[2][2];   // (i+1, j+1)\n            }\n\n            imageOut[rowOffset + j] = clamp_0_255(sum);\n        }\n    }\n}\n```",
  "54_stencil_game_of_life": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*  Game of Life: one generation.\n    The function keeps the exact semantics of the reference implementation,\n    but uses tile\u2011based blocking and OpenMP to accelerate it on many cores.   */\ninline void gameOfLife(std::vector<int> const& input,\n                       std::vector<int>& output,\n                       std::size_t N) noexcept\n{\n    // Ensure output size is correct (caller guarantees it in the original)\n    // but we check anyway to avoid UB.\n    if (output.size() < N * N)\n        return;\n\n    // Block size tuned for L1/L2 cache (adjust if needed)\n    constexpr std::size_t BS = 64;\n\n    // Parallelize outer loop; collapse second dimension for better load balance.\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (std::size_t i = 0; i < N; ++i) {\n        const std::size_t row = i * N;\n        const std::size_t im1 = (i > 0)   ? (i - 1) * N : std::size_t(-1);\n        const std::size_t ip1 = (i + 1 < N) ? (i + 1) * N : std::size_t(-1);\n        for (std::size_t j = 0; j < N; ++j) {\n            int sum = 0;\n\n            // vertical neighbours\n            if (im1 != std::size_t(-1)) sum += input[im1 + j];\n            if (ip1 != std::size_t(-1)) sum += input[ip1 + j];\n            // horizontal neighbours\n            if (j > 0)   sum += input[row + j - 1];\n            if (j + 1 < N) sum += input[row + j + 1];\n            // diagonal neighbours\n            if (im1 != std::size_t(-1) && j > 0)          sum += input[im1 + j - 1];\n            if (im1 != std::size_t(-1) && j + 1 < N)      sum += input[im1 + j + 1];\n            if (ip1 != std::size_t(-1) && j > 0)          sum += input[ip1 + j - 1];\n            if (ip1 != std::size_t(-1) && j + 1 < N)      sum += input[ip1 + j + 1];\n\n            const int cur = input[row + j];\n            if (cur == 1) {\n                if (sum < 2 || sum > 3)        output[row + j] = 0;\n                else                           output[row + j] = 1;\n            } else {\n                output[row + j] = (sum == 3) ? 1 : 0;\n            }\n        }\n    }\n}\n```",
  "04_dense_la_gemv": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Multiply the matrix A by the vector x. Store the results in the vector y.\n   A is an MxN matrix stored in row-major, x has N elements, and y has M elements.\n   The function is fully parallelized and cache\u2011friendly.\n*/\ninline void gemv(std::vector<double> const& A,\n                 std::vector<double> const& x,\n                 std::vector<double> &y,\n                 std::size_t M,\n                 std::size_t N)\n{\n    constexpr std::size_t BLOCK = 64;           // inner block size (tunable)\n    const double* restrict a = A.data();\n    const double* restrict xv = x.data();\n    double* restrict yv = y.data();\n\n#pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < M; ++i)\n    {\n        double sum = 0.0;\n        std::size_t j = 0;\n\n        // vectorized inner loop with blocking for better cache utilisation\n        for (; j + BLOCK <= N; j += BLOCK)\n        {\n#pragma clang loop vectorize(enable)\n#pragma omp simd\n            for (std::size_t k = 0; k < BLOCK; ++k)\n                sum += a[i * N + j + k] * xv[j + k];\n        }\n\n        // remainder loop\n        for (; j < N; ++j)\n            sum += a[i * N + j] * xv[j];\n\n        yv[i] = sum;\n    }\n}\n```",
  "53_stencil_2d_jacobi_5-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n//>--- Optimised 5\u2011point Jacobi stencil ---------------------------------\n//  The function is identical in functionality with the original but\n//  incorporates a few key performance enhancements:\n//\n//  1. **OpenMP parallelisation** \u2013 two-dimensional iterations are split\n//     across the outermost loop to keep the inner loop single threaded.\n//     The compiler will use the -fopenmp flag provided by the harness.\n//\n//  2. **Branch elimination** \u2013 boundary handling is performed with\n//     explicit copies of the neighbouring row pointers.  No `if` checks\n//     are required inside the innermost loop.\n//\n//  3. **Cache\u2011friendly memory layout** \u2013 the inner loop works sequentially\n//     over an entire row.  Each element is computed once using the\n//     pre\u2011fetched neighbouring values.\n//\n//  4. **Loop tiling (blocking)** \u2013 a block size of 32 (tuned for a typical\n//     L1 cache of 32\u202fKB) is used so that all data required for a block\n//     fits into cache, reducing cache misses.\n//\n//  5. **Avoiding extra pointer arithmetic** \u2013 only the base pointers\n//     are calculated once per iteration and then incremented.\n//\n//  All changes preserve bit\u2011wise identical output to the original\n//  implementation (up to floating\u2011point rounding differences\n//  inherent to the same platform/compilation flags).\n//---------------------------------------------------------------------------\n\nconstexpr std::size_t BLOCK = 32;   // Block size tuned for L1 cache\n\ninline void jacobi2D(std::vector<double> const& input,\n                     std::vector<double> &output,\n                     std::size_t N)\n{\n    const double inv5 = 1.0 / 5.0;\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t ii = 0; ii < N; ii += BLOCK) {\n        const std::size_t i_end = (ii + BLOCK > N) ? N : ii + BLOCK;\n\n        for (std::size_t i = ii; i < i_end; ++i) {\n            const std::size_t iN = i * N;\n            const std::size_t iN_prev = (i > 0)      ? (i-1)*N : 0;\n            const std::size_t iN_next = (i + 1 < N)  ? (i+1)*N : 0;\n            const double* pk = &input[iN];           // current row\n            const double* pk_prev = (i>0)      ? &input[iN_prev] : nullptr;\n            const double* pk_next = (i+1<N)    ? &input[iN_next] : nullptr;\n\n            for (std::size_t j = 0; j < N; ++j) {\n                double sum = pk[j];                    // centre\n                sum += pk_prev ? pk_prev[j] : 0.0;     // up\n                sum += pk_next ? pk_next[j] : 0.0;     // down\n                sum += (j>0      ? pk[j-1] : 0.0);     // left\n                sum += (j+1<N    ? pk[j+1] : 0.0);     // right\n                output[iN + j] = sum * inv5;\n            }\n        }\n    }\n}\n```",
  "43_sort_sort_an_array_of_structs_by_key": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n\nstruct Result {\n    int startTime;\n    int duration;\n    float value;\n};\n\n// Sort a vector of Result objects by their startTime in ascending order.\n// The routine preserves the exact ordering semantics of the original code\n// while leveraging a lightweight inline comparator suitable for the -O2\n// optimisation level.  No changes to the function signature or the\n// semantics of the sort are made.\ninline void sortByStartTime(std::vector<Result> &results)\n{\n    // Using a struct-function style lambda yields the smallest overhead\n    // in a modern compiler: the lambda is inlined and compiles to a\n    // single instruction compare.\n    const auto cmp = [](const Result &a, const Result &b) noexcept\n    {\n        return a.startTime < b.startTime;\n    };\n    std::sort(results.begin(), results.end(), cmp);\n}\n```",
  "42_sort_sorted_ranks": "```cpp\n#pragma once\n#include <algorithm>\n#include <numeric>\n#include <vector>\n#include <omp.h>\n\n/*\n * For each value in the vector `x` compute its index in the sorted vector\n * and store the results in `ranks_`. The behaviour is identical to the\n * reference implementation.\n *\n * Parallelisation strategy:\n *   1. Create the index vector in parallel (very cheap).\n *   2. Sort the index vector serially (std::sort is highly optimised).\n *   3. Assign the rank values in parallel using OpenMP.\n *\n * The input size is small enough that the serial sort dominates the\n * overall running time, but the parallel rank assignment gives a\n * noticeable speed\u2011up on multi\u2013core systems.\n */\ninline void ranks(std::vector<float> const& x,\n                 std::vector<size_t>& ranks_) noexcept\n{\n    size_t n = x.size();\n    // Prepare output vector if not already sized correctly.\n    if (ranks_.size() != n)\n        ranks_.resize(n);\n\n    // 1. Build the index vector in parallel.\n    std::vector<size_t> indices(n);\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < n; ++i)\n        indices[i] = i;\n\n    // 2. Perform a serial sort on the indices (fast on modern CPUs).\n    std::sort(indices.begin(), indices.end(),\n              [&x](size_t a, size_t b) { return x[a] < x[b]; });\n\n    // 3. Assign ranks in parallel.\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < n; ++i)\n        ranks_[indices[i]] = i;\n}\n```",
  "00_dense_la_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Perform LU factorisation (no pivoting) of an N\u00d7N matrix stored in row-major order.\n * The output is written back into the same buffer: the strictly lower part holds L (with unit diagonal\n * implicitly represented), the upper part holds U.\n *\n * This implementation uses cache\u2011friendly pointer arithmetic and parallelises the\n * innermost loop over the rows that are being updated.  Only the rows below the\n * current pivot (k) are updated in parallel, so there are no data races.\n */\ninline void luFactorize(std::vector<double>& A, std::size_t N)\n{\n    const size_t stride = N;          // row stride in the linear array\n    for (std::size_t k = 0; k < N; ++k)\n    {\n        const double* pk = &A[k * stride];          // pointer to the k\u2011th row\n        const double pivot = pk[k];\n        const double invPivot = 1.0 / pivot;        // compute once rather than per i\n\n        // Update rows below the pivot row\n        #pragma omp parallel for schedule(static)\n        for (std::size_t i = k + 1; i < N; ++i)\n        {\n            double* pi = &A[i * stride];  // pointer to the i\u2011th row\n            // compute multiplier\n            const double factor = pi[k] * invPivot;\n            pi[k] = factor;                          // store L element\n\n            // vectorised inner loop over columns j = k+1 .. N-1\n            std::size_t j = k + 1;\n            // unroll a few iterations for better ILP\n            for (; j + 3 < N; j += 4)\n            {\n                pi[j]     -= factor * pk[j];\n                pi[j + 1] -= factor * pk[j + 1];\n                pi[j + 2] -= factor * pk[j + 2];\n                pi[j + 3] -= factor * pk[j + 3];\n            }\n            for (; j < N; ++j)\n                pi[j] -= factor * pk[j];\n        }\n    }\n}\n```",
  "02_dense_la_gemm": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n   Optimised matrix multiplication (gemm)\n\n   Computes C += A * B where\n     A : M \u00d7 K   (row\u2011major)\n     B : K \u00d7 N   (row\u2011major)\n     C : M \u00d7 N   (row\u2011major, auxiliary buffer expected to be pre\u2011initialised)\n   The implementation uses:\n     - Blocking (tile size 32) for cache locality\n     - Transposed view of B for contiguous memory access\n     - OpenMP parallelisation over outer blocks\n     - Compiler auto\u2011vectorisation hints\n   The functional behaviour (exact arithmetic) is identical to the reference\n   implementation.\n*/\n\nconstexpr size_t TILE = 32;\n\nvoid gemm(std::vector<double> const& A,\n          std::vector<double> const& B,\n          std::vector<double> &C,\n          size_t M, size_t K, size_t N)\n{\n    // Transpose B into a temporary buffer on the stack if small enough;\n    // otherwise allocate it dynamically.  The stack buffer is 1 MB.\n    const size_t max_stack = 1024 * 1024 / sizeof(double);\n    std::vector<double> Btrans;\n    double *B_t;\n\n    if (K * N <= max_stack) {\n        B_t = Btrans.data();\n        Btrans.resize(K * N);\n    } else {\n        B_t = new double[K * N];\n    }\n\n    // Column\u2011major view of B: B_t[k*N + j] = B[j*K + k]\n    for (size_t j = 0; j < N; ++j) {\n        for (size_t k = 0; k < K; ++k) {\n            B_t[k * N + j] = B[j * K + k];\n        }\n    }\n\n#pragma omp parallel for schedule(static)\n    for (size_t ii = 0; ii < M; ii += TILE) {\n        size_t i_max = std::min(ii + TILE, M);\n        for (size_t kk = 0; kk < K; kk += TILE) {\n            size_t k_max = std::min(kk + TILE, K);\n            for (size_t jj = 0; jj < N; jj += TILE) {\n                size_t j_max = std::min(jj + TILE, N);\n                // inner kernel for the current tile\n                for (size_t i = ii; i < i_max; ++i) {\n                    for (size_t k = kk; k < k_max; ++k) {\n                        double aik = A[i * K + k];\n#pragma GCC ivdep\n                        for (size_t j = jj; j < j_max; ++j) {\n                            C[i * N + j] += aik * B_t[k * N + j];\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    if (B_t != Btrans.data()) {\n        delete[] B_t;\n    }\n}\n```",
  "01_dense_la_solve": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Solve the linear system Ax=b for x.\n   A is an NxN matrix in row-major. x and b have N elements.\n   This implementation uses a blocked Gaussian elimination\n   that is parallelised with OpenMP.\n*/\nvoid solveLinearSystem(const std::vector<double>& A,\n                       const std::vector<double>& b,\n                       std::vector<double>& x,\n                       const size_t N)\n{\n    // Working copies of A and b\n    std::vector<double> a(A);\n    std::vector<double> bb(b);\n\n    const size_t BLOCK = 64;                // cache friendly block size\n    const size_t NBLOCK = (N + BLOCK - 1) / BLOCK;\n\n    for (size_t bi = 0; bi < NBLOCK; ++bi) {\n        size_t i0 = bi * BLOCK;\n        size_t i1 = std::min<size_t>(i0 + BLOCK, N);\n\n        /* --- Pivoting (no swap, return on zero pivot) --- */\n        for (size_t i = i0; i < i1; ++i) {\n            double piv = a[i * N + i];\n            if (piv == 0.0) return;        // singular matrix \u2013 behaviour same as original\n\n            /* --- Row elimination below the pivot --- */\n            for (size_t j = i + 1; j < N; ++j) {\n                double factor = a[j * N + i] / piv;\n#pragma omp simd\n                for (size_t k = i; k < N; ++k) {\n                    a[j * N + k] -= factor * a[i * N + k];\n                }\n                bb[j] -= factor * bb[i];\n            }\n        }\n\n        /* --- Forward elimination within the block (parallel) --- */\n        for (size_t i = i0; i < i1; ++i) {\n            double piv = a[i * N + i];\n#pragma omp for schedule(static) nowait\n            for (size_t j = i + 1; j < N; ++j) {\n                double factor = a[j * N + i] / piv;\n                for (size_t k = i; k < N; ++k) {\n                    a[j * N + k] -= factor * a[i * N + k];\n                }\n                bb[j] -= factor * bb[i];\n            }\n        }\n    }\n\n    /* --- Back substitution (serial, as data dependencies forbid parallelism) --- */\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i) {\n        double sum = 0.0;\n        for (size_t j = i + 1; j < N; ++j) {\n            sum += a[i * N + j] * x[j];\n        }\n        x[i] = (bb[i] - sum) / a[i * N + i];\n    }\n}\n```",
  "41_sort_k-th_smallest_element": "```cpp\n#pragma once\n#include <algorithm>\n#include <vector>\n\n/*\n * Find the k-th smallest element of the vector `x` (1\u2011based index).\n *\n * The routine makes a copy of the input data and then uses std::nth_element\n * which runs in linear expected time (O(n)).  The original order of `x`\n * is not modified, ensuring identical behaviour to the reference implementation.\n */\nint findKthSmallest(std::vector<int> const& x, int k) {\n    // Guard against out-of-range k if the harness guarantees valid input.\n    // Using std::min and std::max to avoid undefined behaviour.\n    if (k <= 0) return std::numeric_limits<int>::min();\n    if (k > static_cast<int>(x.size())) return std::numeric_limits<int>::max();\n\n    std::vector<int> tmp = x;                          // copy data\n    std::nth_element(tmp.begin(), tmp.begin() + (k - 1), tmp.end());  // place k\u2011th element\n    return tmp[k - 1];\n}\n```",
  "44_sort_sort_non-zero_elements": "```cpp\n#pragma once\n#include <algorithm>\n#include <vector>\n\n/// @brief Sort all non\u2011zero integers in the vector while leaving\n///        zero elements in their original positions.\n///\n/// This implementation first collects the non\u2011zero elements,\n/// sorts them, and then writes them back into the original\n/// vector at the positions originally occupied by non\u2011zeros.\n/// The relative order of the zero elements is unchanged and\n/// each zero remains at its original index.\n///\n/// The algorithm runs in O(N log N) time and O(K) additional\n/// memory, where K is the number of non\u2011zero elements.\n/// It is fine\u2011tuned for modern x86\u201164 CPUs with GCC\n/// (-O2, -fopenmp).  No parallelism is used because the\n/// bottleneck is the call to std::sort, which is already\n/// highly optimised and highly parallel on many implementations.\ninline void sortIgnoreZero(std::vector<int> &x)\n{\n    // Reserve space for the non\u2011zero elements to avoid several allocations\n    std::vector<int> nonZeroElems;\n    nonZeroElems.reserve(x.size());\n\n    // Collect non\u2011zero elements\n    for (int v : x) {\n        if (v != 0) {\n            nonZeroElems.push_back(v);\n        }\n    }\n\n    // Sort them\n    std::sort(nonZeroElems.begin(), nonZeroElems.end());\n\n    // Write the sorted non\u2011zeros back into their original positions\n    std::size_t idx = 0;\n    for (std::size_t i = 0, n = x.size(); i < n; ++i) {\n        if (x[i] != 0) {\n            x[i] = nonZeroElems[idx++];\n        }\n    }\n}\n```",
  "37_search_find_the_closest_number_to_pi": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Return the index of the value in the vector `x` that is closest\n * to the mathematical constant PI (M_PI).  The function preserves\n * the exact behaviour of the original implementation while\n * exploiting SIMD and parallelism where appropriate.\n *\n * The code is compiled with GCC 12+ using `-O2 -fopenmp`.\n */\nstatic constexpr double PI_VAL = M_PI;\n\nsize_t findClosestToPi(std::vector<double> const& x) {\n    // Handle empty input (undefined in original code, but\n    // we return 0 to avoid UB). This matches the behaviour\n    // of accessing x[0] in the original function.\n    if (x.empty()) return 0;\n\n    // Find the index of the element with smallest absolute difference.\n    // Parallel reduction to find minimum difference and corresponding index.\n    size_t best_index = 0;\n    double best_diff  = std::fabs(x[0] - PI_VAL);\n\n    #pragma omp parallel for\n    for (size_t i = 1; i < x.size(); ++i) {\n        double diff = std::fabs(x[i] - PI_VAL);\n        #pragma omp critical\n        {\n            if (diff < best_diff) {\n                best_diff  = diff;\n                best_index = i;\n            }\n        }\n    }\n    return best_index;\n}\n```\n",
  "35_search_search_for_last_struct_by_key": "```cpp\n#pragma once\n#include <vector>\n\nstruct Book {\n    std::string title;\n    int pages;\n};\n\n/*\n * Return the index of the last Book item in the vector `books`\n * where `Book.pages` is less than 100.\n *\n * Example:\n *   input: [{title=\"Green Eggs and Ham\", pages=72},\n *           {title=\"gulliver's travels\", pages=362},\n *           {title=\"Stories of Your Life\", pages=54},\n *           {title=\"Hamilton\", pages=818}]\n *   output: 2\n */\ninline size_t findLastShortBook(std::vector<Book> const& books) {\n    const size_t n = books.size();\n    /* Traverse backwards using unsigned contraction to avoid\n     * signed comparison and overflow on empty vectors. */\n    for (size_t i = n; i-- > 0;) {\n        if (books[i].pages < 100) {\n            return i;\n        }\n    }\n    return n;\n}\n```",
  "39_search_xor_contains": "```cpp\n#pragma once\n#include <vector>\n\n/* Return true if `val` is only in one of vectors x or y.\n   Return false if it is in both or neither.\n   The implementation is a straight\u2011forward sequential scan with an early exit\n   whenever the result is determined.  No temporary containers are created\n   and the original semantics are preserved. */\ninline bool xorContains(const std::vector<int>& x,\n                        const std::vector<int>& y,\n                        int val) noexcept\n{\n    bool foundInX = false;\n    // Scan x first; exit early if found\n    for (auto v : x) {\n        if (v == val) {\n            foundInX = true;\n            break;\n        }\n    }\n\n    // Scan y; we can terminate early if both are found,\n    // because the result would be false anyway.\n    bool foundInY = false;\n    for (auto v : y) {\n        if (v == val) {\n            foundInY = true;\n            break;\n        }\n    }\n\n    // XOR: true only when exactly one of the flags is true\n    return foundInX ^ foundInY;\n}\n```",
  "36_search_check_if_array_contains_value": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <atomic>\n#include <omp.h>\n\n/*\n * Return true if the vector `x` contains the value `target`.\n * Optimized for large vectors on a modern 8\u2011thread CPU.\n * The implementation uses OpenMP to search in parallel and will\n * stop all threads as soon as a match is found.\n */\ninline bool contains(const std::vector<int>& x, int target) {\n    if (x.empty()) return false;\n\n    const std::size_t n = x.size();\n    // If the vector is small we just do a linear scan to avoid\n    // the overhead of creating OpenMP threads.\n    if (n < 128) {\n        for (std::size_t i = 0; i < n; ++i)\n            if (x[i] == target) return true;\n        return false;\n    }\n\n    std::atomic<bool> found{false};\n\n    #pragma omp parallel\n    {\n        // Divide the work mostly evenly among the threads\n        #pragma omp for schedule(static,256) firstprivate(found)\n        for (std::size_t i = 0; i < n; ++i) {\n            // Skip further checks if a match was already found\n            if (found.load(std::memory_order_relaxed)) continue;\n            if (x[i] == target) {\n                found.store(true, std::memory_order_relaxed);\n            }\n        }\n    }\n    return found.load(std::memory_order_relaxed);\n}\n```",
  "38_search_find_the_first_even_number": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Return the index of the first even number in the vector x.\n   The algorithm scans the vector in parallel and keeps the smallest\n   valid index seen by any thread.  The bit\u2011wise operation\n   `x[i] & 1` is used instead of the modulo operator for speed.\n*/\nsize_t findFirstEven(std::vector<int> const& x) {\n    // start with the sentinel value equal to the vector size\n    size_t first_even_idx = x.size();\n\n    #pragma omp parallel for schedule(static) reduction(min:first_even_idx)\n    for (size_t i = 0; i < x.size(); ++i) {\n        // even numbers have least significant bit 0\n        if ((x[i] & 1) == 0) {\n            // the reduction handles the minimum comparison\n            first_even_idx = i;\n        }\n    }\n\n    return first_even_idx;\n}\n```\n",
  "40_sort_sort_an_array_of_complex_numbers_by_magnitude": "```cpp\n#pragma once\n#include <complex>\n#include <vector>\n#include <algorithm>\n#include <numeric>\n#include <cmath>\n#include <omp.h>\n\n/*\n * Sort the vector x of complex numbers by their magnitude in ascending order.\n *\n * The implementation first pre\u2011computes the magnitudes in parallel, then\n * performs a single sort on an auxiliary vector that stores the original indices.\n * Finally the result is written back into the original vector.  This avoids\n * recalculating std::abs on every comparison and keeps the overall memory\n * traffic low while using the available eight threads.\n */\nvoid sortComplexByMagnitude(std::vector<std::complex<double>> &x) {\n    const std::size_t n = x.size();\n    if (n <= 1) return;\n\n    /* 1. Compute magnitudes in parallel. */\n    std::vector<double> mags(n);\n    #pragma omp parallel for schedule(static)\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(n); ++i) {\n        mags[i] = std::abs(x[i]);          // cheap, but cheaper than multiple abs() calls\n    }\n\n    /* 2. Create an index vector and sort it using the magnitudes. */\n    std::vector<std::size_t> idx(n);\n    std::iota(idx.begin(), idx.end(), 0);\n    std::sort(idx.begin(), idx.end(),\n              [&mags](std::size_t a, std::size_t b) { return mags[a] < mags[b]; });\n\n    /* 3. Reorder the original vector according to the sorted indices.\n     *    We copy the elements to a temporary buffer to avoid aliasing during\n     *    the write\u2011back.  The temporary buffer is allocated once so the\n     *    per\u2011loop allocation cost is negligible. */\n    std::vector<std::complex<double>> tmp(n);\n    for (std::size_t i = 0; i < n; ++i) {\n        tmp[i] = x[idx[i]];\n    }\n    x.swap(tmp);   // replace original vector with sorted order\n}\n```"
}