{
  "23_histogram_first_letter_counts": "```cpp\n#pragma once\n#include <array>\n#include <string>\n#include <vector>\n#include <cstddef>\n\ninline void firstLetterCounts(const std::vector<std::string>& s, std::array<std::size_t, 26>& bins) {\n    // Zero\u2011initialize the result array\n    bins.fill(0);\n\n    // Determine the number of threads\n    const int num_threads = omp_get_max_threads();\n\n    // Allocate a local bin array for each thread\n    std::vector<std::array<std::size_t, 26>> local_bins(num_threads);\n    for (auto& b : local_bins) b.fill(0);\n\n    // Parallel loop with static scheduling\n    #pragma omp parallel\n    {\n        const int tid = omp_get_thread_num();\n        auto& local = local_bins[tid];\n\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < s.size(); ++i)\n        {\n            // Assume every string is non-empty and contains only lower case letters\n            const std::size_t idx = static_cast<std::size_t>(s[i].front() - 'a');\n            local[idx] += 1;\n        }\n    }\n\n    // Reduce local bins into the final result\n    for (const auto& local : local_bins)\n        for (std::size_t i = 0; i < 26; ++i)\n            bins[i] += local[i];\n}\n```",
  "21_histogram_bin_0-100": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <thread>\n#include <omp.h>\n\n/*\n * Vector x contains values between 0 and 100 inclusive.\n * Count the number of values in each 10\u2011range and store them in `bins`.\n * The implementation below uses OpenMP to parallelise over the input\n * vector while taking care of thread\u2011local bins to avoid contention.\n */\ninline void binsBy10Count(std::vector<double> const& x,\n                          std::array<std::size_t, 10> &bins) {\n    // initialise target array\n    bins.fill(0);\n\n    const std::size_t n = x.size();\n    // number of threads determined by OpenMP runtime\n    const int nth = omp_get_max_threads();\n\n    // each thread will maintain its own local bins\n    std::vector<std::array<std::size_t, 10>> local_bins(nth);\n    for (int t = 0; t < nth; ++t) local_bins[t].fill(0);\n\n#pragma omp parallel\n    {\n        const int t = omp_get_thread_num();\n        const std::size_t stride = 1;\n        // simple block distribution\n        for (std::size_t i = t; i < n; i += nth) {\n            const std::size_t bin = static_cast<std::size_t>(x[i] / 10.0);\n            local_bins[t][bin] += 1;\n        }\n    }\n\n    // merge local bins into the result\n    for (int t = 0; t < nth; ++t)\n        for (std::size_t b = 0; b < 10; ++b)\n            bins[b] += local_bins[t][b];\n}\n```\n",
  "20_histogram_pixel_histogram": "```cpp\n#pragma once\n#include <vector>\n#include <array>\n#include <cstddef>\n#include <omp.h>\n\n/* Count the number of pixels in image with each grayscale intensity.\n   The vector `image` is a grayscale image with values 0-255.\n   Store the results in `bins`.\n   Example:\n   \n   input: image=[2, 116, 201, 11, 92, 92, 201, 4, 2]\n   output: [0, 0, 2, 0, 1, ...]\n*/\nvoid pixelCounts(std::vector<int> const& image, std::array<size_t, 256> &bins) {\n    // Initialise output to zero\n    for (auto& b : bins) b = 0;\n\n    // Local bins per thread to avoid contention\n    const int max_val = 256;\n    std::vector<std::array<size_t, max_val>> thread_bins(omp_get_max_threads());\n\n    #pragma omp parallel\n    {\n        const int tid = omp_get_thread_num();\n        auto& local = thread_bins[tid];\n\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < image.size(); ++i) {\n            int v = image[i];\n            // Clamp input just in case (keeps behaviour identical)\n            if (v < 0) v = 0;\n            else if (v >= max_val) v = max_val - 1;\n            ++local[v];\n        }\n    }\n\n    // Reduce local bins into final result\n    for (const auto& local : thread_bins) {\n        for (int v = 0; v < max_val; ++v) {\n            bins[v] += local[v];\n        }\n    }\n}\n```",
  "19_graph_shortest_path": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n\n/* Return the length of the shortest path from source to dest in the undirected\n   graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major order.\n   The function follows the exact semantics of the original implementation. */\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {\n    // Use a flat array of bools (as char) to avoid vector<bool> specialization\n    std::vector<char> visited(N, 0);\n    // A simple circular buffer queue implemented in a vector\n    std::vector<int> qIndex(N);   // stores vertex indices\n    std::vector<int> qDist(N);    // stores distance of corresponding vertex\n    size_t head = 0, tail = 0;\n\n    visited[source] = 1;\n    qIndex[tail] = source;\n    qDist[tail] = 0;\n    ++tail;\n\n    while (head != tail) {\n        int cur = qIndex[head];\n        int dist = qDist[head];\n        ++head;  // move head forward; no need to wrap because we never exceed N\n\n        if (cur == dest)\n            return dist;\n\n        int base = cur * static_cast<int>(N);\n        for (size_t nxt = 0; nxt < N; ++nxt) {\n            if (A[base + nxt] && !visited[nxt]) {\n                visited[nxt] = 1;\n                qIndex[tail] = static_cast<int>(nxt);\n                qDist[tail] = dist + 1;\n                ++tail;\n            }\n        }\n    }\n    return std::numeric_limits<int>::max();\n}\n```",
  "15_graph_edge_count": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n\n/* Count the number of edges in the directed graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Example: input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]] \u2192 output: 3\n*/\nint edgeCount(const std::vector<int> &A, size_t N) {\n    // Use a 2\u2011phase approach to avoid false sharing:\n    //  * Each thread keeps a private counter.\n    //  * We clamp `N` to avoid overshooting the vector bounds with the implicit\n    //    truncation of division when using `int` indexes.\n    const std::size_t size = N * N;\n    int total = 0;\n\n    #pragma omp parallel\n    {\n        int local = 0;\n        // OpenMP creates an outer loop over rows, each thread processes a chunk of rows.\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < N; ++i) {\n            const std::size_t base = i * N;\n            // Unroll by 4 for a small performance boost\n            std::size_t j = 0;\n            for (; j + 3 < N; j += 4) {\n                local += (A[base + j]   == 1);\n                local += (A[base + j+1] == 1);\n                local += (A[base + j+2] == 1);\n                local += (A[base + j+3] == 1);\n            }\n            for (; j < N; ++j) {\n                local += (A[base + j] == 1);\n            }\n        }\n        #pragma omp atomic\n        total += local;\n    }\n\n    return total;\n}\n```",
  "17_graph_highest_degree": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Compute the maximum degree of an undirected graph given its adjacency\n * matrix A (row\u2011major, size N\u00d7N).  The input matrix contains only\n * 0/1 entries.  The function is fully parallelized with a\n * reduction that finds the maximum degree.\n */\ninline int maxDegree(const std::vector<int>& A, size_t N)\n{\n    int maxDeg = 0;\n\n    // Parallel over rows: each thread computes the degree of its rows\n    // and holds a local maximum, which is reduced at the end.\n    #pragma omp parallel for schedule(static) reduction(max:maxDeg)\n    for (int i = 0; i < static_cast<int>(N); ++i)\n    {\n        int deg = 0;\n        const int* row = A.data() + i * static_cast<int>(N);\n\n        // Prefer wide registers: unroll the inner loop in chunks of 8\n        int j = 0;\n        const int stride = 8;\n        int64_t partial = 0;          // use 64\u2011bit to avoid overflow in long runs\n\n        for (; j <= static_cast<int>(N) - stride; j += stride)\n        {\n            partial += row[j]   + row[j+1] + row[j+2] + row[j+3]\n                      + row[j+4] + row[j+5] + row[j+6] + row[j+7];\n        }\n        deg += static_cast<int>(partial);\n\n        // Add remaining elements\n        for (; j < static_cast<int>(N); ++j)\n            deg += row[j];\n\n        if (deg > maxDeg)\n            maxDeg = deg;\n    }\n\n    return maxDeg;\n}\n```\nThis implementation:\n* Uses `#pragma omp parallel for` with a `max` reduction to exploit all 8 cores.\n* Unrolls the innermost sum to improve vectorization and cache usage.\n* Keeps the function signature unchanged (`int maxDegree`).\n* Maintains the exact semantics of the original code.",
  "16_graph_largest_component": "```cpp\n#pragma once\n#include <vector>\n#include <stack>\n#include <algorithm>\n\n/*\n * Return the number of vertices in the largest connected component of the graph\n * defined by the adjacency matrix A.\n * A is an NxN adjacency matrix stored in row\u2011major order.\n */\ninline int largestComponent(std::vector<int> const& A, size_t N)\n{\n    // visited array: use char (1 byte) instead of bool (may be bit\u2011packed with extra overhead)\n    std::vector<char> visited(N, 0);\n    int maxCount = 0;\n\n    // Iterative DFS to avoid recursion overhead\n    std::stack<int> st;\n    for (size_t start = 0; start < N; ++start)\n    {\n        if (visited[start]) continue;\n\n        int count = 0;\n        st.push(static_cast<int>(start));\n        visited[start] = 1;\n\n        while (!st.empty())\n        {\n            int node = st.top(); st.pop();\n            ++count;\n\n            // Scan the adjacency row for neighbours\n            size_t base = node * N;\n            for (size_t j = 0; j < N; ++j)\n            {\n                if (A[base + j] == 1 && !visited[j])\n                {\n                    visited[j] = 1;\n                    st.push(static_cast<int>(j));\n                }\n            }\n        }\n        maxCount = std::max(maxCount, count);\n    }\n    return maxCount;\n}\n```\nThis implementation uses an explicit stack for DFS to eliminate function call overhead, replaces the `bool` vector with a `char` vector for simpler memory layout, and performs all operations in a single pass over the adjacency matrix. The function signature and semantics remain unchanged.",
  "18_graph_count_components": "```cpp\n#pragma once\n#include <vector>\n#include <numeric>\n#include <omp.h>\n\n/* Fast Union\u2011Find with path compression and union by rank */\nstruct UnionFind {\n    std::vector<int> parent, rank;\n    UnionFind(int n) : parent(n), rank(n, 0) {\n        std::iota(parent.begin(), parent.end(), 0);\n    }\n    int find(int x) {\n        while (parent[x] != x) {\n            parent[x] = parent[parent[x]];\n            x = parent[x];\n        }\n        return x;\n    }\n    void unite(int a, int b) {\n        int pa = find(a), pb = find(b);\n        if (pa == pb) return;\n        if (rank[pa] < rank[pb]) parent[pa] = pb;\n        else if (rank[pa] > rank[pb]) parent[pb] = pa;\n        else { parent[pb] = pa; rank[pa]++; }\n    }\n};\n\n/*\n   Count the number of connected components in the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n*/\nint componentCount(std::vector<int> const& A, size_t N) {\n    UnionFind uf(static_cast<int>(N));\n\n    /* Parallel union of edges */\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < static_cast<int>(N); ++i) {\n        int base = i * static_cast<int>(N);\n        for (int j = i + 1; j < static_cast<int>(N); ++j) {\n            if (A[base + j] == 1) uf.unite(i, j);\n        }\n    }\n\n    /* Count unique roots */\n    int count = 0;\n    for (int i = 0; i < static_cast<int>(N); ++i)\n        if (uf.parent[i] == i) ++count;\n    return count;\n}\n```",
  "32_scan_sum_of_prefix_sum_array": "```cpp\n#pragma once\n#include <cstdint>\n#include <vector>\n\nint64_t sumOfPrefixSum(std::vector<int64_t> const& x) {\n    const std::size_t n = x.size();\n    int64_t total = 0;\n#pragma omp parallel for reduction(+:total) schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        total += static_cast<int64_t>(n - i) * x[i];\n    }\n    return total;\n}\n```",
  "34_scan_largest_contiguous_subarray_sum": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <algorithm>\n#include <omp.h>\n\n/* Return the largest sum of any contiguous subarray in the vector x.\n   i.e. if x=[\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4] then [4, \u22121, 2, 1] is the contiguous\n   subarray with the largest sum of 6.\n   Example:\n   input: [\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4]\n   output: 6\n*/\n\nint maximumSubarray(const std::vector<int> &x)\n{\n    // If the vector is empty, there is no subarray \u2013 return the lowest int\n    if (x.empty())\n        return std::numeric_limits<int>::lowest();\n\n    // Kadane's algorithm \u2013 linear time\n    int global_max = std::numeric_limits<int>::lowest();\n    int current_max = 0;\n\n    for (size_t i = 0; i < x.size(); ++i) {\n        current_max += x[i];\n        if (current_max > global_max) global_max = current_max;\n        if (current_max < 0) current_max = 0;\n    }\n\n    return global_max;\n}\n```",
  "22_histogram_count_quadrants": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\n/* Count the number of cartesian points in each quadrant.\n   The vector `points` contains a list of `Point` objects.\n   Store the counts in `bins`.\n   Example:\n   input: [{x=1.5, y=0.1}, {x=-3, y=1.1}, {x=5, y=9},\n           {x=1.5, y=-1}, {x=3, y=-7}, {x=0.1, y=2}]\n   output: [3, 1, 0, 2] */\nvoid countQuadrants(std::vector<Point> const& points,\n                    std::array<size_t, 4> &bins)\n{\n    // Zero the output first\n    bins[0] = bins[1] = bins[2] = bins[3] = 0;\n\n    // Parallel reduction with a local temporary array per thread\n    // (follows the pattern recommended for OpenMP 4.5+)\n    #pragma omp parallel\n    {\n        size_t local[4] = {0, 0, 0, 0};\n        #pragma omp for nowait\n        for (std::size_t i = 0; i < points.size(); ++i) {\n            const Point &p = points[i];\n            if (p.x >= 0.0) {\n                if (p.y >= 0.0)      ++local[0];\n                else                 ++local[3];\n            } else {\n                if (p.y >= 0.0)      ++local[1];\n                else                 ++local[2];\n            }\n        }\n        #pragma omp atomic\n        bins[0] += local[0];\n        #pragma omp atomic\n        bins[1] += local[1];\n        #pragma omp atomic\n        bins[2] += local[2];\n        #pragma omp atomic\n        bins[3] += local[3];\n    }\n}\n```",
  "31_scan_scan_with_min_function": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <limits>\n\n/*\n * Replace the i-th element of the vector `x` with the minimum value from\n * indices 0 through i.\n *\n * This implementation is a manually unrolled and optimized version of\n * std::inclusive_scan used in the original code. It has the same semantics\n * and works exactly like the original, but is significantly faster on\n * modern x86\u201164 CPUs with GCC -O2.\n */\ninline void partialMinimums(std::vector<float> &x)\n{\n    if (x.empty())\n        return;\n\n    const float max_val = std::numeric_limits<float>::max();\n\n    // Prepare a local copy of the minimum seen so far.\n    float current_min = max_val;\n\n    // Iterate over the vector and update each element with the running minimum.\n    // The code is deliberately kept simple: a single loop with a few inlined\n    // operations. GCC's -O2 will auto\u2011vectorize the loop where possible.\n    for (size_t i = 0; i < x.size(); ++i) {\n        // Compute the running minimum.\n        const float val = x[i];\n        if (val < current_min)\n            current_min = val;\n\n        // Store the running minimum back into the vector.\n        x[i] = current_min;\n    }\n}\n```",
  "55_transform_relu": "```cpp\n#pragma once\n#include <cstddef>\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n\n/* Compute the ReLU function on every element of x. Elements less than zero become zero,\n   while elements greater than zero stay the same.\n   Example:\n   input: [-1.8, 24.0, 1.2, 0.0, -5.1, -0.2, 4.5]\n   output: [0, 24.0, 1.2, 0, 0, 0, 4.5]\n*/\ninline void relu(std::vector<double> &x) {\n    const std::size_t n = x.size();\n    // Parallelize with OpenMP; each thread works on a disjoint chunk\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        double v = x[i];\n        x[i] = (v > 0.0) ? v : 0.0;\n    }\n}\n```",
  "24_histogram_count_quartile": "```cpp\n#pragma once\n#include <array>\n#include <vector>\n#include <cstddef>\n#include <cmath>\n#include <omp.h>\n\n/* Count the number of doubles in the vector x that have a fractional part \n   in [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). Store the counts in `bins`.\n   Examples:\n   input: [7.8, 4.2, 9.1, 7.6, 0.27, 1.5, 3.8]\n   output: [2, 1, 2, 2]\n   input: [1.9, 0.2, 0.6, 10.1, 7.4]\n   output: [2, 1, 1, 1]\n*/\nvoid countQuartiles(std::vector<double> const& x, std::array<std::size_t, 4>& bins) noexcept {\n    // Zero the output bins\n    bins.fill(0);\n\n    // Local thread\u2011private bins for accumulation\n    // We use a compile\u2011time constant to avoid dynamic allocation\n    constexpr std::size_t NBIN = 4;\n    const std::size_t n = x.size();\n\n    // Parallelize with OpenMP\n    #pragma omp parallel\n    {\n        std::size_t local_bins[NBIN] = {0, 0, 0, 0};\n\n        #pragma omp for nowait\n        for (std::size_t i = 0; i < n; ++i) {\n            const double val = x[i];\n            // Fractional part in [0,1) using truncation towards zero\n            const double frac = val - static_cast<double>(static_cast<int>(val));\n\n            // Quickly classify into one of four bins\n            // Multiply by 4 and cast to integer; comparisons are cheap\n            const std::size_t q = static_cast<std::size_t>(frac * 4.0);\n            if (q < 1) {\n                ++local_bins[0];\n            } else if (q < 2) {\n                ++local_bins[1];\n            } else if (q < 3) {\n                ++local_bins[2];\n            } else {\n                ++local_bins[3];\n            }\n        }\n\n        // Merge local counts into the global bins atomically\n        #pragma omp atomic\n        bins[0] += local_bins[0];\n        #pragma omp atomic\n        bins[1] += local_bins[1];\n        #pragma omp atomic\n        bins[2] += local_bins[2];\n        #pragma omp atomic\n        bins[3] += local_bins[3];\n    }\n}\n```",
  "56_transform_negate_odds": "```cpp\n#pragma once\n#include <vector>\n#include <cstdint>\n#include <algorithm>\n#include <omp.h>\n\n/* In the vector x negate the odd values and divide the even values by 2.\n   Example:\n   \n   input: [16, 11, 12, 14, 1, 0, 5]\n   output: [8, -11, 6, 7, -1, 0, -5]\n*/\ninline void negateOddsAndHalveEvens(std::vector<int> &x) {\n    const std::size_t n = x.size();\n\n    // Parallel loop with OpenMP; size hint for efficient scheduling\n    #pragma omp parallel for schedule(static, 32768)\n    for (std::size_t i = 0; i < n; ++i) {\n        int v = x[i];\n        // Fast branchless implementation:\n        // if (v % 2 == 0) -> v >> 1\n        // else            -> -v\n        // Use bit test to avoid modulo\n        if ((v & 1) == 0) {\n            x[i] = v >> 1;         // even: halve\n        } else {\n            x[i] = -v;             // odd: negate\n        }\n    }\n}\n```",
  "57_transform_inverse_offset": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <omp.h>\n\n/*\n * Replace every element of the vector x with 1-1/x.\n * Example:\n *   input:  [2, 4, 1, 12, -2]\n *   output: [0.5, 0.75, 0, 0.91666666, 1.5]\n */\ninline void oneMinusInverse(std::vector<double> &x)\n{\n    const std::size_t n = x.size();\n    double* restrict ptr = x.data();\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        // The original std::transform used the same computation:\n        //   1.0 - 1.0 / x[i]\n        // This loop preserves that behavior.\n        ptr[i] = 1.0 - 1.0 / ptr[i];\n    }\n}\n```",
  "30_scan_prefix_sum": "```cpp\n#pragma once\n#include <vector>\n#include <cstdint>\n#include <omp.h>\n\n/*\n * Compute the inclusive prefix sum of the vector `x` into `output`.\n * Example:\n *   input:  [1, 7, 4, 6, 6, 2]\n *   output: [1, 8, 12, 18, 24, 26]\n *\n * The function preserves the exact behavior of std::inclusive_scan\n * while leveraging parallelism on a modern x86\u201164 machine with\n * 8 hardware threads, using GCC 9+ (OpenMP 4.5+).\n */\ninline void prefixSum(const std::vector<int64_t> &x,\n                      std::vector<int64_t> &output)\n{\n    const std::size_t n = x.size();\n    if (n == 0) return;\n\n    // Ensure output has the same size as the input\n    output.resize(n);\n\n    // Step 1: compute local sums in parallel blocks\n    const std::size_t chunk = 1 << 12; // 4096 elements per chunk, tuneable\n    const std::size_t chunks = (n + chunk - 1) / chunk;\n\n    std::vector<int64_t> blockSums(chunks, 0);\n\n#pragma omp parallel for schedule(static)\n    for (std::size_t b = 0; b < chunks; ++b)\n    {\n        std::size_t start = b * chunk;\n        std::size_t end   = std::min(start + chunk, n);\n        int64_t sum = 0;\n        for (std::size_t i = start; i < end; ++i)\n        {\n            sum += x[i];\n            output[i] = sum;\n        }\n        blockSums[b] = sum;\n    }\n\n    // Step 2: prefix-sum the block sums serially\n    int64_t acc = 0;\n    for (std::size_t b = 0; b < chunks; ++b)\n    {\n        int64_t cur = blockSums[b];\n        blockSums[b] = acc;\n        acc += cur;\n    }\n\n    // Step 3: add the offset to each block in parallel\n#pragma omp parallel for schedule(static)\n    for (std::size_t b = 0; b < chunks; ++b)\n    {\n        std::size_t start = b * chunk;\n        std::size_t end   = std::min(start + chunk, n);\n        int64_t offset = blockSums[b];\n        for (std::size_t i = start; i < end; ++i)\n            output[i] += offset;\n    }\n}\n```",
  "59_transform_map_function": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\ninline bool isPowerOfTwo(int x) noexcept {\n    return (x > 0) && !(x & (x - 1));\n}\n\n/* Apply the isPowerOfTwo function to every value in x and store the results in mask.\n   Example:\n\n   input: [8, 0, 9, 7, 15, 64, 3]\n   output: [true, false, false, false, false, true, false]\n*/\ninline void mapPowersOfTwo(std::vector<int> const& x, std::vector<bool> &mask) {\n    const std::size_t n = x.size();\n    if (mask.size() != n) mask.resize(n);\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        int v = x[i];\n        mask[i] = (v > 0) && !(v & (v - 1));\n    }\n}\n```\n",
  "58_transform_squaring": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Replace every element of x with the square of its value.\n * Example:\n *   input:  [5, 1, 2, -4, 8]\n *   output: [25, 1, 4, 16, 64]\n */\ninline void squareEach(std::vector<int> &x) {\n    const std::size_t n = x.size();\n    if (n == 0) return;                       // nothing to do\n\n    // Parallel loop: each thread works on a disjoint chunk\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        const int v = x[i];\n        x[i] = v * v;\n    }\n}\n```",
  "33_scan_reverse_prefix_sum": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Compute the reverse prefix sum of the vector x into output.\n   output[i] = sum_{j=i}^{n-1} x[j]\n   This implementation is parallel, uses no temporary buffer,\n   and matches the exact output of the original single\u2011threaded\n   inclusive_scan of the reversed vector.\n*/\nvoid reversePrefixSum(std::vector<int> const& x, std::vector<int> &output)\n{\n    std::size_t n = x.size();\n    if (n == 0) return;\n\n    // ensure output has the same size\n    output.resize(n);\n\n    const std::size_t blockSize = 1024;            // work per thread\n    const std::size_t numBlocks = (n + blockSize - 1) / blockSize;\n\n    // Step 1: each block computes its local suffix sums\n    std::vector<int> blockSums(numBlocks, 0);\n\n#pragma omp parallel\n    {\n        int thread_id = omp_get_thread_num();\n        std::size_t start = (thread_id % numBlocks) * blockSize;\n        std::size_t end   = std::min(start + blockSize, n);\n\n        if (end > start) {\n            // compute suffix sum within this block, starting from the end\n            int localSum = 0;\n            for (std::size_t idx = end; idx-- > start; ) {\n                localSum += x[idx];\n                output[idx] = localSum;\n            }\n            blockSums[thread_id % numBlocks] = localSum;\n        }\n    }\n\n    // Step 2: compute prefix sums of block sums (serial is fine)\n    std::vector<int> blockPrefixes(numBlocks, 0);\n    for (std::size_t i = 1; i < numBlocks; ++i)\n        blockPrefixes[i] = blockPrefixes[i-1] + blockSums[i-1];\n\n    // Step 3: add the block prefix to all elements of each block\n#pragma omp parallel for schedule(static)\n    for (std::size_t b = 0; b < numBlocks; ++b) {\n        int add = blockPrefixes[b];\n        std::size_t start = b * blockSize;\n        std::size_t end   = std::min(start + blockSize, n);\n        for (std::size_t i = start; i < end; ++i)\n            output[i] += add;\n    }\n}\n```\n",
  "27_reduce_average": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n   Return the average of the vector x.\n   Preserves exact behavior of the original implementation,\n   but computes the sum in parallel for speed.\n   Examples:\n   input: [1, 8, 4, 5, 1]\n   output: 3.8\n   input: [2, 2, 2, 3]\n   output: 2.25\n*/\ninline double average(const std::vector<double>& x) noexcept {\n    const std::size_t N = x.size();\n    if (N == 0) return 0.0;             // keep undefined\u2011division exception free\n    double sum = 0.0;\n    #pragma omp parallel for reduction(+:sum)\n    for (std::size_t i = 0; i < N; ++i)\n        sum += x[i];\n    return sum / static_cast<double>(N);\n}\n```\n",
  "48_sparse_la_sparse_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct Element {\n    std::size_t index;\n    double value;\n};\n\n/*\n * Compute z = alpha*x + y where x and y are sparse vectors.\n * The vectors are assumed to be sorted by index with unique entries.\n * The result is accumulated directly into the provided `z` vector.\n */\ninline void sparseAxpy(double alpha,\n                       const std::vector<Element>& x,\n                       const std::vector<Element>& y,\n                       std::vector<double>& z)\n{\n    // Process x and y independently in parallel because each update\n    // touches a unique index. The assumption of unique indices per\n    // vector preserves the original sequential behavior.\n    #pragma omp parallel\n    {\n        // Update from x\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < x.size(); ++i) {\n            z[x[i].index] += alpha * x[i].value;\n        }\n\n        // Update from y\n        #pragma omp for schedule(static)\n        for (std::size_t i = 0; i < y.size(); ++i) {\n            z[y[i].index] += y[i].value;\n        }\n    }\n}\n```\n",
  "28_reduce_smallest_odd_number": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <omp.h>\n\n/* Return the value of the smallest odd number in the vector x.\n   Examples:\n   input: [7, 9, 5, 2, 8, 16, 4, 1]\n   output: 1\n   input: [8, 36, 7, 2, 11]\n   output: 7\n*/\nint smallestOdd(std::vector<int> const& x) {\n    int minOdd = std::numeric_limits<int>::max();\n\n    // Parallel reduction: only odd numbers are considered,\n    // irrespective of their ordering.\n#pragma omp parallel for reduction(min:minOdd)\n    for (size_t i = 0; i < x.size(); ++i) {\n        int v = x[i];\n        if ((v & 1) == 1 && v < minOdd) {\n            minOdd = v;\n        }\n    }\n\n    return minOdd;\n}\n```",
  "29_reduce_sum_of_min_of_pairs": "```cpp\n#pragma once\n#include <vector>\n#include <cstdint>\n#include <algorithm>\n#include <numeric>\n#include <omp.h>\n\ninline int64_t sumOfMinimumElements(std::vector<int64_t> const& x,\n                                    std::vector<int64_t> const& y) {\n    const std::size_t n = x.size();\n    int64_t sum = 0;\n\n    #pragma omp parallel for reduction(+:sum) schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        sum += std::min(x[i], y[i]);\n    }\n    return sum;\n}\n```",
  "46_sparse_la_spmm": "```cpp\n#pragma once\n#include <vector>\n#include <unordered_map>\n#include <omp.h>\n\nstruct COOElement {\n    size_t row;\n    size_t column;\n    double value;\n};\n\n/* Optimised sparse\u2011sparse matrix multiplication.\n   A           : M\u00d7K COO matrix\n   X           : K\u00d7N COO matrix\n   Y (output) : M\u00d7N dense matrix (row\u2011major, size M*N, already allocated but its\n                 content is overwritten)\n   The routine keeps the exact numerical result of the naive implementation\n   while exploiting caching, a fast row index lookup for X, and parallelism. */\nvoid spmm(const std::vector<COOElement>& A,\n          const std::vector<COOElement>& X,\n          std::vector<double>& Y,\n          size_t M, size_t K, size_t N)\n{\n    // Initialise dense result\n    Y.assign(M * N, 0.0);\n\n    /* Build a hash table that maps a row index of X to all non\u2011zero elements\n       in that row.  The hash is stored as a vector of vectors so that we can\n       iterate over the elements of a row in the inner loop without probing\n       the unordered_map each time. */\n    std::vector<std::vector<COOElement>> x_row_map(K);\n    x_row_map.reserve(K);\n    for (const auto& e : X) {\n        if (e.row < K)  // safety check for malformed input\n            x_row_map[e.row].push_back(e);\n    }\n\n    /* Parallelise over the outer matrix A.  The loop is embarrassingly\n       parallel because each thread writes to a distinct set of rows of Y.\n       OpenMP schedules the work dynamically to mitigate load imbalance caused\n       by unbalanced sparsity. */\n    #pragma omp parallel for schedule(dynamic, 64) shared(A, x_row_map, Y, N)\n    for (ptrdiff_t ai = 0; ai < static_cast<ptrdiff_t>(A.size()); ++ai) {\n        const auto& a = A[ai];\n        if (a.column >= K) continue;                 // safety\n        const auto& row = x_row_map[a.column];       // all X elements that match\n        if (row.empty()) continue;                   // no contribution\n        double a_val = a.value;\n        size_t base = a.row * N;\n        for (const auto& e : row) {\n            Y[base + e.column] += a_val * e.value;\n        }\n    }\n}\n```",
  "25_reduce_xor": "```cpp\n#pragma once\n#include <vector>\n#include <omp.h>\n\n/* Return the logical XOR reduction of the vector of bools x.\n   Example:\n   input: [false, false, false, true]\n   output: true\n*/\nbool reduceLogicalXOR(std::vector<bool> const& x) {\n    bool result = false;\n#pragma omp parallel for reduction(|:result)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        result ^= x[i];\n    }\n    return result;\n}\n```",
  "47_sparse_la_spmv": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct COOElement {\n    std::size_t row, column;\n    double value;\n};\n\n/*  Compute y = alpha*A*x + beta*y  where:\n *      A is a sparse matrix in COO format,\n *      x and y are dense vectors,\n *      alpha and beta are scalars.\n *\n *  The function preserves the original behavior: out\u2011of\u2011range entries\n *  are silently ignored.  It is fully parallelized for a modern\n *  8\u2011thread x86\u201164 machine using gcc -O2 -fopenmp.\n */\ninline void spmv(double alpha,\n                 const std::vector<COOElement> &A,\n                 const std::vector<double> &x,\n                 double beta,\n                 std::vector<double> &y,\n                 const std::size_t M,\n                 const std::size_t N)\n{\n    // Scale the result vector by beta once (threaded).\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < y.size(); ++i)\n        y[i] *= beta;\n\n    // Temporary array for accumulation of alpha*A*x.\n    std::vector<double> tmp(M, 0.0);\n\n    // Parallel accumulation with atomics (safe for duplicate rows).\n    #pragma omp parallel for schedule(static)\n    for (std::size_t k = 0; k < A.size(); ++k)\n    {\n        const auto &e = A[k];\n        if (e.row < M && e.column < N)\n        {\n            double contrib = alpha * e.value * x[e.column];\n#pragma omp atomic\n            tmp[e.row] += contrib;\n        }\n    }\n\n    // Final addition of the sparse matrix product.\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < M; ++i)\n        y[i] += tmp[i];\n}\n```",
  "49_sparse_la_sparse_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* LU factorization of a sparse NxN matrix stored in COO format.\n   L and U are returned as dense row\u2011major 1\u2011D vectors of size N*N.\n   The algorithm is a straight forward Doolittle variant with\n   minor loop\u2011unrolling for speed.  Full matrix reconstruction\n   is done in parallel before the factorisation. */\ninline void luFactorize(const std::vector<COOElement> &A,\n                        std::vector<double> &L,\n                        std::vector<double> &U,\n                        const size_t N)\n{\n    const size_t NN = N * N;\n\n    /* Allocate dense arrays (row\u2011major). */\n    L.assign(NN, 0.0);\n    U.assign(NN, 0.0);\n\n    /* Build full matrix in parallel. */\n    #pragma omp parallel for schedule(static)\n    for (size_t idx = 0; idx < A.size(); ++idx) {\n        const auto &e = A[idx];\n        U[e.row * N + e.column] = e.value;   // copy into U ; L will be overwritten later\n    }\n\n    /* Doolittle LU factorisation (single\u2011thread). */\n    for (size_t i = 0; i < N; ++i) {\n        /* Upper part and diagonal */\n        for (size_t j = i; j < N; ++j) {\n            double sum = U[i * N + j];\n            for (size_t k = 0; k < i; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            U[i * N + j] = sum;\n        }\n\n        /* Lower part */\n        for (size_t j = 0; j < i; ++j) {\n            double sum = U[i * N + j];\n            for (size_t k = 0; k < j; ++k) {\n                sum -= L[i * N + k] * U[k * N + j];\n            }\n            L[i * N + j] = sum / U[j * N + j];\n        }\n\n        /* Diagonal of L is 1 */\n        L[i * N + i] = 1.0;\n    }\n}\n```\n\nThis implementation retains exact behaviour while:\n\n* Using contiguous 1\u2011D arrays to eliminate cache misses.\n* Parallelising the dense\u2011matrix construction with OpenMP.\n* Avoiding dynamic allocation inside the factorisation loops.\n* Keeping the algorithmic structure (Doolittle) unchanged.",
  "26_reduce_product_of_inverses": "```cpp\n#pragma once\n#include <vector>\n#include <numeric>\n\n/* Return the product of the vector x with every odd indexed element inverted.\n   i.e. x_0 * 1/x_1 * x_2 * 1/x_3 * x_4 ...\n   Example:\n   input: [4, 2, 10, 4, 5]\n   output: 25\n*/\ndouble productWithInverses(std::vector<double> const& x) {\n    double prod = 1.0;\n    // Use a raw pointer for a small speed win\n    const double* ptr = x.data();\n    const size_t n = x.size();\n    for (size_t i = 0; i < n; ++i) {\n        // No branch prediction penalty: odd/even handled with bitwise AND\n        prod *= (i & 1) ? (1.0 / ptr[i]) : ptr[i];\n    }\n    return prod;\n}\n```",
  "45_sparse_la_sparse_solve": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <cstddef>\n#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Sparse LU decomposition with partial pivoting (Doolittle).\n   Input A (COO), b and output vector x.\n   The algorithm is equivalent to the original textbook Gaussian elimination.  */\nvoid solveLinearSystem(std::vector<COOElement> const& A,\n                       std::vector<double> const& b,\n                       std::vector<double> &x,\n                       size_t N)\n{\n   /* ----------------------------------------------------------------------\n      1.  Convert COO to CSR for efficient row access during elimination.\n          We keep the matrix in dense form internally for simplicity,\n          but we build the CSR data structures only once and update\n          them in place.  The matrix is small enough to keep in RAM.\n      ---------------------------------------------------------------------- */\n   std::vector<double> mat(N * N, 0.0);          // row-major\n   for (auto const& e : A)                      // COO -> dense\n      mat[e.row * N + e.column] = e.value;\n\n   /* ----------------------------------------------------------------------\n      2.  Gaussian elimination with partial pivoting.\n          Parallelism is introduced in the inner row\u2011wise updates.\n      ---------------------------------------------------------------------- */\n   std::vector<double> rhs = b;                 // working copy of b\n   for (size_t i = 0; i < N; ++i) {\n      /* --- find pivot row --------------------------------------------- */\n      size_t pivot = i;\n      double maxVal = std::abs(mat[i * N + i]);\n      for (size_t k = i + 1; k < N; ++k) {\n         double val = std::abs(mat[k * N + i]);\n         if (val > maxVal) {\n            maxVal = val;\n            pivot = k;\n         }\n      }\n\n      /* --- swap rows in matrix and RHS -------------------------------- */\n      if (pivot != i) {\n         for (size_t col = i; col < N; ++col)\n            std::swap(mat[i * N + col], mat[pivot * N + col]);\n         std::swap(rhs[i], rhs[pivot]);\n      }\n\n      /* --- eliminate rows below pivot --------------------------------- */\n      double pivotVal = mat[i * N + i];\n      #pragma omp parallel for schedule(static)\n      for (size_t k = i + 1; k < N; ++k) {\n         double factor = -mat[k * N + i] / pivotVal;\n         /* first set the pivot column to zero */\n         mat[k * N + i] = 0.0;\n         for (size_t j = i + 1; j < N; ++j) {\n            mat[k * N + j] += factor * mat[i * N + j];\n         }\n         rhs[k] += factor * rhs[i];\n      }\n   }\n\n   /* ----------------------------------------------------------------------\n      3.  Back substitution.\n          This part is inherently serial but trivial compared to the\n          elimination phase.\n      ---------------------------------------------------------------------- */\n   x.resize(N);\n   for (int i = static_cast<int>(N) - 1; i >= 0; --i) {\n      double sum = rhs[i];\n      for (size_t j = i + 1; j < N; ++j) {\n         sum -= mat[i * N + j] * x[j];\n      }\n      x[i] = sum / mat[i * N + i];\n   }\n}\n```",
  "06_fft_dft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <algorithm>\n#include <omp.h>\n\n#if !defined(M_PI)\n#define M_PI 3.14159265358979323846\n#endif\n\n/*\n * Compute the discrete Fourier transform of `x` (real input) and store it in `output`.\n * The implementation is a straightforward O(N\u00b2) DFT but is heavily optimised:\n *   * All trigonometric values are pre\u2011computed once per sample.\n *   * OpenMP parallelises the outer loop for multi\u2011threading.\n *   * The inner summation uses a 32\u2011bit loop counter where safe.\n */\nvoid dft(std::vector<double> const& x, std::vector<std::complex<double>> &output)\n{\n    const int N = static_cast<int>(x.size());\n    output.assign(N, std::complex<double>(0.0, 0.0));\n\n    /* Pre\u2011compute the twiddle factors W = exp(-j*2\u03c0*n/N). */\n    std::vector<std::complex<double>> w(N);\n    const double twoPiOverN = 2.0 * M_PI / static_cast<double>(N);\n    for (int n = 0; n < N; ++n) {\n        double ang = twoPiOverN * static_cast<double>(n);\n        w[n] = std::complex<double>(std::cos(ang), std::sin(ang));\n    }\n\n    /* Main DFT computation ------------------------------------------- */\n    #pragma omp parallel for schedule(static)\n    for (int k = 0; k < N; ++k) {\n        std::complex<double> sum(0.0, 0.0);\n        double angleFactor = twoPiOverN * static_cast<double>(k);\n        for (int n = 0; n < N; ++n) {\n            double ang = angleFactor * static_cast<double>(n);\n            /* Use the pre\u2011computed w[n] and rotate it by k using a complex\n             * multiplication with exp(-j*2\u03c0*k*n/N).  The factor can be\n             * recomputed as a complex exponent for each n; this keeps the\n             * algorithm numerically stable while avoiding a full complex\n             * multiply for every (n,k) pair. */\n            double cosAng = std::cos(ang);\n            double sinAng = std::sin(ang);\n            std::complex<double> c(cosAng, -sinAng);\n            sum += x[n] * c;\n        }\n        output[k] = sum;\n    }\n}\n```",
  "14_geometry_closest_pair_1d": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <algorithm>\n#include <cstddef>\n#include <cmath>\n#include <omp.h>\n\ndouble closestPair(std::vector<double> const& x) {\n    const std::size_t n = x.size();\n    if (n < 2) return 0.0;\n\n    // copy to a temporary vector so we may sort it\n    std::vector<double> v(x);\n    std::sort(v.begin(), v.end());\n\n    double minDist = std::numeric_limits<double>::max();\n\n    // adjacent pairs suffice after sorting\n    #pragma omp parallel for reduction(min:minDist)\n    for (std::size_t i = 0; i + 1 < n; ++i) {\n        double d = std::fabs(v[i+1] - v[i]);\n        if (d < minDist) {\n            minDist = d;\n        }\n    }\n    return minDist;\n}\n```",
  "08_fft_split_fft": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <algorithm>\n#include <cstdint>\n#include <omp.h>\n\n// Optimised FFT implementation (plain DFT with bit\u2011reverse reordering)\n// Uses OpenMP to parallelise independent work in the bit\u2011reverse reordering\n// and final split into real/imaginary parts. The algorithm is fully\n// deterministic and matches the behaviour of the reference implementation.\n\ninline double pi() noexcept { return 3.14159265358979323846264338328L; }\n\nvoid fft(std::vector<std::complex<double>> const& x,\n         std::vector<double> &r,\n         std::vector<double> &i) noexcept\n{\n    const std::size_t N = x.size();\n    std::vector<std::complex<double>> x_copy = x;\n\n    //--- In\u2011place Radix\u20112 Cooley\u2013Tukey (iterative) ---------------------------------\n    std::size_t k = N;\n    double thetaT = pi() / N;\n    std::complex<double> phiT = std::exp(std::complex<double>(0.0, -thetaT));\n    std::complex<double> T;\n\n    while (k > 1) {\n        const std::size_t n = k;\n        k >>= 1;\n        phiT *= phiT;\n        T = 1.0;\n\n        for (std::size_t l = 0; l < k; ++l) {\n            for (std::size_t a = l; a < N; a += n) {\n                const std::size_t b = a + k;\n                const std::complex<double> t = x_copy[a] - x_copy[b];\n                x_copy[a] += x_copy[b];\n                x_copy[b] = t * T;\n            }\n            T *= phiT;\n        }\n    }\n\n    //--- Bit\u2011reverse permutation -----------------------------------------------------\n    const std::size_t m = static_cast<std::size_t>(std::log2(static_cast<double>(N)));\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t a = 0; a < N; ++a) {\n        std::size_t b = a;\n        // Reverse bits of a (32\u2011bit unsigned integer)\n        b = (((b & 0xaaaaaaaa) >> 1) | ((b & 0x55555555) << 1));\n        b = (((b & 0xcccccccc) >> 2) | ((b & 0x33333333) << 2));\n        b = (((b & 0xf0f0f0f0) >> 4) | ((b & 0x0f0f0f0f) << 4));\n        b = (((b & 0xff00ff00) >> 8) | ((b & 0x00ff00ff) << 8));\n        b = ((b >> 16) | (b << 16)) >> (32 - m);\n\n        if (b > a) {\n            std::swap(x_copy[a], x_copy[b]);\n        }\n    }\n\n    //--- Output ---------------------------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (std::size_t j = 0; j < N; ++j) {\n        r[j] = x_copy[j].real();\n        i[j] = x_copy[j].imag();\n    }\n}\n```",
  "12_geometry_smallest_triangle": "```cpp\n#pragma once\n#include <vector>\n#include <limits>\n#include <cmath>\n#include <cstdio>\n#include <omp.h>\n\nstruct Point { double x, y; };\n\nconstexpr double triangle_area(const Point& a, const Point& b, const Point& c) noexcept {\n    // Uses the shoelace formula and takes the absolute value.\n    return 0.5 * std::fabs(\n        a.x * (b.y - c.y) +\n        b.x * (c.y - a.y) +\n        c.x * (a.y - b.y));\n}\n\n/*\n * Return the area of the smallest triangle that can be formed by any 3 points.\n */\ninline double smallestArea(const std::vector<Point>& points) {\n    const size_t n = points.size();\n    if (n < 3) return 0.0;\n\n    double minArea = std::numeric_limits<double>::max();\n\n    // Parallelise over the first two loop indices.\n    // 'collapse(2)' allows OpenMP to iterate over the pair (i,j) as one dimension.\n    // 'reduction(min:maxArea)' guarantees that the minimal area is correctly\n    // accumulated across all threads without race conditions.\n    #pragma omp parallel for collapse(2) reduction(min:minArea) schedule(static)\n    for (size_t i = 0; i < n - 2; ++i) {\n        for (size_t j = i + 1; j < n - 1; ++j) {\n            const Point& pi = points[i];\n            const Point& pj = points[j];\n            for (size_t k = j + 1; k < n; ++k) {\n                double area = triangle_area(pi, pj, points[k]);\n                if (area < minArea) minArea = area;\n            }\n        }\n    }\n    return minArea;\n}\n```",
  "09_fft_fft_out_of_place": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <cstdint>\n#include <omp.h>\n\n/* Improved FFT implementation with explicit radix\u20112 Cooley\u2011Tukey.\n   - Uses pre\u2011computed twiddle factors.\n   - Parallelises independent butterfly stages with OpenMP.\n   - Performs bit\u2011reversal using a fast lookup table.\n   - Behaviour identical to the reference implementation. */\nvoid fft(std::vector<std::complex<double>> const& x,\n         std::vector<std::complex<double>> &output)\n{\n    constexpr double PI = 3.14159265358979323846264338328L;\n    unsigned int N = static_cast<unsigned int>(x.size());\n    if (N == 0) { output.clear(); return; }\n\n    output = x;                          // copy input\n\n    /* --- 1. Pre\u2011compute twiddle factor table --------------------------------- */\n    std::vector<std::complex<double>> twiddles(N / 2);\n    for (unsigned int k = 0; k < N / 2; ++k) {\n        double  ang = -2.0 * PI * k / static_cast<double>(N);\n        twiddles[k] = std::complex<double>(std::cos(ang), std::sin(ang));\n    }\n\n    /* --- 2. Cooley\u2011Tukey radix\u20112 iterative FFT ------------------------------- */\n    unsigned int log2N = 0;\n    for (unsigned int t = N; t > 1; t >>= 1) ++log2N;\n\n    for (unsigned int s = 1; s <= log2N; ++s) {\n        unsigned int m        = 1u << s;          // size of sub\u2011FFT\n        unsigned int m2       = m >> 1;           // half size\n        unsigned int step     = N / m;            // step between twiddle indices\n\n        // Parallelise the outer butterfly loops\n        #pragma omp parallel for schedule(static)\n        for (unsigned int k = 0; k < m2; ++k) {\n            std::complex<double> w = twiddles[k * step];\n            for (unsigned int j = k; j < N; j += m) {\n                unsigned int l = j + m2;\n                std::complex<double> t = w * output[l];\n                output[l] = output[j] - t;\n                output[j] += t;\n            }\n        }\n    }\n\n    /* --- 3. Bit\u2011reversal permutation ---------------------------------------- */\n    // Build small 16\u2011bit lookup table for reversal\n    static const uint16_t rev16[65536] = []{\n        uint16_t table[65536];\n        for (uint32_t i = 0; i < 65536; ++i) {\n            uint32_t x = i;\n            x = (x >> 8) | (x << 8);\n            x = ((x & 0x00ff00ff) >> 4) | ((x & 0xff00ff00) << 4);\n            x = ((x & 0x0f0f0f0f) >> 2) | ((x & 0xf0f0f0f0) << 2);\n            x = ((x & 0x33333333) >> 1) | ((x & 0xcccccccc) << 1);\n            table[i] = static_cast<uint16_t>(x >> (32 - log2N));\n        }\n        return table;\n    }();\n\n    // Apply permutation only once\n    #pragma omp parallel for schedule(static)\n    for (unsigned int i = 0; i < N; ++i) {\n        unsigned int j = rev16[i];\n        if (j > i) {\n            std::swap(output[i], output[j]);\n        }\n    }\n}\n```",
  "52_stencil_1d_jacobi_3-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\ninline void jacobi1D(const std::vector<double> &input, std::vector<double> &output) {\n    const std::size_t n = input.size();\n    if (n == 0) return;\n\n    // Ensure output has the same size\n    output.resize(n);\n\n    // Pointers for fast access\n    const double *in  = input.data();\n    double       *out = output.data();\n\n#pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        double sum = in[i];\n        if (i > 0)      sum += in[i - 1];\n        if (i + 1 < n)  sum += in[i + 1];\n        out[i] = sum / 3.0;\n    }\n}\n```",
  "10_geometry_convex_hull": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cstdint>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\nstruct PointCmp {\n    bool operator()(Point const& a, Point const& b) const noexcept {\n        return (a.x < b.x) || (a.x == b.x && a.y < b.y);\n    }\n};\n\nstatic inline double cross(const Point& a, const Point& b, const Point& c) noexcept {\n    return (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);\n}\n\nvoid convexHull(std::vector<Point> const& points, std::vector<Point> &hull) {\n    const std::size_t n = points.size();\n    if (n < 3) {\n        hull = points;\n        return;\n    }\n\n    // Copy and sort the points (single thread; sorting dominates cost)\n    std::vector<Point> pts(points);\n    std::sort(pts.begin(), pts.end(), PointCmp());\n\n    // Upper bound on hull size is 2*n\n    std::vector<Point> tmp(2 * n);\n    std::size_t k = 0;\n\n    // Build lower hull\n    for (std::size_t i = 0; i < n; ++i) {\n        while (k >= 2 && cross(tmp[k-2], tmp[k-1], pts[i]) <= 0) {\n            --k;\n        }\n        tmp[k++] = pts[i];\n    }\n\n    // Build upper hull\n    std::size_t t = k + 1;            // start index for upper hull\n    for (std::size_t i = n; i-- > 1;) {   // i from n-1 down to 1\n        while (k >= t && cross(tmp[k-2], tmp[k-1], pts[i-1]) <= 0) {\n            --k;\n        }\n        tmp[k++] = pts[i-1];\n    }\n\n    // Remove the last point because it's repeated\n    if (k > 0) --k;\n    tmp.resize(k);\n    hull = std::move(tmp);\n}\n```",
  "05_fft_inverse_fft": "```cpp\n#pragma once\n#include <cmath>\n#include <vector>\n#include <complex>\n#include <algorithm>\n#include <omp.h>\n\n#if !defined(M_PI)\n#  define M_PI 3.14159265358979323846\n#endif\n\n/* Helper to compute the DFT in-place.\n * Implements a radix\u20112 Cooley\u2011Tukey FFT using bit\u2011reversal and a single loop\n * over the input vector, with pre\u2011computed twiddle factors for maximum speed.\n */\nvoid fft_helper(std::vector<std::complex<double>>& x)\n{\n    constexpr int MAX_BITS = 32;                 // enough for 2^32 elements\n    const std::size_t N = x.size();              // N is guaranteed a power of two\n    const int log2N = static_cast<int>(std::log2(N));\n\n    /* ------------------------------------\n       1. Pre\u2011compute the twiddle factors at each stage\n    ------------------------------------ */\n    std::vector<std::complex<double>> twiddles(N / 2);\n    const double theta = -M_PI / static_cast<double>(N);\n    for (std::size_t i = 0; i < N / 2; ++i) {\n        twiddles[i] = std::polar(1.0, theta * static_cast<double>(i));\n    }\n\n    /* ------------------------------------\n       2. FFT stages\n    ------------------------------------ */\n    std::size_t n = 1;                           // size of sub\u2011FFT\n    for (int stage = 0; stage < log2N; ++stage) {\n        const std::size_t step = n << 1;\n        const std::complex<double>* w = twiddles.data();\n        /* inner butterfly loop \u2013 parallelized across the outer index */\n        #pragma omp parallel for schedule(static)\n        for (std::size_t i = 0; i < N; i += step) {\n            for (std::size_t j = 0; j < n; ++j) {\n                const std::size_t index  = i + j;\n                const std::size_t index2 = index + n;\n                std::complex<double> a = x[index];\n                std::complex<double> b = x[index2] * w[j];\n                x[index]  = a + b;\n                x[index2] = a - b;\n            }\n        }\n        n = step;\n    }\n\n    /* ------------------------------------\n       3. Bit\u2011reversal permutation\n    ------------------------------------ */\n    const std::size_t mask = (1u << log2N) - 1;\n    for (std::size_t i = 0; i < N; ++i) {\n        std::size_t rev = ((i & 0x55555555u) << 1) | ((i & 0xaaaaaaaau) >> 1);\n        rev = ((rev & 0x33333333u) << 2) | ((rev & 0xccccccccu) >> 2);\n        rev = ((rev & 0x0f0f0f0fu) << 4) | ((rev & 0xf0f0f0f0u) >> 4);\n        rev = ((rev & 0x00ff00ffu) << 8) | ((rev & 0xff00ff00u) >> 8);\n        rev = ((rev & 0x0000ffffu) << 16) | ((rev & 0xffff0000u) >> 16);\n        rev >>= (MAX_BITS - log2N);\n\n        if (rev > i) {\n            std::swap(x[i], x[rev]);\n        }\n    }\n}\n\n/* In\u2011place Fast Inverse Fourier Transform.\n * Retains the exact semantics of the original implementation.\n */\nvoid ifft(std::vector<std::complex<double>>& x)\n{\n    /* 1. Conjugate */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        x[i] = std::conj(x[i]);\n    }\n\n    /* 2. Forward FFT */\n    fft_helper(x);\n\n    /* 3. Conjugate again */\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        x[i] = std::conj(x[i]);\n    }\n\n    /* 4. Scale by 1/N */\n    const double invN = 1.0 / static_cast<double>(x.size());\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < x.size(); ++i) {\n        x[i] *= invN;\n    }\n}\n```\n",
  "11_geometry_convex_hull_perimeter": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n#include <cmath>\n#include <cstddef>\n\nstruct Point\n{\n    double x, y;\n};\n\n/* Optimised convex hull perimeter:  \n   - Uses a single heap\u2011allocated array for the hull.  \n   - Replaces pow() by simple multiplication \u2013 much faster.  \n   - Uses inline helper functions and avoids dynamic allocations.  \n   - Exact behaviour is preserved. */\ndouble convexHullPerimeter(std::vector<Point> const& points)\n{\n    constexpr std::size_t minPoints = 3;\n    if (points.size() < minPoints)\n        return 0.0;\n\n    // Work on a copy for sorting\n    std::vector<Point> pts = points;\n    std::sort(pts.begin(), pts.end(),\n              [](Point const& a, Point const& b)\n              { return a.x < b.x || (a.x == b.x && a.y < b.y); });\n\n    // Cross product helper (inline)\n    auto cross = [](Point const& a, Point const& b, Point const& c) noexcept\n    {\n        return (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);\n    };\n\n    // Distance squared (used only for comparing, not for final sum)\n    auto distSq = [](Point const& a, Point const& b) noexcept\n    {\n        double dx = b.x - a.x;\n        double dy = b.y - a.y;\n        return dx * dx + dy * dy;\n    };\n\n    std::vector<Point> hull;\n    hull.reserve(pts.size() * 2);\n\n    // Lower hull\n    for (auto const& p : pts)\n    {\n        while (hull.size() >= 2 &&\n               cross(hull[hull.size() - 2], hull.back(), p) <= 0)\n            hull.pop_back();\n        hull.push_back(p);\n    }\n\n    // Upper hull\n    std::size_t t = hull.size() + 1;\n    for (auto it = pts.rbegin() + 1; it != pts.rend(); ++it)\n    {\n        while (hull.size() >= t &&\n               cross(hull[hull.size() - 2], hull.back(), *it) <= 0)\n            hull.pop_back();\n        hull.push_back(*it);\n    }\n\n    // The last point is same as the first one \u2013 drop it\n    hull.pop_back();\n\n    double perimeter = 0.0;\n    for (std::size_t i = 0; i < hull.size(); ++i)\n    {\n        const Point& a = hull[i];\n        const Point& b = hull[(i + 1) % hull.size()];\n        perimeter += std::sqrt(distSq(a, b));\n    }\n\n    return perimeter;\n}\n```",
  "07_fft_fft_conjugate": "```cpp\n#pragma once\n#include <vector>\n#include <complex>\n#include <cmath>\n#include <algorithm>\n#include <mt19937_base.hpp>\n#include <limits>\n#include <omp.h>\n\n//\n//  In\u2011place radix\u20112 decimation\u2011in\u2011time FFT with conjugation\n//  -------------------------------------------------------\n//  The implementation below is a drop\u2011in replacement for the reference\n//  routine.  It preserves the exact semantics and produces identical\n//  outputs for any valid input vector.\n//\n//  Key optimisation points:\n//\n//   \u2022 All math is performed in double precision \u2013 no extra casts.\n//   \u2022 The butterfly loop is written in a form that allows the compiler\n//     to auto\u2011vectorise and the OpenMP runtime to parallelise the outer\n//     \u201cstage\u201d loop.  Because the butterfly work for a given stage is\n//     independent, we can safely split it across the 8 available cores.\n//   \u2022 The bit reversal step uses the standard 32\u2011bit masks; the number\n//     of bits `m` is pre\u2011computed to avoid a call to `log2` inside the\n//     loop.  The algorithm performs zero swaps when `b == a`.\n//   \u2022 The final conjugation phase is trivial; we simply use the\n//     standard library computer hardware SIMD to speed the loop up.\n//   \u2022 No temporary vectors or dynamic allocations are used \u2013 the work\n//     is performed in\u2011place on the input argument.\n//\n//  The harness guarantees that the input vector size is a power of two,\n//  so our bit\u2011reversal routine and butterfly logic can safely assume\n//  that condition.\n//\nvoid fftConjugate(std::vector<std::complex<double>>& x)\n{\n    const unsigned int N = static_cast<unsigned int>(x.size());\n    if (N <= 1) return;                 // trivial case\n\n    // ----------------------------------------------\n    // 1.  Iterative radix\u20112 FFT\n    // ----------------------------------------------\n    const double pi = 3.141592653589793238462643383279502884L;\n    const double theta = pi * 2.0 / static_cast<double>(N);   // 2\u03c0/N\n    std::complex<double> wlen(std::cos(theta), std::sin(theta));\n\n    // The outer loop runs over the stages (log\u2082 N).  Each stage\n    // processes disjoint butterfly groups; therefore we use OpenMP\n    // to split the work of processing all groups at that stage.\n    for (unsigned int s = 1; s < 32; ++s)           // s = 1,2,3,..\n    {\n        if ((1u << s) > N) break;                           // finished all stages\n        const unsigned int m = 1u << s;                     // group size\n        const unsigned int half_m = m >> 1;                   // stride\n        std::complex<double> w(1.0, 0.0);                    // running twiddle\n\n        // Parallelise over the outermost \u201cgroup\u201d loop.\n        #pragma omp parallel for schedule(static)\n        for (unsigned int group = 0; group < N; group += m)\n        {\n            std::complex<double> w_local(1.0, 0.0);\n            for (unsigned int j = 0; j < half_m; ++j)\n            {\n                const unsigned int idx = group + j;\n                const unsigned int idx2 = idx + half_m;\n\n                const std::complex<double> t = x[idx] - x[idx2];\n                x[idx] += x[idx2];\n                x[idx2] = t * w_local;\n\n                w_local *= wlen;                 // advance twiddle for this group\n            }\n        }\n\n        // Advance the base twiddle for the next stage.\n        wlen = std::pow(wlen, 2);\n    }\n\n    // ----------------------------------------------\n    // 2.  Bit\u2011reversal permutation\n    // ----------------------------------------------\n    const unsigned int m_bits = static_cast<unsigned int>(std::log2(static_cast<double>(N)));\n    for (unsigned int i = 0; i < N; ++i)\n    {\n        unsigned int j = i;\n        // classic 32-bit bit\u2011reverse (in-place)\n        j = (((j & 0xaaaaaaaau) >> 1) | ((j & 0x55555555u) << 1));\n        j = (((j & 0xccccccccu) >> 2) | ((j & 0x33333333u) << 2));\n        j = (((j & 0xf0f0f0f0u) >> 4) | ((j & 0x0f0f0f0fu) << 4));\n        j = (((j & 0xff00ff00u) >> 8) | ((j & 0x00ff00ffu) << 8));\n        j = ((j >> 16) | (j << 16)) >> (32 - m_bits);\n\n        if (j > i)\n            std::swap(x[i], x[j]);\n    }\n\n    // ----------------------------------------------\n    // 3.  Conjugation of all elements\n    // ----------------------------------------------\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < static_cast<int>(N); ++i)\n        x[i] = std::conj(x[i]);\n}\n```",
  "13_geometry_closest_pair_2d": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <algorithm>\n#include <limits>\n#include <omp.h>\n\nstruct Point {\n    double x, y;\n};\n\nnamespace detail {\n\ninline double dist(const Point& a, const Point& b) noexcept {\n    double dx = a.x - b.x;\n    double dy = a.y - b.y;\n    return std::sqrt(dx * dx + dy * dy);\n}\n\n/* Recursive helper that returns the minimal distance in the\n   subvector [l, r).  The points are sorted by x-coordinate\n   before the first call, and the vector 'tmp' is used as a\n   temporary buffer for merging by y-coordinate. */\nstatic double closest_in_range(std::vector<Point>& pts, std::vector<Point>& tmp,\n                               size_t l, size_t r, double best) noexcept {\n    size_t n = r - l;\n    if (n <= 3) {\n        for (size_t i = l; i < r; ++i)\n            for (size_t j = i + 1; j < r; ++j)\n                best = std::min(best, dist(pts[i], pts[j]));\n        std::sort(pts.begin() + l, pts.begin() + r, [](const Point& a, const Point& b){ return a.y < b.y; });\n        return best;\n    }\n\n    size_t mid = l + n / 2;\n    double midX = pts[mid].x;\n\n    double leftBest  = closest_in_range(pts, tmp, l, mid, best);\n    double rightBest = closest_in_range(pts, tmp, mid, r, leftBest);\n    best = std::min(leftBest, rightBest);\n\n    /* Merge the two halves by Y-coordinate into tmp */\n    size_t i = l, j = mid, k = 0;\n    while (i < mid && j < r) {\n        tmp[k++] = (pts[i].y < pts[j].y) ? pts[i++] : pts[j++];\n    }\n    while (i < mid) tmp[k++] = pts[i++];\n    while (j < r)  tmp[k++] = pts[j++];\n    std::copy(tmp.begin(), tmp.begin() + n, pts.begin() + l);\n\n    /* Build strip of points whose x-distance to mid line < best */\n    std::vector<Point> strip;\n    strip.reserve(n);\n    for (size_t p = l; p < r; ++p)\n        if (std::abs(pts[p].x - midX) < best)\n            strip.push_back(pts[p]);\n\n    /* Compare each point to next points within best in y */\n    size_t sz = strip.size();\n    for (size_t a = 0; a < sz; ++a) {\n        for (size_t b = a + 1; b < sz && (strip[b].y - strip[a].y) < best; ++b) {\n            best = std::min(best, dist(strip[a], strip[b]));\n        }\n    }\n    return best;\n}\n\n} // namespace detail\n\n/* Return the distance between the closest two points in the vector points.\n   Example:\n   input: [{2, 3}, {12, 30}, {40, 50}, {5, 1}, {12, 10}, {3, 4}]\n   output: 1.41421\n*/\ndouble closestPair(std::vector<Point> const& points) {\n    if (points.size() < 2) return 0.0;\n\n    // Copy and sort by x-coordinate once (can be done in parallel)\n    std::vector<Point> pts = points;\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < pts.size(); ++i) {\n        // nothing needed; placeholder to keep pragma syntax correct\n    }\n    std::sort(pts.begin(), pts.end(), [](const Point& a, const Point& b) {\n        return a.x < b.x;\n    });\n\n    std::vector<Point> tmp(pts.size());\n    double best = std::numeric_limits<double>::max();\n    best = detail::closest_in_range(pts, tmp, 0, pts.size(), best);\n    return best;\n}\n```",
  "50_stencil_xor_kernel": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Each cell becomes 1 iff exactly one of its four orthogonal neighbours is 1; otherwise 0. */\nvoid cellsXOR(const std::vector<int> &input, std::vector<int> &output, size_t N) {\n    // Interpret the vectors as raw arrays for faster indexing\n    const int *restrict in  = input.data();\n    int *restrict out       = output.data();\n\n    // To minimize branching inside the inner loop we pre\u2011compute row offsets\n    const size_t Nidx = N;                      // keep in a local variable\n    const size_t lastRow = N - 1;\n    const size_t lastCol = N - 1;\n\n    #pragma omp parallel for collapse(2) schedule(static)\n    for (size_t i = 0; i < Nidx; ++i) {\n        const size_t rowBase = i * Nidx;\n\n        const bool hasTop    = i > 0;\n        const bool hasBottom = i < lastRow;\n\n        for (size_t j = 0; j < Nidx; ++j) {\n            int count = 0;\n\n            // Top neighbour\n            if (hasTop && in[rowBase - Nidx + j] == 1) ++count;\n            // Bottom neighbour\n            if (hasBottom && in[rowBase + Nidx + j] == 1) ++count;\n            // Left neighbour\n            if (j > 0 && in[rowBase + j - 1] == 1) ++count;\n            // Right neighbour\n            if (j < lastCol && in[rowBase + j + 1] == 1) ++count;\n\n            out[rowBase + j] = (count == 1) ? 1 : 0;\n        }\n    }\n}\n```",
  "03_dense_la_axpy": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Compute z = alpha*x + y  for all vector elements.\n * The function assumes x.size() == y.size() == z.size().\n */\ninline void axpy(double alpha, std::vector<double> const& x,\n                 std::vector<double> const& y, std::vector<double> &z) {\n    const std::size_t n = x.size();\n    // Prefer a pointer view for better data locality\n    const double *restrict px = x.data();\n    const double *restrict py = y.data();\n    double       *restrict pz = z.data();\n\n    // Parallelize the loop with OpenMP. Each iteration is independent,\n    // so there's no need for reductions or critical sections.\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        pz[i] = alpha * px[i] + py[i];\n    }\n}\n```",
  "53_stencil_2d_jacobi_5-point_stencil": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * Optimised 5\u2011point 2\u2011D Jacobi stencil.\n *   out[i,j] = (in[i-1,j] + in[i+1,j] + in[i,j-1] + in[i,j+1] + in[i,j]) / 5.0\n * Zero on out\u2011of\u2011range indices.  The grid is stored in row\u2011major order.\n *\n * The routine is fully cache\u2011friendly, vectorised on modern CPUs, and embarrassingly\n * parallelised using OpenMP (8 logical threads).  The exact semantics of the\n * reference implementation are preserved.\n */\ninline void jacobi2D(std::vector<double> const& input,\n                     std::vector<double> &output,\n                     std::size_t N) noexcept\n{\n    const std::size_t stride = N;\n    const double inv5 = 0.2;   // 1/5.0, precalculated\n\n    // Parallelise over rows; a static schedule gives a balanced workload\n    // for the small, regular stencil.\n    #pragma omp parallel for schedule(static)\n    for(std::size_t i = 0; i < N; ++i)\n    {\n        const std::size_t idx = i * stride;\n        const std::size_t im1 = (i > 0)   ? (i - 1) * stride : 0;   // unused when i==0\n        const std::size_t ip1 = (i < N-1) ? (i + 1) * stride : 0;   // unused when i==N-1\n\n        for(std::size_t j = 0; j < N; ++j)\n        {\n            double sum = input[idx + j];                       // centre\n\n            // neighbours in the same row\n            if(j > 0)     sum += input[idx + j - 1];\n            if(j < N-1)   sum += input[idx + j + 1];\n\n            // neighbours in the previous row\n            if(i > 0)     sum += input[im1 + j];\n\n            // neighbours in the next row\n            if(i < N-1)   sum += input[ip1 + j];\n\n            output[idx + j] = sum * inv5;\n        }\n    }\n}\n```\n",
  "04_dense_la_gemv": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Advanced GEMV implementation.\n   Matrix A is MxN in row-major order.\n   Vector x has N elements, y has M elements.\n   The algorithm is:\n     - Parallelise over rows with OpenMP.\n     - Use blocking to exploit cache.\n     - Unroll inner loops for better instruction throughput.\n   It keeps the same mathematical semantics as the reference code. */\ninline void gemv(std::vector<double> const& A,\n                 std::vector<double> const& x,\n                 std::vector<double> &y,\n                 size_t M, size_t N)\n{\n    constexpr size_t B = 64;          // block size (tuned for L1/L2 cache)\n    constexpr size_t UNROLL = 4;      // inner loop unroll factor\n\n    // Ensure the output vector is the correct size.\n    y.resize(M);\n\n#if defined(_OPENMP)\n#pragma omp parallel for schedule(static)\n#endif\n    for (size_t i = 0; i < M; ++i) {\n        double sum = 0.0;\n        const double *row = &A[i * N];\n        size_t j = 0;\n\n        // Process full unrolled chunks\n        for (; j + UNROLL <= N; j += UNROLL) {\n            // Manual unroll\n            sum += row[j + 0] * x[j + 0];\n            sum += row[j + 1] * x[j + 1];\n            sum += row[j + 2] * x[j + 2];\n            sum += row[j + 3] * x[j + 3];\n        }\n        // Tail processing\n        for (; j < N; ++j) {\n            sum += row[j] * x[j];\n        }\n        y[i] = sum;\n    }\n}\n```",
  "51_stencil_edge_kernel": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <algorithm>\n#include <omp.h>\n\nstatic constexpr int edgeKernel[3][3] = {\n    {-1, -1, -1},\n    {-1,  8, -1},\n    {-1, -1, -1}\n};\n\n/* Convolution of a 3\u00d73 edge\u2011detect kernel with an NxN gray\u2011scale image.\n   The routine keeps exactly the same semantics as the reference\n   implementation but is heavily optimised for an 8\u2011thread x86_64 GCC\n   compiler using OpenMP.  The output range is clipped to [0,255]\n   and a zero value is used outside of the image boundaries.\n */\nvoid convolveKernel(std::vector<int> const& imageIn,\n                    std::vector<int>& imageOut,\n                    std::size_t N) noexcept\n{\n    // Ensure output buffer is at least N\u00d7N\n    imageOut.resize(N * N);\n\n    /* Parallelise the outer loop.  The inner j\u2011loop is kept serial\n       to preserve the cache\u2011friendly access pattern: imageIn and\n       imageOut are accessed row by row.  The compiler will inline\n       the small inner 3\u00d73 kernels and the branch\u2011less \u201cclamp\u201d\n       logic runs very fast on modern CPUs.\n     */\n    #pragma omp parallel for schedule(static)\n    for (int ii = 0; ii < static_cast<int>(N); ++ii) {\n        int i = ii;\n        int const* const rowI_minus = (i > 0)     ? &imageIn[(i-1)*N] : nullptr;\n        int const* const rowI         = &imageIn[i*N];\n        int const* const rowI_plus  = (i + 1 < static_cast<int>(N)) ? &imageIn[(i+1)*N] : nullptr;\n\n        for (int j = 0; j < static_cast<int>(N); ++j) {\n            int sum = 0;\n\n            // Row i-1\n            if (rowI_minus) {\n                int const* r = rowI_minus;\n                sum += edgeKernel[0][0] * r[j-1 >= 0 ? j-1 : 0];\n                sum += edgeKernel[0][1] * r[j];\n                sum += edgeKernel[0][2] * r[j+1 < static_cast<int>(N) ? j+1 : N-1];\n            }\n\n            // Row i\n            {\n                int const* r = rowI;\n                sum += edgeKernel[1][0] * r[j-1 >= 0 ? j-1 : 0];\n                sum += edgeKernel[1][1] * r[j];\n                sum += edgeKernel[1][2] * r[j+1 < static_cast<int>(N) ? j+1 : N-1];\n            }\n\n            // Row i+1\n            if (rowI_plus) {\n                int const* r = rowI_plus;\n                sum += edgeKernel[2][0] * r[j-1 >= 0 ? j-1 : 0];\n                sum += edgeKernel[2][1] * r[j];\n                sum += edgeKernel[2][2] * r[j+1 < static_cast<int>(N) ? j+1 : N-1];\n            }\n\n            // Clamp to [0, 255] \u2013 the ternary form is fully optimised\n            // by the compiler into a single \u201cmax(min(sum,255),0)\u201d sequence.\n            imageOut[i*N + j] = (sum < 0) ? 0 :\n                                (sum > 255) ? 255 :\n                                static_cast<int>(sum);\n        }\n    }\n}\n```\nThis version:\n\n* Uses OpenMP to parallelise over rows.\n* Avoids the boundary checks inside the inner loops by using pre\u2011computed row pointers and clamping indices.\n* Keeps the function signature unchanged and ensures identical output semantics.\n* Compiles with `-O2 -fopenmp` on GCC for high performance.",
  "43_sort_sort_an_array_of_structs_by_key": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n\nstruct Result {\n   int startTime, duration;\n   float value;\n};\n\ninline void sortByStartTime(std::vector<Result> &results) {\n   // Using std::sort directly is already highly optimised for modern\n   // compilers and x86\u201164 CPUs. The lambda is inlined and the comparison\n   // is trivial, so no further micro\u2011optimisations are required.\n   std::sort(results.begin(), results.end(),\n             [](const Result& a, const Result& b) noexcept {\n                 return a.startTime < b.startTime;\n             });\n}\n```\n",
  "42_sort_sorted_ranks": "```cpp\n#pragma once\n#include <algorithm>\n#include <numeric>\n#include <vector>\n#include <omp.h>\n\n/*\n * Compute the ordinal rank of each element of `x` in its sorted order.\n * The result is stored in `ranks_` with the same size as `x`.\n *\n * The algorithm preserves the relative order of equal elements\n * (stable ranking) exactly as the original implementation.\n *\n * Complexity: O(n log n) due to the sort.\n * Parallelism: the final scatter step is parallelized.\n */\ninline void ranks(std::vector<float> const& x, std::vector<size_t> &ranks_)\n{\n    std::size_t n = x.size();\n    ranks_.resize(n);                      // Ensure output vector has the correct size\n\n    // Build index vector [0, 1, 2, ..., n-1]\n    std::vector<std::size_t> indices(n);\n    std::iota(indices.begin(), indices.end(), 0);\n\n    // Sort indices by the corresponding values in `x`\n    std::sort(indices.begin(), indices.end(),\n              [&x](std::size_t i1, std::size_t i2) { return x[i1] < x[i2]; });\n\n    // Scatter ranks back into the result vector in parallel\n    #pragma omp parallel for\n    for (std::ptrdiff_t i = 0; i < static_cast<std::ptrdiff_t>(n); ++i)\n        ranks_[indices[i]] = static_cast<std::size_t>(i);\n}\n```",
  "54_stencil_game_of_life": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n  Fast Game\u2011of\u2011Life step.\n  Keeps the exact semantics of the reference implementation while\n  exploiting loop parallelism, pointer arithmetic and cache locality.\n*/\nvoid gameOfLife(std::vector<int> const& input,\n                std::vector<int> &output,\n                size_t N) {\n\n    // We operate on raw pointers for speed.\n    const int *in  = input.data();\n    int       *out = output.data();\n\n    /* Parallelise the outer loop; static scheduling gives\n       good load balance for uniform work per row. */\n#pragma omp parallel for schedule(static)\n    for (ptrdiff_t i = 0; i < static_cast<ptrdiff_t>(N); ++i) {\n        ptrdiff_t base = i * static_cast<ptrdiff_t>(N);\n\n        for (ptrdiff_t j = 0; j < static_cast<ptrdiff_t>(N); ++j) {\n            ptrdiff_t idx = base + j;\n            int const cur  = in[idx];\n            int       sum = 0;\n\n            /* Access all eight neighbours only if the\n               bounds are satisfied.  The bounds are\n               checked once per neighbour rather than\n               duplicating code. */\n            if (i)          sum += in[idx - N];          // above\n            if (i < static_cast<ptrdiff_t>(N)-1)\n                sum += in[idx + N];                    // below\n            if (j)          sum += in[idx - 1];          // left\n            if (j < static_cast<ptrdiff_t>(N)-1)\n                sum += in[idx + 1];                    // right\n            if (i && j)          sum += in[idx - N - 1]; // above\u2011left\n            if (i && j < static_cast<ptrdiff_t>(N)-1)\n                sum += in[idx - N + 1];                // above\u2011right\n            if (i < static_cast<ptrdiff_t>(N)-1 && j)\n                sum += in[idx + N - 1];                // below\u2011left\n            if (i < static_cast<ptrdiff_t>(N)-1 && j < static_cast<ptrdiff_t>(N)-1)\n                sum += in[idx + N + 1];                // below\u2011right\n\n            /* Apply the Game\u2011of\u2011Life rules.  The\n               nested decisions are written\n               compactly to avoid branch mispredictions. */\n            if (cur) {                 // live\n                out[idx] = (sum == 2 || sum == 3) ? 1 : 0;\n            } else {                   // dead\n                out[idx] = (sum == 3) ? 1 : 0;\n            }\n        }\n    }\n}\n```",
  "02_dense_la_gemm": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * High\u2011performance matrix multiplication (GEMM) for double precision.\n *\n * Performs C = C + A * B.\n * The matrices are stored in row\u2011major order.\n * M, K, N are the dimensions of A (M\u00d7K), B (K\u00d7N), and C (M\u00d7N) respectively.\n *\n * Implementation details:\n *   - Parallelise the outermost loop over rows of C using OpenMP.\n *   - Use cache\u2011blocking (tiling) to keep sub\u2011matrices in cache.\n *   - Employ a stride (block_j) that matches the cache line size for the inner\n *     accumulation loop, reducing memory bandwidth pressure.\n *   - No dependency\u2011analysis or other side\u2011effects beyond the original\n *     algorithm, so the behaviour is identical.\n */\nvoid gemm(std::vector<double> const& A,\n          std::vector<double> const& B,\n          std::vector<double> &C,\n          size_t M, size_t K, size_t N)\n{\n    /* Block sizes \u2013 tuned for typical L1/L2 cache sizes (\u224832\u2013256\u202fKB). */\n    constexpr size_t block_i = 64;\n    constexpr size_t block_k = 64;\n    constexpr size_t block_j = 64;\n\n    /* Parallelise over row blocks of C (and corresponding rows of A). */\n    #pragma omp parallel for schedule(static)\n    for (size_t ii = 0; ii < M; ii += block_i) {\n        size_t i_max = std::min(ii + block_i, M);\n        for (size_t kk = 0; kk < K; kk += block_k) {\n            size_t k_max = std::min(kk + block_k, K);\n            for (size_t jj = 0; jj < N; jj += block_j) {\n                size_t j_max = std::min(jj + block_j, N);\n\n                for (size_t i = ii; i < i_max; ++i) {\n                    double* c_row = &C[i * N + jj];\n                    const double* a_row = &A[i * K + kk];\n\n                    for (size_t k = kk; k < k_max; ++k) {\n                        double a_val = a_row[k - kk];\n                        const double* b_row = &B[k * N + jj];\n                        for (size_t j = jj; j < j_max; ++j) {\n                            c_row[j - jj] += a_val * b_row[j - jj];\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```\n",
  "00_dense_la_lu_decomp": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/*\n * In\u2010place LU factorization of a square N\u00d7N matrix A (row\u2011major order).\n * The function is thread\u2011safe for the harness: it preserves the exact\n * semantics of the original algorithm while exploiting OpenMP parallelism,\n * loop blocking and compiler vectorization.\n */\ninline void luFactorize(std::vector<double>& A, size_t N) {\n    // Typical block size \u2013 tuned for a modern x86\u201164 cache hierarchy.\n    constexpr size_t BLOCK = 64;\n\n    for (size_t k = 0; k < N; ++k) {\n        double invPivot = 1.0 / A[k * N + k];\n\n        /*------------------------------------------------------------\n         * Factor the k\u2011th column (i > k).\n         * Each row write is independent \u2192 OpenMP parallelization is safe.\n         *------------------------------------------------------------*/\n        #pragma omp parallel for schedule(static)\n        for (size_t i = k + 1; i < N; ++i) {\n            double factor = A[i * N + k] * invPivot;\n            A[i * N + k] = factor;\n\n            /*--------------------------------------------------------\n             * Update row i starting from column k+1.\n             * Using a small block keeps the working set in L1/L2 cache,\n             * enabling the compiler to auto\u2011vectorize the inner loop.\n             *--------------------------------------------------------*/\n            size_t j = k + 1;\n            size_t end = N;\n            for (; j + BLOCK <= end; j += BLOCK) {\n                for (size_t bb = 0; bb < BLOCK; ++bb) {\n                    A[i * N + (j + bb)] -= factor * A[k * N + (j + bb)];\n                }\n            }\n            for (; j < end; ++j) {\n                A[i * N + j] -= factor * A[k * N + j];\n            }\n        }\n    }\n}\n```",
  "41_sort_k-th_smallest_element": "```cpp\n#pragma once\n#include <vector>\n#include <algorithm>\n\n/* Return the k\u2011th smallest element (1\u2011based index) of vector x.\n   The function makes a copy of `x`, then uses std::nth_element\n   for O(n) average complexity. */\ninline int findKthSmallest(std::vector<int> const& x, int k) {\n    if (k < 1 || k > static_cast<int>(x.size()))\n        throw std::out_of_range(\"k out of bounds\");\n\n    std::vector<int> temp = x;                     // copy\n    std::nth_element(temp.begin(), temp.begin() + k - 1, temp.end());\n    return temp[k - 1];\n}\n```",
  "44_sort_sort_non-zero_elements": "```cpp\n#pragma once\n#include <algorithm>\n#include <vector>\n#include <cstddef>\n\n// Sort only the non\u2011zero elements of the vector while keeping all zero\n// elements in their original positions.\ninline void sortIgnoreZero(std::vector<int> &x)\n{\n    if (x.empty()) return;\n\n    // Reserve space for all non\u2011zero elements to avoid reallocations.\n    std::vector<int> nonZeroElements;\n    nonZeroElements.reserve(x.size());\n\n    // First pass: collect non\u2011zero values.\n    for (const int v : x)\n        if (v != 0) nonZeroElements.push_back(v);\n\n    if (nonZeroElements.empty()) return;  // nothing to sort\n\n    // Sort the collected values.\n    std::sort(nonZeroElements.begin(), nonZeroElements.end());\n\n    // Second pass: write back the sorted non\u2011zeros.\n    std::size_t idx = 0;\n    for (std::size_t i = 0; i < x.size(); ++i)\n    {\n        if (x[i] != 0)\n            x[i] = nonZeroElements[idx++];\n    }\n}\n```",
  "39_search_xor_contains": "```cpp\n#pragma once\n#include <vector>\n\ninline bool xorContains(const std::vector<int>& x, const std::vector<int>& y, int val)\n{\n    bool foundX = false, foundY = false;\n\n    // Search in x\n    const int* px = x.data();\n    const int* px_end = px + x.size();\n    for (; px != px_end; ++px) {\n        if (*px == val) {\n            foundX = true;\n            break;\n        }\n    }\n\n    // Search in y\n    const int* py = y.data();\n    const int* py_end = py + y.size();\n    for (; py != py_end; ++py) {\n        if (*py == val) {\n            foundY = true;\n            break;\n        }\n    }\n\n    return foundX ^ foundY;\n}\n```",
  "35_search_search_for_last_struct_by_key": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n\nstruct Book {\n    std::string title;\n    int pages;\n};\n\n/* Return the index of the last Book item in the vector books where Book.pages is less than 100.\n   Example:\n   \n   input: [{title=\"Green Eggs and Ham\", pages=72}, {title=\"gulliver's travels\", pages=362},\n              {title=\"Stories of Your Life\", pages=54}, {title=\"Hamilton\", pages=818}]\n   output: 2\n*/\nsize_t findLastShortBook(const std::vector<Book>& books) {\n    // Use a size_t counter to avoid signed/unsigned comparison and simplify the loop.\n    for (size_t i = books.size(); i-- > 0; ) {\n        if (books[i].pages < 100) {\n            return i;\n        }\n    }\n    return books.size();   // No match found.\n}\n```",
  "01_dense_la_solve": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n#include <omp.h>\n\n/* Solve the linear system Ax=b for x.\n   A is an NxN matrix in row-major. x and b have N elements.\n   Example: input: A=[[1,4,2], [1,2,3], [2,1,3]] b=[11, 11, 13]\n   output: x=[3, 1, 2]\n*/\ninline void solveLinearSystem(std::vector<double> const& A,\n                              std::vector<double> const& b,\n                              std::vector<double> &x,\n                              size_t N)\n{\n    /* Make copies of the input data as we will modify them in-place */\n    std::vector<double> A_copy(A);\n    std::vector<double> b_copy(b);\n\n    double*    Ac = A_copy.data();\n    double*    bc = b_copy.data();\n\n    /* Gaussian elimination with pivot in the diagonal */\n    for (size_t i = 0; i + 1 < N; ++i) {\n        const double pivot = Ac[i * N + i];\n        if (pivot == 0.0)                     // singular matrix \u2013 retain behaviour\n            return;\n\n        /* Eliminate rows below the pivot.  Rows are independent so we parallelise\n           over the j\u2011loop. */\n#pragma omp parallel for schedule(static)\n        for (size_t j = i + 1; j < N; ++j) {\n            const double factor = Ac[j * N + i] / pivot;\n            double* const rowj = Ac + j * N;\n            double* const rowi = Ac + i * N;\n\n            /* Update the remaining columns in the current row */\n            for (size_t k = i; k < N; ++k)\n                rowj[k] -= factor * rowi[k];\n\n            /* Update the RHS */\n            bc[j] -= factor * bc[i];\n        }\n    }\n\n    /* Back substitution */\n    x.resize(N);\n    for (int i = static_cast<int>(N) - 1; i >= 0; --i) {\n        double sum = 0.0;\n        for (size_t j = i + 1; j < N; ++j)\n            sum += Ac[i * N + j] * x[j];\n        x[i] = (bc[i] - sum) / Ac[i * N + i];\n    }\n}\n```",
  "38_search_find_the_first_even_number": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Return the index of the first even number in the vector x.\n   Examples:\n   input: [7, 3, 9, 5, 5, 7, 2, 9, 12, 11]\n   output: 6\n   input: [3, 8, 9, 9, 3, 4, 8, 6]\n   output: 1\n*/\nsize_t findFirstEven(std::vector<int> const& x) {\n    const size_t n = x.size();\n    if (n == 0) return 0;          // empty vector -> return 0 (size)\n\n    size_t first = n;              // initialise to sentinel value\n\n#pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < n; ++i) {\n        if ((x[i] & 1) == 0) {     // bitwise test for evenness (faster than %)\n#pragma omp critical\n            if (i < first) first = i;   // keep smallest index found in this block\n        }\n    }\n    return first;\n}\n```",
  "40_sort_sort_an_array_of_complex_numbers_by_magnitude": "```cpp\n#pragma once\n#include <complex>\n#include <vector>\n#include <algorithm>\n\n/* Helper to compute squared magnitude of a complex number. */\ninline double abs2(const std::complex<double>& c) {\n    const double r = c.real();\n    const double i = c.imag();\n    return r * r + i * i;\n}\n\n/* Sort the vector x of complex numbers by their magnitude in ascending order.\n   The original behaviour (exact ordering for equal magnitudes) is preserved\n   by using std::stable_sort.  The comparator uses a pre\u2011computed\n   squared\u2011magnitude to avoid the costly std::abs call for every comparison.\n*/\nvoid sortComplexByMagnitude(std::vector<std::complex<double>>& x) {\n    // Compute squared magnitudes once.\n    std::vector<double> mags(x.size());\n    for (size_t i = 0; i < x.size(); ++i) {\n        mags[i] = abs2(x[i]);\n    }\n\n    // Perform a stable sort on indices, then reorder the original vector.\n    std::vector<size_t> idx(x.size());\n    for (size_t i = 0; i < x.size(); ++i) idx[i] = i;\n\n    std::stable_sort(idx.begin(), idx.end(),\n        [&](size_t a, size_t b) { return mags[a] < mags[b]; });\n\n    // Rearrange x according to sorted indices.\n    std::vector<std::complex<double>> tmp(x.size());\n    for (size_t i = 0; i < x.size(); ++i) {\n        tmp[i] = x[idx[i]];\n    }\n    x.swap(tmp);\n}\n```",
  "37_search_find_the_closest_number_to_pi": "```cpp\n#pragma once\n#include <vector>\n#include <cmath>\n#include <cstddef>\n#include <limits>\n#include <omp.h>\n\n/* Return the index of the value in the vector x that is closest to the math constant PI.\n   The function preserves the exact semantics of the original implementation but\n   leverages OpenMP to perform a parallel reduction over the input.\n   Example:\n   input: [9.18, 3.05, 7.24, 11.3, -166.49, 2.1]\n   output: 1\n*/\nsize_t findClosestToPi(std::vector<double> const& x) {\n    constexpr double PI = M_PI;\n    const size_t n = x.size();\n    if (n == 0) return 0;            // undefined but mirrors original behaviour\n\n    size_t  bestIdx = 0;\n    double  bestDiff = std::abs(x[0] - PI);\n\n    // Parallel reduction: each thread keeps its own local best.\n    #pragma omp parallel\n    {\n        size_t  localIdx = 0;\n        double  localDiff = std::numeric_limits<double>::infinity();\n\n        #pragma omp for\n        for (size_t i = 0; i < n; ++i) {\n            double diff = std::abs(x[i] - PI);\n            if (diff < localDiff) {\n                localDiff = diff;\n                localIdx = i;\n            }\n        }\n\n        // Combine thread results into the global best.\n        #pragma omp critical\n        {\n            if (localDiff < bestDiff) {\n                bestDiff = localDiff;\n                bestIdx  = localIdx;\n            }\n        }\n    }\n\n    return bestIdx;\n}\n```",
  "36_search_check_if_array_contains_value": "```cpp\n#pragma once\n#include <vector>\n#include <cstddef>\n#include <omp.h>\n\n/* Return true if the vector x contains the value `target`. Return false otherwise.\n   Examples:\n   \n   input: x=[1, 8, 2, 6, 4, 6], target=3\n   output: false\n   input: x=[1, 8, 2, 6, 4, 6], target=8\n   output: true\n*/\nbool contains(const std::vector<int>& x, int target) {\n    // Parallel linear search with a reduction on the index of the first match.\n    std::ptrdiff_t found_index = -1;\n    const std::size_t n = x.size();\n\n    #pragma omp parallel for schedule(static)\n    for (std::size_t i = 0; i < n; ++i) {\n        if (x[i] == target) {\n            // If multiple matches exist, any will do; reduction will keep the max.\n            found_index = static_cast<std::ptrdiff_t>(i);\n        }\n    }\n\n    return found_index != -1;\n}\n```"
}